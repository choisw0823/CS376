{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEpP0mNQYl-B"
      },
      "source": [
        "# Intro\n",
        "\n",
        "\n",
        "\n",
        "We learned about RNN and LSTM in our class, which can be used to process time series data. These models can also be applied to NLP tasks. Among the various models available for NLP, BERT is one of the most famous ones. In November 2018, Google introduced BERT (Bidirectional Encoder Representations from Transformers), an AI language model that gained attention in the field of NLP deep learning models by achieving higher accuracy than humans in some performance evaluations.\n",
        "\n",
        "NLP research labs and companies often evaluate the performance of their models using the SQuAD dataset. SQuAD stands for Stanford Question Answering Dataset and it is a test set created by Stanford University using datasets such as Wikipedia. BERT has shown impressive scores on the SQuAD test set since late 2018, further increasing its prominence.\n",
        "\n",
        "The purpose of this project is to enable BERT to solve fill-in-the-blank inference problems from the Korean national college entrance exam (수능) English section. Since there is a limited amount of training data specifically for 수능 fill-in-the-blank inference, we will utilize the TOEIC dataset for training and then apply the trained model to solve 수능 problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cpgV_pmejae"
      },
      "source": [
        "# BERT\n",
        "BERT stands for Bidirectional Encoder Representations from Transformers. It is a state-of-the-art machine learning model developed by Google for natural language processing tasks. BERT is designed to understand the context of words in a sentence by looking at the words that come before and after it, which is why it's called \"bidirectional.\"\n",
        "\n",
        "Here's a simplified explanation of how BERT works:\n",
        "\n",
        "**Input Embedding: **BERT takes a sentence as input. The sentence is broken down into tokens (words or parts of words). Each token is then converted into a numerical representation (an embedding) that can be understood by the model.\n",
        "\n",
        "**Self-Attention Mechanism**: BERT uses a mechanism called self-attention. This allows the model to weigh the importance of each word in the sentence when trying to understand the meaning of a particular word. For example, in the sentence \"He picked up the glass and drank from it,\" the word \"it\" is heavily influenced by the word \"glass.\"\n",
        "\n",
        "**Encoder Layers**: The processed embeddings then pass through a series of Transformer encoder layers. Each layer further refines the understanding of the sentence.\n",
        "\n",
        "**Output**: The final embeddings are used for whatever task BERT is being used for. For example, in a question-answering task, BERT would use the final embeddings to determine the most likely answer to a given question.\n",
        "\n",
        "One of the key advantages of BERT is that it can be fine-tuned for a wide variety of NLP tasks with a relatively small amount of training data, making it a very versatile and powerful model.\n",
        "\n",
        "![644a6ad719f3e45cc76e075d_644632db715a5e555cb15777_aa1-1024x881.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K3VCu3tKWsm"
      },
      "source": [
        "# Get Pre-trained model\n",
        "I will be using the Python library called transformers. Transformers is a Python library that provides various modules for natural language processing, allowing for effective utilization. It includes implementations of leading language models such as BERT and can be used for various NLP tasks such as text classification, named entity recognition, and sentence generation.\n",
        "\n",
        "By using the transformers library, you can easily load pre-trained language models and perform tasks such as sentence tokenization, embedding, and output classification. Additionally, it allows for fine-tuning the language model to tailor it to specific tasks and train it accordingly.\n",
        "\n",
        "Transformers provides a convenient interface for a range of NLP tasks and offers a variety of pre-trained model options, making it easier to perform natural language processing tasks.\n",
        "\n",
        "We can choose the different BERT model depending on the task. These are some examples.\n",
        "1. BertForQuestionAnswering\n",
        "2. BertForTokenClassification\n",
        "3. BertForMaskedLM\n",
        "4. BertForMultipleChoice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azVrT7U7LApS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9999caca-c82f-4ab6-b1ba-7abda2bbb1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1+cu118)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=c25bcf34d8271b76e4262fb32c80ee28a97c1a5755e35320920db432ace8b52c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torchsummary torchviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKPOoY4maLt6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchviz import make_dot\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddkaWFUkNkeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4807df03-3469-4f4f-ca06-83ef7aa0a457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS376'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 35 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), 310.98 KiB | 2.88 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/choisw0823/CS376.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px9-vpetN5Am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6feea9-3b29-471a-c910-f01c579f5fb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README.md', '.git', 'sat_train.csv', 'train.json']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.listdir('CS376')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training without TOEIC\n",
        "First, I will proceed with training using only the Korean national college entrance exam  English dataset."
      ],
      "metadata": {
        "id": "tT2oE43b06dt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWFBlEca7Ioe"
      },
      "source": [
        "# SAT Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SGBdu2jDOHP"
      },
      "source": [
        "I will proceed to train the model on complex problems from the Korean national college entrance exam\n",
        "The problems are in the format of fill-in-the-blank inference, similar to the previous TOEIC questions. All the files that were originally in HWP file format, as shown in the following image, have been converted into CSV format. <br>\n",
        "\n",
        "The dataset contains fill-in-the-blank questions taken from exams for the first to third year of high school.The Blank in the question is represented with \"___\".\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8oTu5sGHnq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45bae33-c622-4321-dc66-b902d8a8901c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(155, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Load the data from CSV file\n",
        "sat_data =pd.read_csv('CS376/sat_train.csv', encoding='ISO-8859-1')\n",
        "\n",
        "\n",
        "sat_data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPsxZuo_4Y5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe8d9f8-8549-4288-81fb-d19a254a3132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [question, option, answer]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "rows_with_nan = sat_data[sat_data.isna().any(axis=1)]\n",
        "print(rows_with_nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOhNw_fxS_cC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54269d40-2806-47a2-b0f3-49076a21eb09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                               question  \\\n",
              "0    Languages evolve differences because different...   \n",
              "1    Our craving for ___ is illustrated by a study ...   \n",
              "2    Feedback is usually most effective when you of...   \n",
              "3    Think of how you developed your style of using...   \n",
              "4    Feedback is usually most effective when you of...   \n",
              "..                                                 ...   \n",
              "150  The idea that artists have a unique message to...   \n",
              "151  If we can't have everything we want today, wha...   \n",
              "152  Once a hand or gripper has been directed to an...   \n",
              "153  A sleeping mother has the ability to identify ...   \n",
              "154  ¡°What¡¯s in a name? That which we call a rose...   \n",
              "\n",
              "                                                option  \\\n",
              "0    artistic taste, group identity, intellectual p...   \n",
              "1    knowledge of the future, relief from feeling h...   \n",
              "2         For example, In addition, Similarly, So, But   \n",
              "3    the ability to control emotions, the assistanc...   \n",
              "4    however, as a result, in fact, moreover, there...   \n",
              "..                                                 ...   \n",
              "150            trade, hobby, symbol, miracle, blessing   \n",
              "151  Scarcity, Morality, Knowledge, Reputation, Com...   \n",
              "152  distance, efficiency, mobility, direction, sta...   \n",
              "153  affection, creativity, sociability, intoleranc...   \n",
              "154  changed, classified, preserved, controlled, in...   \n",
              "\n",
              "                                answer  \n",
              "0                       group identity  \n",
              "1        relief from feeling helpless   \n",
              "2                          For example  \n",
              "3    the quality and speed of feedback  \n",
              "4                              however  \n",
              "..                                 ...  \n",
              "150                              trade  \n",
              "151                           Scarcity  \n",
              "152                          stability  \n",
              "153                        sensitivity  \n",
              "154                        interpreted  \n",
              "\n",
              "[155 rows x 3 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "sat_data.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjTL_Bc8I6uT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5db043-23a4-40e8-be1e-9b33e33c1a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data :  124  test_data :  31\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(sat_data, test_size=0.2, random_state=42)\n",
        "print('train_data : ', len(train_data), ' test_data : ', len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_afwOHgEcf9S"
      },
      "source": [
        "# Training\n",
        "## Bert model selection\n",
        "Now we will load the pretrained-model. The model is BertForMultipleChoice.\n",
        "![image.png](https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fwikidocs.net%2Fimages%2Fpage%2F35594%2Fbartbase%25EC%2599%2580large.PNG&blockId=7b607dd2-9f3a-4d01-ad14-39eadb3746e1)\n",
        "The basic structure of BERT is a stack of encoders based on the Transformer architecture. <br>\n",
        "L: Number of encoder layers <br>\n",
        "A: Number of attention heads <br>\n",
        "H: Size of hidden units <br>\n",
        "\n",
        "BERT-Base: L=12, D=768, A=12, with 110 million parameters <br>\n",
        "BERT-Large: L=24, D=1024, A=16, with 340 million parameters <br>\n",
        "BERT-Tiny: L=2, A=2, H=128 <br>\n",
        "BERT-Mini: L=4, A=4, H=256 <br>\n",
        "BERT-Small: L=4, A=8, H=521 <br>\n",
        "BERT-Medium: L=8, A=8, H=521 <br>\n",
        "\n",
        "In BERT, the terms \"cased\" and \"uncased\" refer to how the model handles the casing of input text. <br>\n",
        "\n",
        "In the \"cased\" model, the original casing of the input text is preserved. For example, \"Apple\" and \"apple\" would be treated as distinct tokens. <br>\n",
        "\n",
        "In the \"uncased\" model, all the input text is converted to lowercase. Therefore, \"Apple\" and \"apple\" would be treated as the same token. <br>\n",
        "\n",
        "In this project, I will use bert-large-cased model <br>\n",
        "## Tokenizer\n",
        "In BERT, a tokenizer is responsible for breaking down input text into individual tokens, which are the smallest units of meaning in the language. The tokenizer plays a crucial role in the preprocessing step of BERT, as it segments the input text and converts it into a format that can be understood by the model.\n",
        "\n",
        "The tokenizer in BERT performs several important tasks:\n",
        "\n",
        "Tokenization: It splits the input text into tokens. This process involves handling punctuation, splitting words, and addressing special cases such as contractions and compound words.\n",
        "\n",
        "Vocabulary Mapping: The tokenizer maps each token to its corresponding index in the BERT vocabulary. Each token is assigned a unique numerical representation that the model can understand.\n",
        "\n",
        "Special Tokens: The tokenizer adds special tokens to mark the beginning and end of sentences, as well as to indicate padding and unknown words.\n",
        "\n",
        "Token Encoding: The tokenizer encodes the tokens into numerical representations, such as their respective indices or embeddings, which can be inputted into the BERT model.\n",
        "\n",
        "Overall, the tokenizer in BERT is a crucial component that enables the model to understand and process textual input effectively.\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAhIAAACsCAIAAAChANLEAAAgAElEQVR4nOR9d7xkRZXwCVX3dvcLk5khz5BzGIEFRJAMC4KCkgcGJElQWVZMLIIkARFYSQICAiIiIiI5R0EkzIBDkpxmZNKL3TdUnfP9UbfDCzNO+32/3f3W4nHnvdu3q+qcOvmcqouqCv9MTdUjYvGHoKoCISIqgAAoDEEHAhhAWHYMIQCAFv82f/NhNNDwCIMiAEjol+tPL1P/DhSgAIBGeUIAwLfMmBUAwnggRR888rsKGj41bcwGBBQBBYBUAQDrwyqhBw0oJQACZKjDi230rwg5gIAaQAQhEAQApSZIhAANaAUAUEfDypIaggNtrtconyMAcDEbUPCAKAUigQosDh/Rg4f64hvgtuingTQYOqthZAlQ4DOgoSDpvzsQSg4qIGHmDIRDQZcCHmkZBYtREAHA1xlkVIyFtW4LXt/CLxzGF9/4FJAVQAF9fUy7LGCO6L/RHwxfLRnxjXBXW+5w477WOaXxsW0HXkXIQTyIAUQAAkAFxMCjTbYtqEoAMLDXEufT+Eia9NYO/gHCemq9uyAJW8YKj7RwNyEAmHZG+F/SVBWHCq9whwAEsEESCEjho2UnCxhdLBKAAGDzs7oA1UCHbfRPGIR1sxsAUAQCbPRFdW7gFnCgLgTDAwpD4MKCHmBJZgSOgEtVAYuBFFt0BhZjKWiQI9TynWUFtd4IsQVv9SWqQ4UwXJ4Og2vprY7PURVwQ4Y2ntZAEaN2hc2nlOpK+h+jn4bOGEmojcewhdVbeL7lmdFQrYAISmG5h00bAJaAB2jMpyChIdJt+BBtwouANAxEJFABbGo0bMF72/23SNGG6Aco+GUZG7bgs8Ep0pgPCCyzsYKIQ3QGAIgCBgZrrgbWoR1VPzfmg2FFsWD5duktTAhw1EGW+qV/Nm9DwEOwiaCwpJq+QYNMtdUu9u0hCIfYAkXPxdBDeVUB6mZpG62Y8xA5HqR2mH9DaheEXcDCQ+a4BPIKvtewzltBGGU69V+awm7EM03XSrVwTNpoVJ9O4Z1pq4hrkatBhbVPzwQwRIS0iuPAUK1SIzyqoAiIdcm5RF5FaZ+7qGWc5nwCnK29BbN3SSy/RDGmHpoU2PIUtVBlmEBh+9e9jRaEABR0NQoJ4XD7fSmt8B0D+VLd0B8KxxDfHaBdfhzV+ywAGYo5bfGxgm3SgA4BR1o8RfAAFbANtaFY0Ntw1BG2YL6FokgBQHXIXEedT0Gi1Ka4qvs6o3/a2nPx/D+rt4FD9QRqXdo1KVYBghUgwBRYp/HUUq+jU0/TO9Yhck6VQnhsGfsHoFG9mUBhQXOgFp5mw7YaJnGWpDOg7qJq8URhkY2qCRqNYIi1PuzJJsOHaaMAYnvwFu63KqKijIwptOhDAhBEXbaVarDEcAZuOOOtgCMWBlbx3aA76ihein2HiNoGvACAjegTajGNVnw2TJCli4eGqyRD1whxFIkDrdY0Ls1arevLBhKGQSttwksNpqu7VjSMDxW0wHBTu7TT/6h0PgLp0CIisW74F6gXHRXZhemJEBiurfmMzn1D6a0IHykiDnU6lzCf4hmEZcf/6B2N1vMwa+yfTm1QiwwvHNhgSQFAI9KiYXUL8pUR7Leka2jD5GyrxkYFrVvIUieltvovXPrR6B5a/irsOABUDeQ/XNs0QgNDCUdAFJAKU1NlGB8PR2aB0iEUP/K55lDYNrxLHBZb7arW8F97/Q+JDSxp4vUnw0OqqNR0SkAB67p5iP7WhohvD97G0rQO3/BbMBjLxcdLimQ3/CRquRbYa+k2xPRabdmCUAsJPuQj1CaeC7wNNxOwLfzXUYbhix4UAbnF9grh/mG2Uvv00/y2Ni0obVyaOIMiRjiE6ggLlTaKmix8viXPgUbKhxGTaqJ9aBgboZAVQx9tzGf4/MONpc9n+LUR1h7mfA3ju2Hhh3+6IFVryHo0MgCAhhZWAGg7qKI4bAmKX1vCFYoIGPLk2k7CNLRRHJrhsrW1y6A2RpMLowp6+XvzafpqUCjC4jo8RD3KXIoR2mqNPA5Ca3gqxIWbMBRY+ceDQqGNDsOQ+QCADypZscULWaKR3ia8S1rfIfTTEi9q8V+HBBPqrufw65LmOYLMR02r/N2m7cCLACAIih6DqaYIwNDQz0UGHgFJQ4q47SAnDsVni5c5At66lzkcoqYeHaUtG7zDFcfIvrSemm7WFIS5jnh06fzbFv6hWacSjIxmT0tf+38+tRHAravqhr6F4vYwmagES3XaR2mo9XUXVASs1/809HoRx3QACMBtpfgQfOt0tFHSAxQyqUMiziMYAAvSBABVlRHMQAC0dKobyTwj6aeupcIHHrRB6EUasB14FRt8UPzLwIXPMsynIwCQRu5nGfv32OS0hh/aDGq3qofRxHfjCi36oZWf+R+Ht2ikSNiolWnpa1R/8e+xs9AomIOGbd4aQmkVoDqkc4EQOqn3WX+kXXihDrIr8jREAKYZ/ANXWFfCgNwm8RSdA7ZQRODH0HkrpwAEvq2vZv1+C7+MWBeok8oyTKmIDNTprdAMIw2EOv6HuUfNv2A0emt/Pi09YrMnHJoBXUr7pwtSFaSvBb02MCwSwrI67GGVNtUGFdFOLZJxWgRnGw/UJW/BG749sQKoioWLSQDBihnpbzeeDzHSQl80HxHxCiiALCigRKEfDck9AaUi0de4Ihf3w5MoqKStiqfhZQe2UAAsdIaqUmOWosteI6soyqgojXgUBQ5UaC7eUA9RRKid/oGkJdwEpKJK2sgpqAegYKkX9gMOX6/wp1cJmGllZgRQoXbWV0Lp2JCb2sxUjfIVL8NWSgUBhZRk5BVAhokbFFUiEEQDMBy0hsuNjd9UQZVABCjQYbjKPwSvoCAPscGbi1l0B4QSfA5VQAFRbWd9QRspaxQAUBBRAgCi4Z3ocBRrQ1Y0sApQYLLgAoWCtYfxy4iJhKsiIKGihJ4LpCkAADMPqXMdZUpadw0AQFSb82nwb/i/jRp0lCGaYil0NrSZJRX5/S9uqopEIh4IGUnUERKIN8bkWWaMQSJQ9d6zMW3tMwAA8KIuxyhW75AIEL0IEzsnho14j4jIJCqgSlSn3kJINazc0QelZk4GWzIzdeNMBAgB0XlhZsTiBiA47wyxeo+G0HlgMMz16DcWHQI2hP5o6TwV8cTknWMTiXgm9N4jIDOrD0F5AlVVQaDwNVQlVARAURABZuBltWgAgIABhQtHDcQJIKJh9Q7RAAF4AAYVEO9BhI2hNvsnwHrhTMA81Te5hCEFmEA9EtXSWimuCCgTiQgAEIJ3jpGAyBQx6Ebsv9FhG/RDwKAeFEDEg7IxAODyHKwJZg0igWqe5zaORBwiOnHWsnPOMIkIkhKRFwEqcvqtV2rNbDSsl7D63gEVW4jEa5DmHpQQENCLZ6SiVNQ5iJgUC9oaFknhNuEVh4QWMROHaBhJW+ZsADwgK6AKIYF6ZNtO/w1rpuVuqGpVAVUgFJFiW5EoGwoIt8YWLoF6FAGDTNRklvBLSDGF24otXLlEDAReZxhBFQggHgHUe7AGFEWFiJx3zEyAzjnDJugoDBuiyDRn0uBfAOBl1hlhLpKBF7AmCAvvHHMk3pNZGh9hIMdhd/8X6xJxnpjTLI3jGABEHBFlaRqZ6I+PP/ryiy93dlaSJGFrAICIvA+bj5Y1ycRIg7Xqxptu8tnPbZd7Z8slAPAqqKSqzAwKLs9NxKA0f94nv7/tdkJFZERt7UcERu1/yDYIAAAtigWZZhw6Ew0jE3CxCcmDigiIRGxdWjNs333z9YcffCiKrXfSGvOmuooQwLp1O/yqKsyGCJ2I9278+An7HrC/EufegWBkI59lAMBRlGeZjaMkqZZKpScffWTO7JfLNjaASZJQZBXbwKd6MZbFq4ist8H6W31uO+8dl8oAkDvPxFCILwGXP/zQQ++9/Q7qsvaPGjw2BUApzLzCWSEiVVUFE0UHzpwhiqYU594ZjgBARQgJxKnz4OXan1/NSNCaKA99FRqpjSQlI6n3bC0A9Pb3fWW/AyavvJKKojUi4sQbYxBQvGfGLE1J/LVXXx3bWFFDH+qVLbvMjar8G+WW9cBEPaCJmGfuoEMO7ugeC5HJnTfW5uIRkRF9mlvDL//5+eeffSYy1nuHSIFOpA51oCYpbOQ21heZOsZ273/QIaKCwCLAhsQrEXjvGfWV2S8//ujDYzq6xLm2+kcVy9yYGxabelAAarXajJmHlzoqFFkACnFjBfXeWzZZkrKKS9Jf3nhDHMde3Eh+CaEk//fVRLOhgiUuKsVbviUAaZp+ZvMtpm+1FYAAsoAKKBOLijhvjQWXf/jOu/fdc3dsLSI40dH4t238W8RSqbS4r/forx0n4pEtGgYafddvQy+Mntv4X6w2AMB7z8zeewBhInACKnfcfMtjDz102EEzBvr7vPdxqZQkCTEY4mVn+xCl7ewec/Mtt2y5zTb7HTbTpQkYayIbiFLE+dzFNlKXpYPpYYccfNQhBxtVItOqNlQ9sx1tlBDqaZKjoCiQIPxt/qcPPvroVddfBwQaRUCUeUEmAmIQ9Z4QX33u+R+dddaxRx7tsoTQBIc6bHcjFQwhjuD2joBOFInBOwUUQoOkL8/+y/y+xaf95IKa+JKJcpdHxgJAlmWEiKJs7G2/vOnJRx/d74v7oBPJcg5ZidH6X8IVmDlJEmZbKpdv/d1vt9jms185bKaIeEZi40W9z1klMnztlVe+Nnv2F3bZjWVZ+6dmGD1ADY1xIUTw2b7zwXvPvvTC5ddd19/b0zl2nEfyXi0jCUCWgfhjj/jq57fZZoUpyxMIKg2rmxeUdtQGJFk6pnvc4OAgM6PhS6+44qdXXDlx6ipOcjQcysdyl5VMpCKUZScefuS2W265yoqrJHli0CgpKeWSRxyN2n9QE4pFDqixzSJ1uRe4/qYbr7n++sq4ccqYAxKRgkcnhsxTDz14/VXXHD5jhqulCNJKn6T1nlG0zfUFABuVnnjm6Uzke2edpSoYxVmaMjMzg+Izjzz888svnzljhkvS2LAgtIVP8EF/NASsCJICDGbJrbff/rOfXxON7Rbn0RqPhICgEjybrLf3xK8dt9tOO3WWKpEhJhtUZJ1yGvwCdcoZ2YarDVISV+yBL3zaehYw6ihfe931hx995FbbfQ6jGJiqWR5HMahjJHB+7vvv//vXv3nEoYdGyICCwEvg3zbwrygiIIRz/zbvkceeuPqWm0EE2HpxxLaRdW9ogn9etRFAUwBQRVQQD7nc85vfPPXwYz/8j1N7F/SUSxEROZcRW1EH4gFHjROPcvUEGUAmOm7ihNN+cMaW22yzzyGHABIYduqRWCU3xKCy4MOPv3bUUeefeeaEcolVWUkZSNCjhCt6GNk/AAyjRSmSqBRXyi/OmXP9TTdcddNNmfioUs5Emdhr7rO0bOO//Pn5c/7j9J9fccVgb5/lZmQ3kAZpCImKYnPMIVYw29xnjEbAG7KZS8d0j7vl97fPfv/dcy6+KPfOGuu8E5HYRgAATm+94RfPPfXUWaedNrCop2wNiIIXRF0WTBZXDKyKiJg76Rw/9tQzz9xi2232OfRQj6Jocp9bJgN6/ZU/e/vVV39wyrcHFy1iXdb+oZn0LtSGNq1nECABLXV3PvTEE3c9eP/Pbrghy1Mbd+TiI2KX1Izo0YceeviMwzZZd920WmNU1MZ2qwaCXVvwkrGq6r1XQTSciHz930/+6dVXT1p1pVy9MqmqQU6r1ZjNYV/Z74RDDt1y+vTBvkGyFEJ2LnWljlKe5MPERGvIWxHq8AZIARGjcuXDeZ+c+sMfXn3jDd2TJwuigIQA0cN33/vL666/7KJLkt5e8FKKjHNuKPFA4T2gtAWvKma5Hz950i9+efPHC+Z//5xzBITiEgD4pPbso0/c8PNrLj73vGp/X1e54tIEoI3+oSXN26ovFUgtfzh33tk/Pu/am24ylQqXIkX2oAyaJVVI8yMPPezEY762wVprae58nmFjX8twflnyfBBIofUKQNQ4qiacGlLn38zlEyZPOebE4w8+fOZ2e+wOiB45c0lsrLp83vsfnnjMsZf++KIOY1AUxNXFd7GgyzSfUfFvSJCiUunPs2Zd98sbr/vVLbU0KXd2K1LrdtcgOaGey+TTTz99mFQtsPO/VW0gAGDucsOc12pMdNtNv3zm8SfPPeP0hXPnji13kneSZiyiXtB7UiUtmOfvXkE1sqzia/2De/3rnjfe9MueRYvX23R6ltbIRAJiiFyWDS5YeMzhR/z4zDO74zjyQuLRi3qHXlQcegXxrDiyf1JlUFIg1fDDxRWyPF1+8uSJy00+95yzv7D3FzLvoyjO88wQRca89Oxz5/3wrGsuvaxvwYLuqGRByQvXv44iLIohghzGkuJ3ql8ld6XIoFdGSAdrkeGkf3CTTTaaO3/+r2/99a677AwEQISM3jtWvfWGG59/6ulz/+OMnnmfdpdK6nLJMmsIVQmEFXHolWRUrKolFOcMoiXu6+3Za6+9fnHjjYsWL9pw002rWS22Eaq/9sor33n11VNPOrl33t9KSMu+Xg001mFXVCVREo2INfcM0NOzeN111okje+kll+y5995p7iIbuTQzosfMPPzg/Q7YZJ11XK0aqbCokfq6AJIqqUeVZZlJA171Tp23gBYJnKDiTrvs/PWTvvHZ7bYZO25s7nNLjOpZ5OjDDj/u8K9uuu46yUC/OM8E4ryqJ8A8S4qcTci8KgCEIJyyBHg1wBuADYTU19Pb0dG57ee2+8ZJJ+240w6Vrk5xnhEevf/+W2686ZILLhhYuMiodMWlrDpoEBvkh6CsygoEQqDYzvoaxFJsexcu3mqrrd9///07fv+77Xfb1asD75774zO/uOqqS350fq2np9NazFIQxzi856VcCQC8Qy8oLT9eVFTFd3V1bbrJ9FO+++29v7i3IpIxIgLeW8TDDz70xKOPXW/aaoOLF5UUjQiJNHBV0EmAAmGJc1AI1V+NKymodyAKIigeRUAEvaDXsrWfzp//pS998fzzL+iodExdfRowMhIDfvjW2yef+I0rLvrPWBWyzHiNidh5ljANJdUm/4K2R2/OEUCtNrjSCitOWX6Fc84590v77ltsWUfAUPZc1xyoRVZmuLfxD6uNpVc3/89pRQBbBcQzwp+ffPqWG2488/vfry5YWCZLTkCcqpY7O2pJQhxw1IbTl3oxkfVOcoAJy63w7R+cvtOee+y8z95K4AFAPPjs8P0PPP2Ub08oVawIi6CKahEBH5bhGNl/i+VYBAcEQQEdagYQjxnz3KxZv737rkuvuybPnY0il6effvLJN4874dpLL8sW95aJIHNY33I4dDNXPYdR/29Yzb+oF6/GMiErCCEPZFl5wsQbbrs1YzjhWycP1AbLlQ4CePje+/5wy28uPPOs3rmflplJhRidiJfckm0HnyAiRMRIzgsw1bzvmDTx22ecvvdB+2+3y04IeOcdv3v6wYfO+PdTagsXlYConfWCokYmoEJbUAGI6L0Ya4V4wLvymK6Hn3zy2VkvnXPJxUktLZXiE7/61X332HPL6dOrixZZVQPQcDW0OGARizxRG0FOIROlacoKURSLh0TEl0y/dyf/4NQbb70FDSNABPT1Y447YK8vbbD6mpAnBkREEYHZZFka29iJa6xia26DimLjYpUDKzSKjG1cSkQ887y+3jMvOP8Xv76FY/Pua6//8NRTL7ngwmpPTyRQMcbV0siaYft7UMPuS20riKQIiui9B0AlNl2dN9z2G+0oHfvNb7731tvfPumka//zstrCRSUFC+q946LeoQ18juQXAPCIaqi/lnRNnPjmhx9cdNml1//m10mWRVFECMfOPPyQL++34dpry8BgjMheub7xsLUMl7SxA7B5b+nhuBYpNLQgT1EQOIp7k+rYKZOP/vrXTzvnrGnrrOPVaZofesCB559xVgRQAcQ8j9n4LAuokJbMSn2t28APAIgIGHaqOQOVy8/NmnX/449feNmlEjYSIDdKlouDcqjInIwQrP8XOzlCteU//PX/gqagUtgIAIivvPLKrjvvPNg/EBnLBGzJxLbUUa6lNYzYgRIRskHiZbkSmbI1VhW8j8n0Lly0x667zf/bpyDgnHj1RPTxBx9OmTRx1RVW0CRR5xAIiAGHjALEo/YPZIRUeIipzKiEYIhjG1X7+jf/zGaDvX0gAF5A1Bj75pzX9tx5V80cegEvBpAVGMKhBaqkQiqknkFYhYI7A0qqLVdgJEu2FKHB1GUevAcxjOmivt0/t33P3E8hy6Mo8uoB4L333ttnr73zwVqMGBFapDzPkSGKY0UM8A67LgFe4jgS0jRPCMEiWcW0f/DLe33xg7++g5lDLx+++faXdttDqmnJY6TI2MZ6IZMaUkZlVCZlAgYiIIKYCb0H50l8CXFw8eJdPretr9VAQJwD0Wpf/xabbR4ifpExjGQIgCFYlcIqDEKI3B79ZHliI7bWqvPisrI1RnHS2PHrrLHW3I8+JgXyCmhiDxutvrbJhcSDestMqOJcKbYgHtQzAqEyArdcEVUZ1YAyhqkGYA1Bie1gb58Fqvb2T1tplbVXX+ODt98FJ7Oee36Xz+8QAZXIsAirWsORIYKCeMKPEAiDMAK1t75eBZmYiQnyNNvh89t/8tHH4N1zf3pmx+13IIVyFKs4ZkImE9kl9T/qVZGH8QuSIikhuCzvLFeSweo6q685ptIJihaIvELuO0vljdffMB+sRUoRUNh+aJCIAML+EQNgQCyKoWI+4Wcp8wk/hELoC9pQJQ08iAQEmibVSqmUDlT32nPPZ556ChEMmTfnvLbxehtMmTCJnMTIxqsFitgwEYXJMCiDMohBZWqT3qhsI3I5A0TI6WB1889shgAgsnQxXqgNVQ8gAALqwx6Zogw+3KybKCN70sZPyzDa0v6fyfv/R40AGSlEZgEojmOfZ5YRUXOfi3pFyPM8FMYys9dQqqfDrjD0d5ACalTI06yjXOZgmoQopGowmUUElWI2Pk8ja0OZBygq1c0GURFRAQUZOSLWt5IWmb0WXyHPc1KJmXyalEoxOGfZgAh4393dndaqBjRmwmCWWvLgixUSbCyWaP2gZhQAIBBSCMcGiToAEOecc3HJqqr6vGxtZEDzXEWAI1QiJe+kEpfSpJol1XJks1qCCFFkACDLMpSh+CwGHgXD4ZM0TwCgVKogYpIk5XLs00Sy1CIhG0CKrHXVquYZE4adhcP68aBewUNxB1rWztd3+tUxKQBQQCEQRVEUWfGeVKxAlqaoAN5bNqC+s1J2SY0RWEG9B5BGVxJKN1EUwQF4baygBKDCfBr3tTkftVHJOceAqhJFVsR5lzEBgYr31kagCs4ZpDKxZikjIaLzmffeMuZJWkDS3OxCdbgEoDAaWw8cDOubu7Szs0N8Xi5FmmcuSSvlMgh2lCsuzzXPrIhBdC6LDNXSVFXDphxRDCTkVX0AZEmrOdr6ElEo5vTeicvEZYQAiLGx4nJWSZOqMZy5PIqiMG4rzTQwOSo+tc4vguBpiK8QcEsgJN67HKpVDgoC0efOp0nMpOLyPK9TlW+MDIKq2IB4SGtQNUjzDkj406u2UlooZglLQ0SI4PMsjkxtcKCjoyMw79gx3Um1quJipjypRZEV9V6lPnRAPgpgGMortFL73+WvPM+ttSDCCBFTXqtKnjVOQqO6hsChkQlSAOcyBQeagU/fe/utnXbZJQUYdCIAkGfBeHGSZwIOQlwOVMG7UOIJiVMB+PDjjy688EJE1XDEJqI4bd3u+D+kqYKqGmOKPQ8AJMpekQCZsNh0I+qdIeOcd84hhSJtFfXEGM6hQREEVRBR77OMwxY3VQE0UexyDwDMKuid5MCg4BGQhIwyKjFSludBgimxAikhExIIISBBMOcjExOw8zkGH8ADAWuu5JGUmK0iZU6ImJlVBJ1YJK8CkfEqQAbYCICKGFBxnhBylhScGgBSAo7IkCAqGTLkwaBBwcDPBhC9EDB4QGDwYNkysHf1XZDiBZwnp2wACJVA0HCkuSd1kSXnnLXWoYoIiUZkrTHhPAxi9CCFNwOCBCreMCEoEyKBFwcohlgVxSsAGmszl0eRQVEFAjXBgSYiRgimnANRAiIiIlEvqAISjIXUZdawJZI8JwQPomHrlfcRsQFVEUIDgB5AEHPUzGeIYgAsoeFIAYENEAJT5pxBQu9YFcQjooCyjVQRPICgc6JIHsGDEhETonpxuQdBRjLspDiMtogdM+XeO+cBjQdFwylIht5E7H2uqqZuf4BlYfDoiYAUxAObiNh67621AgjIAt6DMhlxAgCMxMDqwaARp5YjFTTKJFhIBqLcOwAAL6RgFEEUmB0QIBtQVMeoiJiJB+L6y2O42PrswyH5AoxKoARQrC8IKjACYy4u/CKoHsSDhBfdhB1FkbEESqDMDICsSE4YNGISUGRO8zwyRgA4YkAV9WjIq/egwAQEXn0YSwmBiRgZlQRZmciIIgCBBzKRgHoVJVT1wU6COFZQjxrWNyKEPCdCohDPVwAhEIPEaCAXK2SEWAlELROCYxJCUBEkABBGQBUMtbHq0SCgMgang/PUxbYkCqKoisjGq2JQXCHOKRBcmyx3QERKqmosO3UOQJk9khMwZBiMc56RCUicKILXkDNRJXDqwhIQoxcXikidcyJCjF5FmTJRIRQR4zRGNswQSocUqL43BAISGpaICLAxhIFZVMW/8847iDB/4cIsd48+9PCiuR8DQpZl1TR95dU3XnxxtqqKg4ULF9VyzRV6B/prWfboI4/fcfvvXJKqCCJmLmdD3i+pNO2/rTU33xdxT2IBAhURVR90JSJaa9M0NRzF5VKSZQoIhAKQOReOmvCgigBEAlDqqHhQJG66ZiFuqwogLZWdBdrDBBpxSUQMpjSAIGrunRACoiIkWZp7iUpl5cIoIyJCE0UlAEiTjMkYYyf2VpsAACAASURBVJ33oZpl6NECBMUer6LWhYpD60RRFEUJvZc880BcLldEAI3N0hyIwreqSWKtzb1ja4nYK2R5HjYWxXHMzFmWhd4CGIXmUKBir1RRKxKuqIQKzjkiUhCvqihRHCODB+9EbBw557z3eZ6rahxbbdk3WwerxX/FAqONSKtisdUmy9PgSAT9kbncq5RKpSzL0jSN4zjP87A1RgnZRgCQeaeqzjlRJbY+WKaEQEraNNygJZINKAViA7rJ9A0M+EArSNZEqupEnUJ/Uk1cznHkVUSkmtTSLAPEWpYmLhfFWp4556IoQjKERkRFBAiVsBUJBfwInortiOEDaRybr6oIxIZNZKNocHAwisu510x9Lt7ayIkAYZpnoTfDkXcqIo3aqgaVNlAKAAQ49Ax4sdZaa8naXLTSPRaNVURbiqXegoQiw6rqxIctinmeh41QRISIItIo79TiZWbF6AQFYhE0uNchEWuIBgcHVb2Joty7UqkU8ENsolKMzIoYxhcRVYyMVadZljFb7z1wI9JQ5HeaiEUCrR9rqxBeTFL4jgjIRNbU0jzL8iiqOCcIJCJkOPdOAXLnBDTsNo2iKJgFXlSRwqBkjFdwzqlqHJf6+voBAIKz6NwwA7t5ckF9PlSvBPMIHgGZgLBaS3OvURwnaeoFADnLPVrjvNTy1KsoQJLVvEqSZU7UxFHqckFAw2nukHlotqa5radRmz5qIyJw3gGAz1x4rxYReYUjZh6+3Xbb3XrrrVtsvuVfX3/95ZdfXn+ddc8644cnHn/C0UcexQy77r7bX995CxBO+tbJt/3u9sceffSVl2bdf9c9TCZNU2usIpAdJXfy39yoxdtqwZElttYGwREInQx7lYEkLXV3Jc7nqkqkRGDYgQKhE0mdA+ZqllWzLFdA0/ZhLYgoeeZd1tFRAZRcBa2tZlkq4lDBsCOoeV91uWPMUDLnlKinr59tRNZkWUZUP+wJlrjSgeyah/NI8AlJ2STibCm+5fbbXn/nnRxRrQ3HriS5M6WyR8pVM+9rWS5IaCOyxmsIVjm2pl1/UlUB0RgjIs65Rx9/zImisR6gP0kyUI5jimyWZSLCy7Dlu3X8IGgsUqVU9rljZieS5c6aSJwPQoqjKHGOrbHWAkCqmgH0JVWyERoLhsBy6p2ANjY3SLAAcPjGWAybIDGU6qKIdFYqxhhBSPMsqMAxY8bYcmXc5MkSRf25q0wY3zm2e/zEidZasmbscsuVx4wxXZ22o6OWJl6klqVAGAIcxUnJIlysMI48uCKc9BVOIBEsMrcc2bvuvW/WnDlxZ6XmElsqiTEZaKreqToABfSqzosHRUQTlYrVGbaaOMQQadglQVLffc89f3rxedvZ+eDjjy0aGOgZ6LvmumvZGiAiY5A59z7NcmQGpKhUStIMiJA5c86JmCjy/1AQuxKXkG2SZYg0OFitlMsvvvDCk08+CYpZ7mtJAoSFNCQeTFMhImSXezIWiZ14IEIFbmhJLCANdtbIw1EEIHW58z4ul4DJgVIUV12G1ihT7pVsxFGszJl6iuxLr7z8xtvvRB1dam3mnfNeAXIRp4DGCIBXKVXKguCcM8YQ0ZLOkqrrThn6qaYuJWNMKXYgqcsrXZ0UW1Mud4wZ60RLXV1jJkyIOsq2UolK5VK5Uu7s7Bo7LneiQICsCGTYq/5jdr1J0zyOI+9qHEXgxYkP+2Pnzp37ozNO33v3nU45+eR7779/ux12IqKbb/6lFVh99WlvvfWuLcUCWs1z7733/sgjDq/29Oyx117gfRzHuXdARp2PbBuHPfzXN6wrVeccgUYmdgBsKMuyjz75aMoqq8SlztlzXu0qV9Zaa40FixYiqlNjCJlNUh3867vvrrnm2h1Rad78Rcst3+FdbutHburSXjbabCG2a5DEuTxPo3JFOBo7ZhyS7+/p4XJcMnGqvlYdEBCD7JwX8Z1jxoZgYcEhuUemepppCCWgNk0VaPlMVb2IGts9Zjx3VZ55/rmOcRPW2mA9l9TKlQoz15Kqz/IsTymynV1doZqxNlit1hJrCJGUWGn0lzcspRlra1nqU1fp7BjoHXj62T9N33wLURg3bhyRSdM0z506H5VKqt7nDg038DjaDqMRd0TzPEf1zJjmrmvceLBRVhskxNjaRNPE5eVKZ5on5Tj65oknfONb315nvfX7FknqXUd3t7V2oHcALYuXIqYdTkop3vWAANJy7pAU/yNAPUw/WKud8cOzN9h043323quaJmefd76NS17goBkHict+cfa1E7vH9i5etN8BBzrR3/3hrnKlc8011/zSXl945NHHn3jisW/828lTpkyJmcUHf0wViLBpjmDjAiAIpp6HDBUOXoQQmPnZ55/vr9U233Ir8H7B4l62JoojBSh3Vky51LdwkXoRwCTNSnGUZRkyNGxtQSgC5gHG4heCYsc7IIjpqsx+5eWV0myTLbd58k/PTllpxVIJ73ngwaOOOa66aHF391gAWdTbN27cGGPjLK0NDtaMNQpU7uooC+ZZUq0m1hpt6yhPAVVvIgvMnZ1dRNjf00NEs2fPzp1sv9OusTGljg7NE5dm1YFqOS53lEsDAwO2FLs0s9ZWq1VrrYgP8bGiFrFYwWZGFwqbAKC+6TqKy4Npkrtalkt1oIeIShVry5E6p4yfLlwkXmtZPnHi+Bjh3fc/sHFp2rrriUVTiioxg8jCvmpcLie1wbHdXcGG0zwTotyLigARtMiLVpygAoEgiBSHmSgARFH07nvvXHzpVVtutdW+X977yWefvufu+yuVzkpnxwknnHDTLb9+883X48io6klf/8YNN988d+7fjDF77fmFiRMn3n77He+++/bZZ58tWbqsqB/aTBxbL94Yoy5DNkSUZVlEaBCnTp2K1sZxzGwGBgY++9nP5rmLjFlttdUWLpzvXAYAHdYiapqmAwMDWZYBonc5W6uhJPF/sM7QlhcuIoAhRtQkSUqlGEDue/CBO++69yeXXXHyKadMnTr1o3ffX2/dtTu6Ks5lRx/x1b6e3rfee+/8H1+w9Tbb/ujHF55x6ulnnnPuITNm7LTj9prW2pqGFxfeeElEtmRn/+WVRYP+r2+//c67b5xw/LGvPvPMgw89tsm/bLnfvvu+8sIztcH+rbb+fJIk73/08V9mz9pzzz29y1yeh7APNeynJpCNGlAAAAVSRC6OObGZ6KK+3st/fF5HR3lRbx8YdoCJ81defMm8efO+/JV9Ntp4YxBZ1NN33kUXqeLUqVO32mqrVVZYngCSJCnHsXMO2lxhL84YttakaRrH5c033zyqVHInl1xxxQfvf7T66qvvt+8+lcimeWZAS6VS6vLWr+Pfe4UuMpEiGhSBWpZecu6PFvX2bbPNNjt97rN33XXXbrvvweXys7NnAcikMV3vf/ThTbfe0jV+/GH77Q8gV/7nT+fOnbvbTjt/ftvtNMm0XtE4DKs6RFNKKD1lRe+9IfTel7s7v3rMsZpUTzvpmzOPPGrdjTd9btZLtrPrxReeX37lqSed8LV0cLAUl3/561tXXHXqfgcd9J3vfGfKlCn7HXbovHmf9A8OTIH6+7Iar3nQejilZeTWo35ZAZGE1IuoCiLGpUqSptf87PK3331n5pHHj588Kbb83HPP/eHuu8rljmOPPqaroxO8mpgACsNzWCqyOEqsJYgD4Ty1UKKephRbW67khJtsufW4ycv1LpprK6VMFEulm3/724022mDdddd/9PFH77zr7mnTVj344Bk2jhcv7Lnop//Z3z+40UYb7L77HsyMed7YTdbE69D6miKMqwCqxpgnn/4jd3U/9sTj4vKjjzyiq7srjmNh9cS/uf22l2a9YFB33mHHHXbY+S+vvPrBh+/ttNNOWZIuXrj40Vmz/3WP3arVKtfd2MYewMYRU1DPAzcXXdGD5FlKhicst9xvf3P7tFVXe+KJJw7/6syB2mBszNjJy/3+7nunb7bZvfc/8PUTjh/sW7zammsIRpmHu+5/YMXJk+7/w+9WWGGFGV89pj9NOysdV193/fvvvjtt2rS11133Mxtv5L1HaR4ZRCOMzbDuBNrQGYDiRHLvVllt9RmHH/Hhh3+97hfX//TSK3KPf/rTn4Tw5VdeOfCg/ddbZ93+/v6uMePmvPbGIYccWqlUzjvn3EsvvfSwmUecffaZWe5FlIlGtceW3ki1OP8ImPI0IWPjOHYCnZ2dzjnJMhNHaZpWKpU5c+aUS0ZRP/nkk/ETJ6jz6EQBPvno4/FjxpLhUqUMTMgkIsYYQsjS/O9N4L+5NfhCVbMsi6IoSRITRf0DAwcecvD9Dz6w6tSp3/rud8+/6MKpq682kKQCmORZuaPy/IsvdI0dM+OwQ390/nmV7jFf2W+/apaFM9G0HQNcEY0xTJTWqsw85/XXzjv/wmlrrLPxxhsfethhb73z9v6HHHDDL2/+04svTFxu0tnnnttfG+zoHnPZz67sHRhEwyFQy8X5cdJSuD0UzFC50aIm1Ytz7tgTjttw0+k77rzrgp7FGBkHeuwJx4+bOGn/Aw/60XkX/PmlWb21wa+deMJa6637hb32+t0f7nzj7beiSkea5iGm3Hp27DJACooQ4hIhG5wkyU8vvQyBf3jm2YnzM446Yn7Pog8/mYtsiI0xUVKtUcsbE5clHpbnOSImWS116dHHf221ddba+8tffvWNNwaT2rU3/CIF4Urljy+88OjTT49bbrwyTFpxxZWnTosqHd/69ndWWmXlmUd99dobbnxp9stoGJvlJEWtoHofXqoKikXZPkqACw2jgvqcGMDYgepgnucrLb/CnXfe+dTTT0+dtvqKq04ljmb9Zc71119/6aWXvvHGG1EUdY4dO3HyFBuVPKivDTqfAwCScQVXIpOh+smJo2NVNRxA2JC64d+4VLn/4UemrT512rRp3z/9tM7usfc9/ODPr7v2kENnrrn22qefdSYypS5XxTQbwqThNJSmAkEBUkUK5WFFCk0UUZ1zqXccly772VUfzp1nS3HuXKm788cXXfzSy7PXWX+D397xu1/d+pujj/saRfF/nHG6sjn5lG+tuc66++73lbfefa+/OphkmRZbbQCG5lRaW1NzqZpy6Z7777v0qqu223XXjnFjvnPq94Ewd84jpd73Z9m+++93yGGH/vTKy599/oWOMWN/esWVvYMDcUflV7f++pN5c5msjthe1lDALWqziXBfSGpM8uyqK66874H777v/wZf/8srdd9/d1d1dy9KfX/mzx5544vY7fv/Gm2/ecded4yZOvO+++5798/O56lXXXnf3/Q/sv//+c+bMufFXt4yZMOHU03/w7vvv7XfQgW+99+69997b2T0mTdMoighGD1IVmTuVuoYrpkhEgkRsBqrVckfF+/zmW259/4MPtv7sZ+NShSN71z33/eLGG2646cYkS8nwuAnjJy43KXUe2KQuz0XjSvkfrlgyiGCNFZ8CoI3LaZ4tXrzYECyYPz/Pc7Jxf/9A17hxkbGvznnl4EMOm/vJR5ttudnKK6+84w47zDxkxiabfWb2Cy8uWrRow7XXvv2OO+65757ddttN6y8biaM2jqv8r2kKTbOi0cL2rlBjgIgQWWNMtVr96OOP11h7rQWLFkqafWG/r1x47rmdnWO89/39/QceeEDf4MD+Bx7Q0dHxnxdd9umC+RMmT27jncLN+fg8d+SRiEwcDwwM7Lvf/rvsstviBR/e+uubjz76KI7LW2y59V/feudz07+w/rprP/n009Onb/He+x+ec+ZZ/f39DFqyVlpN8nqqX0AYofWszcD5wW611tz78MNTV1vjC1/cuxzZ9ddfP8uy1157zdj4iKOOzGvJwTMOuefB+z+XfG6FlVY+4KCDxelGG2+auTzLc2NMUq2Vy6VRjpofrbXKPGLIXR6ZOHM5KI7tHmMiW02TapIlaf7vp3wHXJ4ODnYaQ14iY/yI3kYKl0ZcWMPhHOAq5c5bbrt16hqrf+XAg3r6Bj+z+RbVxZ9WxnTV8rRsyXZUai4Zv9ykKSssv/U2n91g/Y0ff+D+WjVdccUV582bt8Zaa959zz2f2XBDwRBYFsAhpn2xcNrM+SNSlmVdlUpa7RMRAY3icrp4wXHHHXffo48+/PDDl1xx5Snf+z4zr7jiittvv33/gvkrrbzia39969e33zHrlVfXW2+9zTbbTNSHAjYIm7A45CxCcWUz8d6cANZfloBKWkcUIXoghZ7+gYMPnrHjrrtuNHfubfc+kjl37z33f2aLzed9+reVVln19dd/Pn/+winjx0vmrLUq9f1nw0QXtsY8qV6HKQgCzMwc6ge6uscCcZIkXd0dF110kSnHp3//uzWX3XH3H3bZZZf3P/lonQ3X/80dt/cM9vcn1YV9PWuW4++fflp/fz+rQDpyhRvobUmrhJsAwCzMhxxx+Mabb7beBusefsiB8xcuwMikiedyedcv7HHfPXd+Ou9jR/DR3z7d8rPbrrHO2g889OAeu+/5x+f+/PPLL+/r6yuVY5+7VhEw/BixerlKK91aa8Hybrvt1l+tbbT+pquuuuquu+5Sq9WiKNp6661qqV9znXU32GTjTTfe0KW1SqVCRGSijq7Ok046aVKH2Wuvve574pnFPX2zZr9y9113oujOu+z21JOPBws7y7Jw+O7oGQ6UevDZNrxf9QJevAoyE+C5Z5/zh/seueaany9evOjqq69GxPXXX3/NNVfPsizQyUUXXRRF0fHHH8/MeZ4CSJqm//DubFPUazADqIqsscYas2fPVtUnnnhi/JhuBf3hmWcq4Qsvztp9991P/Y/vffTB+7vtvIsK/PiC8x955Im4XPrZlZfXarUxnR2PPfG4iRiJFEhUwAGHU3z/x1XhjtJCAlYBvVefJCHfu+qqq85+5ZX999+/Z8HCM77//UmTJqD6jq7Ojo6Oq6+4Yvtttz3x9NOvOv+CX9xw3SorT02zfOQh/n+3IaIxrCKW2GWJMaZ3YKC/v985Z4gH+vs7ybosQwXL/K+77/rr39/T01udPn26EjJbUpfnef29RfViyhGtURBSDKoAbBYtWLjCCiskSeJqNXGeFAYGBjo7O/Pc9/T0dHZ0J0nS2983efLkarVqOAp1XKGHOI5FlIj8siXVGrzgvQ+BUGMMqGZZliX5aaeddvlV11x88SXz53964Xk/Wmfq6ulgf7n+6qm2moTD2cimaTpxuUl9gwN9A9U8z0lExLO1SZp6UCeKiFmWVQdq1Wo1q2XVwcFnn312oFaNbGn7HbYpnAxVAEXGRhs5IIQcA3OeZaEWznlVQu81d8mXv7LP/scee8sNNz/+8CNbbrH5KiusuOYaa8hKKxJRdaBv372++MUvf4UABhYtNGMrlqlRr2XYCnjvPYx8BUcrYsMr30VFFRCQFIUAkclUq9Vab5/LcoOsggMDAx+9/8Gixb157vfdd9/Ozk7JHQG4PGdmKl6IVC/2GyIzRYY5lKIAmNaSSqmsgnmeM1Js7Dtvvd3TW9t5192IqFarOede/+ubb737jvd+n332YeafXHLxzy6/4qGHHmLmn/zkJ5XItlVDoqqSZWRM/8DA4v6BMisgZlkWSuoXLFp46MyZn99u6x22227hwoUDtWqaZwcffPBPf3pJXO7YYKMNJyw3Ka8mtVq1FMWgTQ+uqGwEQBQe+qqiRmGCKr7917cffurJefMWLPzbI12VjnmfzJ06baWXX3rp8ccf7xtI3//go7GTxq212qpmygQUr16CA9E/0DupNE5dDgBpnkXlEhke6OsXkczlYfOFjazo6OoTWjCv9RwbACBiFEXqhRFdmlVKpeOOOZbHjjtmxozXX5tjiTebvslKK60k4gxZy+aEbxy36qrT0jRN01psLBGBF0MMS3Zkl9IMNd5vrgBETGbKlCkAOGXSBAAAdaWOTkQ0xixYsGCttdZae+01nQoLKuLnt982GGKdnR0KuuWWWyiCqCgiI2EIEP7Py26ErEZxFliImqoaY5KkWil1OpcDQKlU6uvr2/eAg++67/7vfOuU9956e5edd7SWb7rphldnzV5h+ck7fn77737nO9O32OLNN9468/Qzn/zj0x3dY8TnOGqEClHrL44PhFi8FUqVkL0XRlQVS0ZEypFlJBS1xB1RCb2UyZbIpAPVrf9lyxt+dedNN9106U8uyvM8MsalmTVGxdU96SJe0RoqRqZhIo8QIXfrrLXW/dddP7arOx0c6FmwMEJed8213n/vvf6e3inLTX76qadWW3Xq9E02/dmlVx595FH9/YOvvPzy9M9sEkVRMjBoiIBJVAI4qi1eR+A0aiaOGwgvTEgAy+EEL42iSETefvvtH/zgB1GlfPwxx7z4/AvrT12DrM0Ga6XYNlaqDp36Ef6NtgSmEZGRfJ6vtdZat1106Te+FY0fG8//29xxJc5qiYhYaz/99NOujgoii9PIcmzsmqutHpP51kn/Zsul2mD2t48/UufD6yXCtBWLzBBg8xydlpC7IpL33tRLv/I8r1Qq5/3oor6kNmmFlV/+y2tnnXPuK7Nffui+e2vzP1644NMDDzywFEeDtZofHEydKxmWPFORcJgKEuV5biJWVQpv2aNw9GBI04s050BeBACYOfOpgpQ4ApHIGAZkBQJgpBLHKy+/wmqrTT32307WNJ87dy4oWGt9lhtjEItzSECb0DXeTlps4EMQAB+OYyICl3eWKy7L0UvZRiSeFFeasvzNv7ntS/t+pVKKjzzyyAnjxm660YYHHXywinz44Yfq8p6FC37y4wuI+Yt77/3OW3/9zMabQJoNC+oiYgO5XovqNS/CwIXhIlKK44njxs+Z9byKX37KcgBqjPngvffHdo85++yzB3sW3XrzrzrLlVqttv7663d3d593wfnXXXVNlmXeuchYDOXEhKGo1zIXNQWggNB6bkpjlX3uVps67Y/PPbfjtp9/8fmX9v3SPl3dHT7JVl9ttdmzZm3+mfWefObZvfbYc+yYThAVn4cdmggSIZMKijeAEyeMA4AHHnhgyy3+5eGHH650lLSVTxED4zZZNbxTEhE05MPrn4oCiM8dI7FiVh0844c/WGX19dJMxnZ1b7bp9F//8qaf/PiC8ePGZVn63e9+z7ssS5KBvh5rLYGAekNgGF2atvX+m0ZrKHtS9A2PlMKLrdQrYHhXzCabTL/99tsYUcEThBe1Y8tb2TXIRWx9nT3+f+BnhNNVkcmFbai1GiJwqZQkyScLFtaqA1dfcfmcOXMmjhu//ORJtay29x67o3dZlo3tHvOrm25885131/jmmpGJ35jz6nobbWjZ+EJy1/sPLbxjpzgaqKDFRul6bG02WCMGYFOJS72JWMbIUMzGJWnZllilZJgBu8pd/7LFZrPnvL722msv+vRvphQV+9rCnm7AZrqh8f5OFSfehzeKFW/AAVHN02Srrbb61R/unnnwjCmTJiYD/ZZ40tjxMw+e8bVjj540YaKq//dTTiZjjv/acSd9/Rtrrrn25ImTGMk7Z4iZKRcHhT5CIgICrO8dkPrhBGE+QW0ETIQ6PQBAVUMcsamUottv/c2FP7l44sSJ4v2eu+1eqw4Yka6uLu9SCK8LrbPXkJhYfYjmHVFC9F6duK233GqH7f4y85AZY7rHi8uuuPjCHXfY4RvHH7fiqqt92tM7fZNNxPkv7bX3maedvsa0Nc743vcOOnD/L+6192prrP7O2+99debhu++ww/+h7s2jbtuq+sDfnHOttc853+0e78Gje4iAigpiWxGbqFQlRnnYoICaRC1TUagY0UKNEQ2oSJ6IwR4RTalxWOWoYRMpjRmxxUSHTRQQg1Hw0T54vPbe+51z9l5rzTnrj7X3Pufr7rs3SRmyxhvnffc0a69+zeY3fxPTRdWeYnA7QeDmTiCww+EhhlprKbrdHN7zvrtvXqYXv/jF77n77vuvXH3hP/7avh8+45M/+RlP/3gd1sImEj/syU9RD6WUZUi5X19er++7754YpWoO5jwFLWI6LNp5yhTATCTubmYm0u42a2qHi8NrsS6EyJJSJwgH3WJ9+cFv+vpv+OZv/qYv/cLnxLTIw/D93/t9m8P1ucXSrY5X43RgMUBKqoqWjGeyvPr8HwEkUUIkTkznu46qddxdPH/Bh/Ljr/mR53/lC2571CNf9tJve9GLvu7XfuVXDQqjV77yFT/wPa96TQru9OQnPfHjnvo0y4OAnAjkrQtoBrqjzHgjKZq7mUEkhfjjr/2xf/drv/bOt//lP/k/XsTEy5hqto9+ylNvvfnmL/jcz7v1pktX73+wk8DmUfiTn/707ZA/5Mkftrnv/qVEMlMtiOxwa6JMC+Imb47pfQGrLTp3l0ApRAY9/oNue8/b3/2hT3zSvffcnVgOLlwS0OMe8+jHPvLWD3nCBz94/70gPrc6CFGi8ColuJJrF+KFg1XH4Y6Xv+xVr3rVL//iLz360Y8uJYvIGOYyLrNd/A3cR5WX2MdRmpage4yBHJcfeOCeu+++cO78j/zwq996510xLR5922MPLz/40m95sWrtUso5W613vOxltS9EAoNWe+/73/fgPfewWzjtznB32Ck8WvtlH9gnOzmOXIjMiJm1VABdTI98xCPUNExx52B37LAXszQ7evoBYUzH1AdiaQuiHXBtRYbQMvvR+sEHP/VTP/VXf+03tNTL99/3YU/4YBvK5vJlIxBDQKvFst9uq+qHP/nJpv7gvfc8/rbH/s1P+aTcbyKNmNR9oemYkWHc8GZtm9Za03JZSl/Wmy96znMtnM/bTWD6lz/2WlUvm/6ffuM3bA6veq7g+MY/ecOX/q9fsT68cnBw0G/XnXCt1VV9nBeCs7NDQLURH1M7fWYTU5PNQ4p93/+LV3zXu97z7ovnz108d36onjfr5z778//OZ/6tw8tXHv2YRx5uNu72t5/xGZ93+zNF4pd92Zc9+UkfYkMxXt+WIAAAIABJREFUVRWCWQhp0Dru51lQ2uty+18LrG/vRIl93ys0xrhcLn70Na8Ztv13/fM77r3/vitXr37Q4x6X+yGoCvO23xK5B26S4Dh2vBvUEbN4dGy11uVyMWyvrh88fNE/+povuef+PuutD7/F8vrrvvqFz3nfe7uDc3FxEITWl68867M+++mf/OmlaAS+8PM+92995v/ynvfe/djHPi4Qk+qUFH20NjcJAxQiK4icCSxOJD6myi2lxCAXLlz4lE/65D/4/d/7rE//tMPDw0c+4uEPf/jDt1cuJwnu7pYXXaw1E1G/3XTpnDBrKeeWi9/83d966lOfesvDbmZmQNnHRMWKpmq4wfcBP61NUzLjkfGAyNxda33R135dKUPZDOdW51/9Az/ABHL6oe/9/ne9//25ltse81gv1bvOzBZd1/fbKTnrbsUyM4jJuckGzqMAYC4ELYeH//sLXlC7g/UDD3zvK7+bvbKuv/97XrW5cmWV4s//7M++/967z6X0E6997Tvf8S6J8phHPWazXf/Uj/3YO9759i4tHvmoW9eXD2MIRwWpUzYLJvnUmcgIuVgevvLvf9lTP/ajLx4szi3S9srV53z+F3hcoOQ7XvLSK1cffMTNN0WWfquitlwufvff/4cvfPbnq5aUkhXtQmjHtBF2OjpxW7q7R45yHtgBQukHXvHf++Iv6brl42593Pbw6qWL5zebQ6v1737xl7jjuV/wbB3yxdW5/vKVv/tFX4y4HDbrH/uRV1veWtVP/Buf8Amf+ozDB++/+cKlH/3hH+piesUrXnHx4i1aynK5nPDTI5B6ksMYNGdLaAHmbXBGc8XNt9z00R/5lD/5gz98xmf8jbzePumDPrio9YdrEQpRtJZhs41RJMVhsyVHCGRm/Xb95j994+d97udqrSkEn/LQjd2dd9aZNjPgZC5xb1RsIC21QTikZUogylokRG4RqU0336VzplkQnFWQ0R7xgVpmQcYJ5h5SzDUTxNWI6RGPeMTzn//89baHuecsQJCQraSQrCrchKOEVPqBmS9duvSV//AfbPtea3UmTJKRTyI2Jrl7/+nz9jBQqRUsjfOplG0IQViGoYcRC/WHh51wLfXOP3+bkH/sxzytbgsHThJC4DIMXeyyZjhPVyDaveQGF8yqhquBSeEGZzMQ523/sEs3senh1SuEEIKUnMXtkbc+vN+sEzNAL/7Wb71y5Uoe6u3PfOZtj3y0W10sU80liJRSmt0fOGL8pskeNb42She4uw/DsFgshmGoZjHGUnJVc/dVigePuHX94JXVsmMhKzUwOIRiO34dzNqbj1kLwTtCrTbCXddpLma2OlhtD9erFA9WK9SCov3h4U0H5xVOqqUfOmFXu3iwIhKxevXyldSlxz/2MX2/5ZSgTRgldwOmgaVRl4JVMzX11gSYOxGLlFpiWjz3C59di1neBuFaq1ZjdQlBRHKGZo0hVrMUOmF2I2KUMnzmZ31W1bqtRm4Cd/KWt9hU55E8YnuEkLBbi3luLMoOkDvUKpgJZgatRaJANbBs1uuHNQzC4WHHIYp4LcPQM3NteeTd3UmddBpwM5iiMSopEeDC5JBmR7WhJI5UimpmdvOyCIta9f6777504Xyt9er9m4ffdJPEcPWBB1JKw3r96Iffqqp1O0RmIVKbNFFzc5rl7lmeax/NdxqIbrp46cJq+fCLF63mYb1ZhaDktZRaa2I87Nw5qVZKTqHTWt799jt1yH/zUz5lu14vjZPweGfAgXFfWNswjmbQbUvJ4FNgIwFIKdVaAe43W6HgqlY8MIUQhmFIiy6xXD3cLBeJORBprlUCaa5UjTtOKQ1uF5ar1/3iL7zuda+7cOHCLbfc8oKvev56fTVU70L0ZsVuR4e7urU4DW+8W07mxOZwbZnArNYLFy4873nPqVpRtkq8WV8NsVvFmOtg1YLTqKWpCaFxFrjj0oWLn3P7s0Rku92UUqRt1XEKzJud4KFizsLoSvVmydxt/WZgdWoRNkpEMcTN0B90aVy1jpZZat8Q+AGtX7TigDmEjmkDtRZmhlEMwaFkdnj5SnUIfJnSsN0uFgsO3VAyzLuYVHeqdM3ZanV4iqEtNW5Zt47K3cC+MDfKFESstZluKgORhZlqLRzBzCKRSNzUzJbLxWNvu+1V3/MvytCLk1cV5kbhYGZMk4V68mQIEWC0c6iyQAhE7BCows1hNQBgWnarUqrBSLHqUs1DCmMS4x941asON+sYO1WttZJ5hYKJRAiKuXd7096MUU1+hDtzW8EEgCTkqrHr1ut1t4gAUgy1li6EWsr55SLnnGtepMSMoRYWYeJZq2WmllN7PD2psbA02Z+ZqNTqpsvlQd9nktAFKbW6IKbgWhOHIRfivAiS85BSIvUYSauKsMPY5WCxzDk3vlIaKXlIKDAJkbQrZOwyE3OQRj8CwBG75WazodJENVNVYRbm1UEahiEgCFGIKecsKZqiqjYiKTI6vHKFgoikWiqRRImFHEzactI10xCPppz58mAWIliz8TgxMxnMUYbNcrksm00Myd2YAVUG1VqMIYQQuOYsoMaQQQwCj6yau4lkAtMeJMAYBnZ4roU4RIJBBSiuzEwQM7Oqly5cyHVKZOnuaucPzm23W1VdLBYgzv0QRUopMabRDEg+b0gwgXnnk2tJu4nhGIb+BS94vnMgrQsRdRuGIaVFAJFbkKBwK5pCdEeM4aaLl77nu19hWrsgyXlYbxeLBTEqzJkcRMxg2oX7Tar5rG2MLhCraEuMg1UnItXSdV2fc2OX2G63q8XSobVWEYkx9MOQ0oITbzZXRSQk3l658txnf/5zn/35Znbu3LkHLj8YJZCpudKU1d5ngdId8NFQSY1hV5vxwD00FpN777lnsVgIa9V6sFhlreaeYqy1pBCJw6hLuDeMaMuZuNmsRaRbLrbrTeq6UaRl0hkHwYwjXDLHyylABkKjwB2FOybmEEy11LLo0uSiad88Sid/FO6JD1RlY18LHu92OAUpNYtTizFWOEtatrOk1sBSSnHhlFLNtVYNIRStKXZD7hsyoZTSICVAk+dPG/fJPNWOYHEnBAAcQjtB3J0lMlvOues6V9pu18tzB2q+GfoQUz/0i9UBqjYSFCGGmwMtmrjRYe5uxClF6ajqmjfMAmBMwkHMnEHuvt5cDZIACoGGPIiIqzExqa2vXlXV0peDg4OqxkJmRowhb1NKfcmzJ2Ne7rMVzgxo3K9k44UaYt/3qrxYLc1qY25LMcAQmaxkgS+WSwDbvI0xTkoTubtzS01CI3ud8N64+ph+nYhCyOYAi0iudbHscs7FanP+nDt3sNluVHW5XPZDJiK36tAQgsNzGRgcJakVuLuzN6O3TWIpEXOYMJvcpGSYk7AThpJDiO62WC2HnEVEa1XVrfWBeai5cR7HGIeszNItYy485D7FmBYrMytWm+nUKCiqYSQ3ndVWo1H3MTNXc4bBzTFSoTZyPqcgXPIw8Saxo2qtXdeRWy1ViErOQkwElmCAmSqDXZr3m4hBAiJ2Jm/UJmbUxt/JEUJsm4IpgNDFUOoGgBCHEDZ9DyCEQMJNgF1vNyJy7mC1vnrYdV1jdhFAmw7TSLGORE6MV6PB4dCxlw5zDsKBS8lDthDC4mA1DENzwFitbiYiZk5Ws5YYQtZK7hI4Nzoyq6rGzLO1xBr1oTERzcS1sNGtYWYgi0K1FvNGRx8dcLX1dhtCZJbtsBURdx+Gslx0quqlBmFvfCKxc1eYCzOptdCiqw9ebr7+FKTx0IDJd+c2zwjspkcrnNzNFC0pqaqpXrhwAUAuxRRYkGaFN9SAFytTeD9EhCnknEXCZrNZLBYG7/u+Wy5KqRiH/QZO6yN+j0liHNcqyPq+bxPIIilI0aKAjnwD1u5naXDu0RwBnfzqNHvQPpDKfGXM+7BJ/Y1Irv0RQkgS4J6HocXThRBgXqvmoRDEwf1QzCznHEPq+3673Xoj1t2rtj1oOj7nBox6xlxqrX0emoYAdy0FbhxpqH2ttVsuBu37siFmc+9i6g8Pc9+nEKxqKQVOtSjRDqY5H9s7rXNPzzFChRdY0TpmNiYj5hCCu20260Xqaq1wrXkITNRSLKSw3a4F7mbVzQjE3E7GJp1hFoGPKlh0VJIopUgMsUt9HppoNQxb02K1uFaGu9ZSyqbfNk6wY9PnezBimLXB9cmXq+5GqG7ZDEGKqlrJuc91aN6IonmzvtqiI3stCo8hlGEA4K5D3kZhcoxe4tFZBJ6cK96CY220+RngYyIF05oxec6ThPXVw2EYhmFgCu4eY+zzACaF5lxLUWbhIJevXBnqIClW+Hq7bdQ+IQQAqkVVR/eGu8TgrWlmIBKRIGOw87z1msHBnObWEokRm9Za83K5GIYBjX2EiQjupqrb7dagTjC4c3O9TgAKdTOQ0Sx7OhOIjKBmVzfrlmuvlqGWIXbJCcWVQ6hmseuqWT/kquZoxiheb7ZgrmZFtdGON5+N7YEA50F2d52wAK04QcmV4e6qJXbBoIfbDQXhQNWKWmmm9WpKQYiQ85BiWMaow0CE6tro5nyiNleowhtpbOMqtwaiO2pJzlqbgdeZilYScAwhJZAcrrdd11GDt3TLoRR1azqCVWVmhTvLZrMRIpgJUZQQRFpnG4B4XNE04daapcgMarNhkiY9u20LFtGa1+u1E9Jqsd1uRYSI2hYj4bbwGjavlBJCoyUNRbWUShN2eRa5dv3Va3o2TmobNPsmhEvOq+VKTUldQnD3TmJr8JHbYLKDGXZ8HXz0ow+cMh3r7URzCYEWCzlYrWippUpHi/MHTCilLCSh2eLc3CyeO/AQtsOwTMtGUq+qCiWi1YXzeRgagStRE6DZCSoUVqt4eMgiVWtgBUkIISxSWK26UjoJ7rTgCwqHVVaVKNZ2KzmAQBEA6bBKl2DwqszcnT9wdQDL1YKIXC0xN0I9VaVlF2IkYuZmzqEQOXSLsFyl6hJIuDOoG6UYbWggf18y9/1wcO4AQM75wvmbtZbQbN1AJReJbacRUWJzgNRSittSgjnHAAa0JW8QMC/OnUsH5ziCzJkNcAa7e2Rh5lzrctmFEErfX7p4SUsNNPoPFsxG6OAKZyYzYyeGuHtj7XWW7tyKr1wFMchiTOlg2Z07h6ojjxITg2AWmKpVIloEMTOvmji6q6nHFAa1hYiXfOH8OdWiXi+Gm/q+P3dxlYfS+DaEHObsDHNeLbvFAhjdlWHZhdWKgUQEt0SUta5Sp7lECVQ76RZmZsUuXDyXaz04WESWWis5RMQMBr9w4bw2ZYVILrCZmdckAbUys7gpEZhktZIURWSOBZOYZNm5awrcjhEiEjczCwjekvOqCiUzc6oiXKteOLilaBYRVaXJtrUM3JccGms3kRWNq4V0SUQgtFgs0mIRDg4iqTMZIRCbWWRZqApJKWUZO/VaXRcHKwb323zullvMLKS0jNHd1W3BMh9Pc/RPY2lsJyGEUS3VGmIEc+xSWnTx4MDMGtmggMzAkfthCCHEcyuoC7lIqLUIKB4cMJFWA4uI5Nwv0wGAdvteWK1UlYNkrUQkICOwIa4WMSUKgauROySkxSIeLFUQWXxndAHYo7NILENNEkDWUr4/7NKlXDZCRIhEQtalwI2JVCSWUhJ3RLS6OHI6MLOqO+FCvGBmpJWZDa4EMYTVInQNPs2Apy6kRRcOlrGWQGZemYLBmRoxM126mIoV87parcxGIXgYhoNlV3MB+fmD87XW5TI0KmgRaf4YSQI1IjEznRjVPMaYFpCAeq3Y5TAGfxJqrRKCNwYBdyKKaQEgsGAM2hPs26PmMhrthfYuk53Sc4PXxnzxHivHhNb/4kLkIgQYzMF2eX35TX/yx/dcfgDAzIM9Q8IIgPNsbToZKnyidnP3JgwOpUqX/vhNb3zs458AWCBmEKgq8n9885t+5Td/4/DylRTifqXsaFujVQVgnDlq4GYGjYD99uk8JkSUS1ksVjln6RZvf/s74K6ligQQDZvt7/7HP7z5ETdvrh6mKObuaFRuLTD1iDWN5rVCxjZt7xMd9ylRLMX0nve/7/333Qs3qznEAPjhZv1vf/tP77rn/khccwmRa63C0cz4WCDPFN2x34g9sgczb3mumIgcGlNa98Pb/urtj7rtNniB++Fm/W9++/XvuOtubvJ1Gx7fq38aIndn4/bEHWv9Lq5tsrZOI9CY4ZuPPWvtVqt3vetdcLeq6NJfveMdv/Ibvzms14sUSu53ZL2Tc2BqwgnO2h1ofTeSu8JuZgxqoZTVLYSQuuUb3vimv18VsMQE1b+8822/9Fu/rkOW66QCnMZ5P0HTXBrhfM45LRdXrlx52M0Pf/NfvAVkqHndr1//h/9heWm1ObzSBOckYRaPaEbsz6TrkJPHjRPOspUTOxHVWlli0XrPA/ffe+99UOqH8rt/9Ee3PupRVy9fbnxx1q66o+vT2OAMMpr0g/2nGzXPxG5hzKpqA/v0pb9w8eKf/8V/hpujAiDzt7/znb/0a79O7g1E2qxPdKQDOyLLebFOm5FwfQaWI7G3GLnZVcvqwvnf/t3f+4z/+Rnwilpd7Y/f8KZf/c3fvHL5gUVMuQymnlLykRN3t9b81JVAp5/+NAGCzDymtN1uJcVaa4jdne9+H1ywh/yee+0+kpvQrJ60ocSeLPA/RNlv/34565qpVtB0CGY3e/973/dLv/ivV6uVlQqyI4cOOVrUAACwu+65cs5+JY8pHR6uD86fq4Zcy7Oe9axbH/NoLSaRvVQK/O/+31++++67yZFzjtIUvuP1EMmp9U+xSPu4pUYRHZuDUVUf9/gnfPozngEAzHCvw/CLP/fz235NPtoluq7TOeuAE44s4tP7NWc73391MpBUt0/8pKd/xEc+FUSAoeq9973/53/+58+dO8jbHkCUoKoiQVV5xxd3rZGcR7ulc2/6c8u6GFLabDa3f+7n3PqoR4H57ne/93Wve13XdaUfDg4ONJeHbL+PSMAdYd3JFkSOfekjx6w5UJAkpS9P+ZinfcwnPt20MvNv/dZvvOPOtxO75tzFBrOZc0fsOc8moeo6+4spwUYLcGn7NoTQrZZf8JwvgpnWKovut3791++8804hppaJ6npzR8/r53hp/tKiNcaYtd5yyy233347Qji87/7Xve51pjCvDFLVRno/2V2P4yV5jLK+1vjvj0bTe5hDS4jSD8P/9PRPfPJTnnLl/gd/4Rd+LkloC9XVAJNZToKMByI1L6Iee4fY4WzUouRsXtXTOKPZqZyMmW+65ebPuv12MCxXjvHf//pvvO2td3aLWLO6K0NUi0icV8tpZax/b12duY+cjJyPvo7ANWpCQwzPetazLj3sJjg828/93M/VWlsqgRACASMH0r549FDzfmz/Tu2EE1RVOIKJmbPWJ33Ih/3NT/80bwgn8lMPUnL3aeZ4vluOXjJHyn8rbeBkPcdcAtdZbuj7Dgy1xBAZUNPA0q5odyfm0wKQsWd1u65t6aVSjAC0ZA5J3UTEqVH+OINyzkkCYF6VYpwugOut/2h/9kyQHKAKkRYlNBkERq8DOxpcxGrhEFErdsLBUSmB/bpbMr0S5WFIqRsb5TCrEgKgXpVCc9oaSZqsmDdSv2PkPxAZczuNpv8qIcC9FgsxAih9H1Mar64bqh+Tarn/qoAA1REZWZEExUBADEcESjJUBfMkNJ4QuW5w/YxYZRzxwgEAU+tpI1Qf+15rCOEG5+voftj/V62UItzVtAX5lpxjSqbKHEFmubAImL3WI6ll/GSlJ8WpUy9OoGoLVHatJAIirVXmP0IAYKUwS5OB4D6yrrWDb75ur30xHxeGpv7G0M4ddRsdk2osBMPQb7rlOcBQDYFhBNhptpM2WQ8hFpzSnvmSswYUY5iBeZ7fzXazWq0aiSbMIBMRiDtEjp9UO7HjjJacJvY1pxK8AgImL4VShDpaqlAawW0n+zyH37aFuoPb/4+iczzkNbb/BSc4aKhViEVYgEYZ59PZdLK2cewc1/Pavt+QEk5ocJFcNEYp5sJEDjM3LSmmxgV0Zv1TMMwUEuOnvG++Mz64E7ObkXApGqPUaiE0zKJ2C3FHezoLWYsOPM30dFbilnltHCuNY6rBQN3gDnMLgVuGvhiFiKw28VncQeTX7u+up479fgFodj6rWrSmlNoqbQA0IopBzK3Fql9//WcWIq2ViFjEzWqtMSUQqrqqdin0fU4puLuwmOo19sv1rBybWnWk/a3NDUlGBKAUFRERGoaSUtzt6LPXyX5/j63VY/0FmsPdm1nGRkiSEXOTcJuvfh/fcaSC8b64QWOyjUmwmXnGnRJDq4lwy3IYgsz1n2qSu4aYC5wx0XPYJI9RCtN+8VprDFFrHfMtuuOah+HJ3XrW6xz0ut/y6Y/xKGZhJlR1EarVhGFWmYO7CgWww3k/fOeUET1txvfXVdM9yAEyHsFkpmYSOx/jKqdGnjGb1FSNZl4MIbRT4L+VI+Hk6OwefNqxfo1y1rF1o9qGAUOtXROmhtJ1se/zYpHOrMWbfXA2Wvq1FgcYTO5QNQms6mYWo1StQYK5qWoM0Qy1lK6Lp9Q/XgZnLj4H+5REY9xlPoF8ABEack0ptIyNQULVGoTHR0vyKR7edY8ce6/cuLTATR5q8zAM2nUyZZ1pAzhlqVMQQLzX32v2tI1niyrApHLQJCG1x+VcUwrmBsDVGuDt+Hhe87WN59EyHotmJizrzXq5XDKxttTfHM1NiAjUnt6iGUeb7z65zhj/7NMsn/06j8OYaY7m96aL43g0VAuxcjUhPr2/xw6y8RfcJKf9ynYXCaNWk9C4asA8nqRZa5KgpsJibrVYSmcyENLeAF5HGV1as3612W5Wy9VQSxdia3Q73Ws1gEM4pf5rWyn8xOy2/tassWtqq7uRRPR9XSwCgKoZ5i0ag47pfH58tYzenetebzoxVB8rWj1GAdCXGjmQjD8iKMFL1RgkD8Wgy27VwFGnHKq7bl/HBTYOvSJw2Q6hS8RhFICacHf2qO7O4oYOsknoPiY97Wskp1Z0VrnR6+FG6zmr2lPfb64/AzSrBBKWqjVKaEZzADsFtj0UxpN334ExYnjPOri38Uc12EAsvKMkczWzEJhIas0icZTaiAgopQQWnDq5PnIxHTcxzKFvzaE9dU2ESlF3jymYatG8SN126NtabBPKkDxCZsPemOw2ITnMTpfOdgjUo+PpLVLJCCS1lG6R5qN8tH86Qgju1Dh9x05ct0rfgu2Zg0GbUu9GMUm/zRJGyyrMiTyEVGttcTMnx01o3K7qRwwWzmLUMuYaOxvZ/GmxEiiwBNNazRYxObzvN8vFstRCJEKccwXQYHVHR8baeLb1c7Jfc3vm19ZmA03XxngdtZXmZuq1iynXEiUYVIjNmtX+uuof+0s78MF0BHNTIcwqwBwoSuxzLxRIoKpN7AWMSJoC3eccKEzjtnsFANdrrJ9jS8gJIKEgOWdy7bqOGX3fN1RPjLHlAAfgJCGE0g8S6Fj9syvo2Du7R+wt7/1iZqXoarUahiGmZGa11tQFM0shbjablFIpQ4t2PJqfmOfzoXnKr3M96wk+dvfRrNmyNpgihNC0vb7vRSQmaiDdNvJNpt9bbLtet961MKzrbQ8UWo2wWC6HoQQR4pbDTU672vZGct+lPAxD13XX+Pa1y7W1gWOfXuf1c+y6uobWcp2lbQNVFxlpaNEcG+PzGHTkKTQzZ9Ckacwi0HGZsW2DRjPtIuTupkVCgGvONXXR1FnEVM0pSJjNCSfrOaV+n2+JtvB4bBgAoJYSYnSz5uUrdYghAmiKjjvlnLu0bGPaKpp21KwmK8A3apw0q8wY1QIKILQ7mCYk8jhxOjJD4Kx+na5ttCnLTKFlJgRM1ZlHJ/ModpkRA97Q43yt8bTjyjtOMWdNv6YRriIMB/JQUgpmVYRKLTFEUycIMc9W+LF3uznam6ZjTz9j/Rx7f5QKufGGWB6G1HVjfwFVF45Hv/8QBrH9GadR02WQaXWJDKNqhSEcqGYNSdp+aSACs7Z9BEzNkXu0/iaf3tDyaSyCKiwt0C6XvksdgKbcOJwg7p6rpphurOq9h5xslJsRM4zMjEWGPMQYd8jg6szUbKogctvzNO2tzNF8dR0reZ4XJz+mLc2XGVE7lyTnzGMcVQtHVxkj6iPwEBa5qWVnnlfHVgjMSFBKCbGbtWZza0kLpsfsN5gBBJ9ISTebzRvf+MYxvEj1LBvcWZbNfR/JyR+e/Gi+MK/xq/1iZ/gezmrPHLp8rOzCQN3dGxi3harKriN7N+1c/alazin9MnP3GHgYhhSFiDQPLaxvDAJnzmpEFKTlcA4AGhpk31FmutvSbrR73+o8i7TngCWiscsjwXZj8jcSUVWGiEjJzQTPc8snj7BNr6x6uvY2j/PRLhuhAq5qItEU7k4y19+CDbXByVt/wTupbb+qs+YRpmqlhRqY+2htJ2pgnhRjKcOYX8ucY9IGGt4byTZ68xgeGef95x5FppqNZAyqWqvRSARp8NLWCBGPYX82fm3Xr1ZVQ/ra6dfwfn+PSMda960us1RXdZQ3zWqb6BBCrRUUdyrydYynWZ3/3hd83b2xYuybrJsEUMrQBP+u66xpf7v693vH2NvX1+jvkfehZiYEMyOAqAWqagixidg555gWZuZOYNLq07MMewi0GSl0DPHoUIxH85HLo41hk+trrV3X1VrdSCQ26blROTTRRET2jV0jcnpmeaGjLu6je/b4vsZ87h1Ry0y1Naa1jabcCi2kx92JPOfKjBBS21NTH+dmnbLaTz1D9v9m5px7lvjoxzzyZ//v/2e56ojoIRPdhHZnmNnv/M7vPPOZz2zb8qy5xwnp/iH9DWcpGWf98Cx94hQN4Ox6rlG4IZqIR/YAAEDTP3Z1XrOdD9EeMDObFhFxG5csE4hIzYMwgKzjvO31d9/0dWQbnHg92aOdwZ8yAAAgAElEQVTpwoMCYIYaiEFT0voRicNMzk2OaAsHx64Nmjp/I0VGAMgI7RRp5hprdoZRejNyeAyx1HKjlkqe2hljLKW0juyfQSJk6g1bUOvc/OtU00eD0NFn7q2Eaej2bhfQRL1GDnekmHLJx395ohzbOO10PvmFRnN68v12czBzjLHW6q6NXI84nGpPaBfAtVsyAc1HgWw8Ot2DpBHpIGOE6eitjaGdZXsW/yOmXQAc6OSDjjz0RO/MbJG6XPp2+HQhmlVVnwk2tDr4iJnoJKCZeYco2/sUzZAwmePa4BqmozkEVlUzpJRa6jDzEVyaUpBp3ucAST+SMosxGsdOWV377dlfb3vavO2Pf2SxkSTIATb3lNLVzTqmhXs1s8UiqZK7NrxJCDNwfx5SBqj1/eT47L+zPz4OrA4OAL544SaA24XRjDEnFs7ulpoMNcADDzzw+te/frFYNLqrdnPMS3b+6VkOqHk4jn10dLIfYkkdHdbT67/G+8fqPB06RhJjXK/XIXDXdaoqxNVKENkzjfB4gAOzJfVkbadub1AUEZDlfkgpBSGts2Yjk+NaDC4Sa81Hbaa7Os/q7wjnPXI+MYAo4er68OLF88MwuLvEAFMwuRoJW/Va62q1qrWOC8tbiNZ4Fc2yVENWXEPhbk2c3zGzlNJ6vT44OF+rETNDDMpEBqUGxpVoZoGlmp62HK9dmCd7a86Zg8xodw7kikaIPQzbNmLNFH79ZRrwvZujxcFMNJHu3iTcdqqCdym2yLFYrA4PDxeLxbFqWwub7Hza487858imccT4w2DXYotVt11vOEgKcSh9I0kP4QTRw56acrIwh2PrpwWyicgwDF1KVb1BY9zJtcaU3KyhiVRVIqNZeEbjLbdHHm3BaY/2HTfDsRa1K8qsufdp6PtusQDQIjY4SDPkzlYa4LR1OaODRoPe+P4cpHcUOTi2sF2Tk/dbVEtzCFODCAqo2axHUzJ2ih1A17T+n1V2QMVmsp1ujhErSOxuxGyqcGYREIrWwFKtBJamjhEfQzgd9+vcKFAIGNH7pXiMNENajhqp2nEx+g4dU/xIu+33D7iTj7/RZs3L99obZr/+G3VXnFXPsXfG7TThSJrAWKvBPUQZF8fkbdhdrK7X2xoiAGpcTN19EcMwFKaWwG6chlqNhVXbriNmzMnljzX1LJd+4+o+SZNoqqmLtdpkB6tdiEMtgaHugbmhqpqskXPfxcX+tdEUePYWkH7c1XmNV2sisjMzW3NbjyFMjZQDDcVoZq4NeX/d4wk40EwTBBk9gcLzMyAQsLuJMBH6Pi8XqZRyXVHT03gC+4iy3XlXSum6rlZrpFvu3v42cCPqYGav2nZN3/fHju/mYAcZ7Hh/j2mrR1VV+Mh3zfP1DCMnazKiqTYnOckYsqpaTo7nvsx0rP6iu/XTvOMN/jsDNENMm812tVrW6jQRkh8sVy0kTXVU+CaDxJ6060wwIm9sC8fWyUjmMWv68/pxMh81iTwMIYSUwmbTt4GNMQy50GQAYCKY4myH/wk4ACtojLYY6RBG+2Gzv8UYiahpscKx1KHWKjF2UdoCyDkHoVKr8Az6coBnCACNPLrXtaid2I2cdrfnZCccsc5WtcV7EhGRqJmqSpIUQp+zkCs8EEPYSt2vmYgAPhKtfHbZmVIIM2KquR5D4BGI3L45/uK4b4PaVV9rne3vZ8npN2oOOtbEY39fj/Hnv+bpp3cBZIZqiBFqYAcziKCmk7LZCu+uDfNTIz/PMCKBmBWOSRxj4pxr2xUNjGsGaoCKaiGwnyYVXmsV0t6VtleaC7HUIiE2YasqgrReg4CGH41MueQU0/41iT39c9ocZ9pq96NwW5R4X3KKqVQnoqY7EZqUZ0xM0PYcM4TRsXHKZr+GUc7gRDJZ1aDmDeLv091fioXA42xea1GcUnw3DnYM574d+mW36vPQxaRugcUcRtj2ZbGI5h4mreAaYuc4uifG88zXWd893k6UUveRr3vA8esfz2Prx7DTsBs4QJq3XwEzDzR2rVYQ7wwXZvUY8nCvoTjd1q8A2bFYbmA+60aw7zCoiBBBBC1RFo+wYCKQqTak3Cme92Pnw97JuF/2Tb1DHrrUqSmRMMF8jFJQa0z87KbC1EAl82zaCGee0lodb8dDl7mh+7+d5fUWKDNDurMiCBoAF0DVGkUMJnu/pjGV1H9habdU82Y5ULX6pMVO+8n2vtliaCbXLhHlnFsUFW7Qf+BnhweepaSf5Ru40XLWb09V0r2lJBTopIuZVyGYz9tgVBonNZcnJMz1bnv30pKoO8Ac+r5fLg6mp7sbEc/xRLlBS0+GFp85HuTuip2Q4sc+I0h7MkGIUKsTETOa878f+mWX3N2hR9FEPEq4u3KKJHcUcuwAOblZVdUYOwKVoiGIqjUe8lozNUuNj9ZzZnGEU8fz+IGye7+qVmYhIjiPVwiNCEAmaVKyuQlx0cp0ZkjB6SM6zfexa6MRdLtC3YSYGFbhBJPRPFG1Nhq+nPsUW1LH3YHQWos97eEYpUTTIRiy/z5gxNrgEETUQERN9GwaTz+U5bIrtYhQI6EbH3jd43l0/ezWjaoBiKFzAsAtZgVALeruKYXRP+y76C4cF2x51A5PWz/McqrhU7WY1yDJ3UnCHA2zH/qTh23XdWpFOHpDK54oZxxRBtixK7k9u5TSpWWpJYTkoKrmTnFC97qjFF10Mqnvk7l+ErMc3IxhNybNksF0N0d7v2URgHPORCIhEo1WIwCNBogItWpKolUlsuv+DO5QbTcoXJvpkEKotXIQJsklC8fZ2oQ9X87+vUCNHrJ9j/foq05VooHTlev/juWsK+1MIxjGyHAAqoUFBNQ6hHAq5ww7Tl+mZzVHax9CC4duoXbJ3H30IzZ90AHUkt09pjRFD07NnvGbp0drO48mNOwZHMemAuJuREHNhPcBNiOsDjDTyrx7q43U9E0C4GbXE9W8k8qJqlailrIgTLeImBsTmZVp8zvA7gaKp47n3HE/svIdXsgBZoDN1I0khKracFkppTneKA/DYtmdMW5nlmZkOOrbaCfHdPw17FnLrsxwQm4Sn9XA1AwtTfMZtYrddDDoRvexg9S9+Z8EGFcOiN1G766ZNbLgpvGd3inQWeuHHFPkxhF6KocTBQC1aDtBzDDh7hq3tQNuVvasEfs1TMoHnbFf9o3A86sbMWCmbizRvUW9dU2SNTOzygJhrnUI0lIxNSTJtaKg9yLhfbw5pnGZW+tAzrVLi1qNJDRXsDt4L9VcLUMjQHCzcSJbaO0YWsM4m+PrVDCSw+CKkU5kf8IYQMkaU2cG5tDa7o62m0ZIAsO0sIjWskedeczNcUPHsgPVrLiTSACoHR3agA+Qs66NMEHsd06O5vHjKVHzMWfDjAg89v5f5y1yPZrKEVDjUcwo3LWqu4cYvvPbX3rnX7314sXzqrXZZI//Sk7WcK0SuYXURYWbcwzdlfXmtttue8lLvt1Nzet6vf7Kf/AVT3ji4688eJmZWHDadXVW4SMMoA7ARrcEBzNzCJxzrq9+9WuqEYAg/Pa/euvXfu3XPPnJH7pZXw1BuN0fO22MR/Bxw96T22m26WamOvE+q9Gmzx/xEU/5mq/5GrcgITDRL//yv/7Jf/njj3nso2rOIBMRwMjIXfdzK51V9ke75bpo6cesbWyJd91115d/+Vd89u23A4Vs8Fq///u+741vfOOFC+cICqrXqPyUId2VPQmOhJlrMWYOIb7tbXd+9yu+54kf+mFwYlc3/cdf/YIgZFaF4K7C7K48IYuoGSLp6LF1HWXaiUxE6i10QETkXe++60d/9EfPnz9vZnGxeP4//N9SCiygXYKb6+os+9zlI7+qbkxhGIbV6kBCuuuuu1772h9fLBYkMefsql/0Rc99whMeDzJVVW3a+R6kdaZqdgeu5ds4Gh7YQEEpdgvi8F3f9d0cI1DbkSnCL/uOb3/3e9554WBFsDL0Tep39utYmaO51d0ndAtsPsqdSaRLy7f8xV/+6Gt+7NZHPqrkzBQkMry+551/9cIXvvAJT3x87nsiIm8e+7p31Oy5oJn2R3Jeutd3YuzaA1C3WP3Zn73ljle88qkf9TStJhRYsL5y73O/9O898UkfXGu1WhvXYQhMNkLtZ8ZljGZbP5Wo+xrnsxPcyIgJ3C6t7/veH8B4wh+pY/5rSgprziCYCyMENlU6gUghAA4h9inWkc92v/zX2NoeslzPFXXmldbkJhKtFVY366svf9m33XLzRSI7pjZiFkJ5zxQw1nh0ozpAmKfL3TkkVyeWXNQQvvUlL4ErQMLxnve998Of/CEv+WffbDUzwb3s2tnMSxMgcv/9WTUm7OaF9kBQ4y1OwRC+6iu/GiKeh7hYAHbXu9/1vOc++0u++Lm5P0wpNnlnWnMn4Zv1DCTMiRl1dmLi+K733P2a1/yfMaacB80lpe69737XN3zDCz/h454GM7UiEqxWMwsx7tEvNufkQz5KAJg6kVAIAGm1N7zpP73hDX8KQHMmIpLw3rvefcd3vvSWWy4xyinHKNnpa+YEV8T02wbvCURUi8XU/ezP/tz73/fuJz75Qwih9mW5WnrJ3/f936e1jzHWvheRneXH93wsXo+S1s0GEzn+TltdI0XaSPBg5iyRwuI7vv077r//3ksPu9n7HlounF9+9yv+udlAKDRrOScnbn8od2DZHQZ0b4ikrblaNXbLl37bd979vrse/6QPtVJT1/3FW/7sYz/uo771W7+5DuvmrHYrOFqakc1dic8+MY95ywB3UqOYVi/4R18DIfcKZ2IBoZTt+uoDP/i9r9SyXS07tCD6faPT7IdrhWfYFNMOWz6l2yLCTCTjbM4c0x3f9cp77n7vrQ+/lZlF2EumYG+/862f8zl/+8u+/EvzdpMWSXMWOg2q054mD30CuvvcSDqSkpLm9qt7WJz7yZ/4V2//q7c+9aOeFkIwVQLec9c7Pv7jP+rF3/pP82adFsnzsDe8x86l0VZ0ls/stDYyERGHFmY4lAqK3/TNL2GRKTrBcCzTAQAgOIyI4Vy2Q1zFb/tn3/Kf//xNy9W5wheubrcf/mFP+raXfkuptYsLqkTqbvXbX/4dX/1PXnTu3HkZ93TTGknVWrIdCGXVJAIaiR+c+JheNh2xitGF8Nehr0xzT23KnKOxmA558yC4MNwriEhRBRQ4as1gUq9wjjEOtfnrSLVMGXOsOfUmL8jYCZ36Vx3Vo6uCpJmMSTotA6xsr9wbIgEopay6ZZMmQopGVq04NIVoxdy9i4tcismEzpx2Qru0W3JpkIJJnRerS40xEVGcnBBIQj+s3TY5X7GCtv0UmSkQFkxBay+B65BDCDaas0BE7Hs2SZzUxtkILsLjyUXEoZk1QgjD9mq/eYC0AGieZMDq0IBaCGiAEXeMZNENK9XSYDRRUQwAjAwYE4ij8VrJot9cYRGQIJBVFeckoeSrefD2RACq2oVIRH3fLxapZeFt1BGmSClVt4YEwVFFf7Juj3ZFcwif7/uNguABRCLRjcwA7YfNA4WITIt5N0ZUGMG4RVk2fASwb+VvAOgzXdZ7qrzBnVgNB+ceRkIKAkRCB4Jr1nq43Two1Fyp0czIzay2ZozZcciL1pSCO/XZRERGZAGhXZpuANgZE+KgaI3pFsIgIcCFJcFMUgRcdb3d3pdIiumYW4mCu7sVZqbakOW6Qxmd4h890t82uduily49kohMiaQlbIeZxhAJWvrL7EN/eHk8LYWL5hQ6r4VgrkYUicgBZTNxJ5AFhgWrACpop09jREAYiDitupvHEWcSEjejIABLjGXYWL7a91dqZjNvaXi6GLZ5CCE0rsBIMKsObrrUfLw0x9uJ/cL7SsCk/7Q0aGQE4sA8jiSc3MBCgIIDMSPnur3ig0vLGMzk7uq1S6Hv+xg6gNXRbHW7lbZHMtJG75giMsFhWIwKk8JDOscwh6sZj+ySzQ8H2mN1CRUqbqwxLjvAbr/9s5/5dz7t1a/98c12+6Kv/0ZozyQs9cHL919a3cxEpdaf+qmfev43fG2FkznMo4RhGIZcL1w4B0cjeay1WqnLZXeW+fW/Vxnh44RJxwPDmTRG3hxeOVidh7sTmxnDODACRY+IUXNZdkKQqjktktcCcqBdH9REbwDjmTvaQBvFkUchgNzFMWHd2AJ7FDCFJGxaUhCkRS19isI+csJ0XfCqhCpsMXZE5KoQt73QvxHDTXAGmwlbw9Jh1E5Gng9iiwKh8XKjEGuFFmOm1KUhr1fnV5Z7sEy7ekp5tD964/8nfwWhYn4iA2QOAbl7DJQCAU5uLcwVDHcYOIRQ1msJwQFOAp9IPeHtzmirOTS1hEb8ChG8AUgEYZSMyY2mC9sIJlQnui9Q7Jp9/OD8sg5DSjFFgojXamTwwqDVsrPxmpk0yslQSS5tBtWJBcQOEpBglCNFGCwWggViGAWwWQ3kHBgEBKJsEkXUd3b/8XUWRPnEKwAQwcyZqeUmZRYOTi3zAY2dFYawRbEg1CzyRiB3WS4s5xSZKGitEgPrmCRxtQgs4rUAaMCEdq5MqE0a4cgA2JrpGsQwAgtBmMFiIohMsBYRZOpGTHHV6ZBl0WEozrNfAdgjfPUjXp/x1YmNLBpIGpCTfbePFERCLmwCE1JxcQK4QfJMBUEEHqCAE9iFUQREBIcYCwtcmZpxzLFzWpkSV6uAAhOCHOwT7oOIGMRCQRACyAI52E1rPjjoANRqRO4lx0Uy1bEzRG6OEdQ6ZaDY6/KOe4Js+qQZNMibwih2hEa22UW4hUIhMEU2Ive2BEQAsVIOFgsAWesiLqsp7xZS8ypOVlPfWSbmL1hjTgM10VMBYuPR0diuw9NLCBCdKObB/vGf8Amo21/5t7+B7uaPedrTIpta/aqv+qr/9Oa3IMsP/eAPfvRTn5IWHYB/9ZM/8bu/+fqf/omf/Jmf+Zk77rgjpsUXPu+53/iir3/5y1/+jne/681vfjOp/ez/9TOPfdxtbcJO9Q4etwn9/2nawijHtT/Z3RkgcmIEpqrDwYXzKAqirDWEAAWYwTzkHGhixqZGbkg7ZdNmyYqmHozLgoicm2zj2MchNMg9MzO1iD8Z8aUaUhyKxq5jRsk9HBQiiIJEOA2lpMCAyRHrw6iEN/zODnrooyij0Eatw6DQiJfJas4cFhwjcchlSCm5Vg5xkgobcuk4UmRU8eeFPbmyaR88PaN/qKG42ufN+ObCVHMflwuYE6GUElKyWoWE0KxJaAoczRoVzb3jBuA/Sf9JU3GrZh5ip7VlfYerS2wsueRV3RHSAkTI1asyScOSyajZCNGUN41ALUBhhNrbpCUAYzSvAe3KdLTs1ssD1AygDI0LhBpr5MnWjoimk1uCBUATMwhExGYEPuKZHP9iFokEL7XvggRmq9pgN8TBFcQBaPEdYCKrrlokMAACu7sQtUeNjWLCaOoUgJpA5TCCzxQdTMTj8jYREU5O3PfrFMWGfjz1aPTxHjcOnyg0Ttxu0eIoJmKc1HllM1XNi0Vyl8AxD5sUIswBb18N4yUhI9M6EY8O7MmI5+NGONmYEaLlLZUkAxA0oB5Ru7zJYZZrBUsMQpxqKSEkbSIM0Wjn2wvjIOx02clYZgBNoYI8op+aMWYci117fCrzULRVAaJSDEyq6KIQcaTAzORGIHbZt0pNseiNMnX/8hg3KeAjivK6PbiMOZCbUbWCCSKllPvuuy8FROZXvfJ7Hrjvwd//vd+/4447nvu851Xy5cHq3/zyr/zQD/zgq3/oh976F3/5nd/xsj/4gz/4oz/6g5/+6Z9+y1ve8sY3/ykHef3rX/+Uj/jI1/zwa64de7Ib379eXJaDmnzB4xEMdtS8rVpMNaVEHIzcGVlrSFHdSMa09QCslHlGnWZjcTtWtMnNPqaSV4f6CM7YwZ/R3jQPqRG0mdXBVN3IidW5VhAnbU6uUmrO7r6Lkh3LEV+cu7VHoy2A2Zw6ell1bhtsjOh0977vQ0xOYmDdW6ZzVceH7uyJ2tvjtFvx03/Tv6t7tVrN1J04LbORS2j5Blr01xTay3PH/Fglp4H029Ol6wB3G+OQGh9GNcCZOUoI1EhIWlrTEYTOI4+s885d5w7TsSUnx2G6MybuL3fC/8fbm4fJVVVr42utPZxTVd2dgTAkQAYCQoBAwihB5hhABmUUZEYURDHIrFwRQUC91zkQ0IsXxQkFB8B5YBRURhElBBCSEMYMnXRX1Tl777XW749T1d0JgUu+7/l9++mnk+6uqn322tMa3vUul+epKFiAFYzLkkBMMlKea8j2Tdrwy0SxS58GnTcKqMpQbod2jmZC23FJVQlYzsUYgijZTIiiQkipWgXGmaHpWEfHPORtHyF/gGqZ6bD8WUHAmLIsmTWU0ZhM1CgZsFZgjWGue77eMF54g1iGFJE1FxIbQkkphFRGdlkjJoHMgSMFBhheP7rGMHXkqN/6eRCNgNUhE0RRlVVZUlDu5NKiNWXimMS4rEP91i13+NYfPizPzmwyKmBHpAwAOqLwWvey7Eq+E9cBAWVFss65msvyGDQVzDHGGJ2xbxZXWudEkIIIj/jT28VWVE6Mji1inRNFFjHe9dTqIEAId//pro985CMhhf1n79vorS989ulXXn/lgyed/LEzP9Lb6Fm4cOHChQv322ffnWbuvPj5Fxa9uMRlfr/ZBxjC6dtOL4ui6qUriKGvbnSro6a//cTe/+uGphtoIQTpHN8AxnsAsJkDgla7VDIlCyNFUSFDZGOMBAgEhFpxvgKQVPAeHDpMpZIodOFp3QEO+3y6sejuFoylKgMBWUMEZYrG5aImsQFySSr/NlYUc51S592vEVIdMnvXOEOxc1cJ0pBCVy0+BajKjmKe5yISUgRCVpFhx2tnXGt9wfCndMYBb3kOrtlUUnCNnAwmVnCuSIkBFO3Q+1HB4BDkZW3Y1VvoGR15lgUARGE0pkwxsqB1rMCAkSWmyvImVURAkOFY5Zu1SjkHEKTKA6uA0tVBu+VDUGIsK+tEEExWYwUgp1j5viqjRAm08ltXzjVU6E5k96uLvOrKs/LDj9A21tTfGZRVXKeaZAIAa61GVjTGuiAYmIzLkSwgIpHEEfiLzr/DQK+uSAnAdJyulXLV0QQ6PrrqXVJZqIDW19H4UIXjugW9cRhCJiO7kHX+ds3JRRgy3IeX8Qhji4nQOm99PQKJ80WIlVOo87CKVOkB3YBNV1xDvQAArOt4rVxVlYnSjXpUrgEFMhYtIlESZQEyruQqREREtjpHqv8rEpBRJO2ih7ody7pC01JJa4RysMbzGLRdFwVW4FpBqDTLMgonQrDW59Z4RBVJgIIg6zglsOvnhLX/tOYcrPWE9MY9CBUDbmWtsFROGwqszFoRNKbAjUZvc/VAlbrZarWyWq2vr+/3v/vjAfvtd8QhhwHAXnvt9ae77mo120Uoe8eM/u9v35hlWRQxSDWfdZ25a0hqXc/7/66NDM4jdKTMRUmWOATyec33KKLL6gBa68nb7bZFQFVA0SRoDKh20U3DdgYAVKfJyHsbUUE79OzQ1SaGVHIkAmHsFsIUgHz0WCnBWodIHFpZXufQMtSxspn5DfjVEXu+uli6bWgJjlDoRgTTWUTZugyMtUTW5BqTYDe56C3byPkbXtMjO37zW4QIuGhJJF/rg7xRzxpIlMq2iqB009BUgEwF8VvfVlVL5Sqfq1YHNCCS946GdhMQUyyZEylQFf5RBqgcfoJQMdcOYfy1628cHhYADNW3Ue3cvpVbxmdZjNFldQIFY0nBuFxS0Nher+cfQs1Vn9ydwjUJ4oaiWYKKoKCcmDpsRRg5+Z7RCh6EnDGACaLEojmSGLw7Lhn+Ee0IbNIIVQClyq+AKnqmhCRQ4V+8tZSXUbJ6j/WeY6Fcrm+e/ps6qYbK3al2vb8IoCKJshqIB5Mhep+Z1FzNqTBDPmJRrUikhrqANU4gBKjAHut8nu7pjSCd/HUDiCgcS+M9p5TXamAcWO/rDQghFC1Hdm0K5Lft7YGOL23YTF/jQzreLeqiOjsfK0DWZSJknQdD2lyFiITEzO5/I69du/eRt/LbfmpbeTMTi7UUUgDkLG+UIRkSELDOfPiMD33wQ6f39vb+8JafTJwyecqUKatWrdp0/PjPXXHlIYcdev/99596+mmfvfzy7bab/tGPfvTeP9/f398fQrBEq1evXr58OUAVIlv3GaBrXGXdEPX/v62DfUKFkdEW41yKJVkqy/KZ5xfFBNZRCIXxZttttkZh7z1wAmaoPNzUcYAPt3Vd3yOUcRneltXLEQHAuAykkwZKZO/53e+XrSxKFgPY25vNOWAWIQCqptQFM43YD7qOvkCVtBNxUdXqkCMdIWslACHrY+R77r5r1WBTILaKgcmTJr1zt90QANaF/B4Z8B9x9qz3ZBEgWG+su/e++5e8vtJntaIoenvqhxywD3Y0GICq+hNYVV7LqPhfN2SKSYTReGv90hdfeujRx4QhpIggu+22y8TNNjXWooKkoJyQ1jhf3jDm7oFVnV6CoFVUAEccOgKgilCEMs96Xnvltb89/EiZIiDGBNO332abqZPWdE52WkecbzaarvMC8K1OYUQkQhVFALIOOKiIz7J/PfnPJxc8b7JaWZaEMme/PUfXMwBQDmjcmoqTdh36nb5UuYqHqUrlj+q4SgQrrCAAgah1rn/5igcffnCwWQBhuz04Y8a07bbeSoWHtxWuvbvfuFyGRNMRM+gbJ6Tze1VAsNaueO31+/7yVEIXUtlqDczadcZWW2wOmgAAlLHiVoFKz1uH0N6OFwmg0rs7LPxQefJVieiF5xc99PgTAsTMkOJ7Dty/t1E3VSmtTqI0I9K6dXkYIYPuC1S5Q4sz4i1VIq3CGgUgVFVIVK0x5sknFzyz8DkEkBgQ0rvn7N/bW3szoO2IQb3JZVmxu7/529b62SIRiFpLLOCsK3LlUHsAACAASURBVFki83vfd0QK6Cxwgjlz5tx4440/+OEPN5s4ef78G1Dlms9dlfvs5JNPbhXtVtF+9PHHPn/1Nb++85c/+dEt79hqy4+cedaOM2fGmA457NBV/SuG4nfrcZf9P2ndi11MFXaoiu4RPf73xw4+7LTZc/YtWoPkcMONxsy/9uuhLADAO4vWAjM5C6oVQEOGVFStllpFWF2dLLpmX502fJcocLeieIzRWrriis/N3HXvUWM2RNJRvbk9cN9UFBUMDokMwYi8h3UNSruK2wgtYkiXAR2ehRRSUcRLL730oEMPtw6BOEbde7/9eHAVwrrQC+vuT9YR6+gqL2uNunoWEUmh7TP/uWs+v+2Ou4zaYAMAGNPb291OldBM9Vroqt4jfVPrtq27zVoLYCMj1up33XXP/Bu+ddQxxxZF0W43d5gx3ThXNgctgelCyqp8mhGfNFSfVQC74upYhp0UaEQEMKaD5O60qgTW3//xxGWXX3HSKSe3izDQak+ctFmFzdERgIihfoYpbIa+K3TSlKuiv51Z64oaoBMnGyECESFAIoKUQEVB0ec3f//7CxYumbnr7kAUiuacA/YCIoklOdcp2dPJIR863yv7GCvHw9B4u4YAVvSJ1Z2hmqqI7tKlL19yyadOOuWMgdaAQtpk/Ljttt26g2lY49Pfqr0hntGV6pBF3n2grhzsU089fcVnrzrmAye3YsHS3mLS+GnTpmqROstDoYNyHlopuvY6HNr7b3yeodjciGBk1TXGIrrevjt++auf3fnrd895T9Fuo8b993lXI/NmRNCx8/lv2+BARByB8KiqjmDnMkccQtyYyqkORGScu+Gb33zlldd333U3FY7twfcccmCX2v1/pzIc2XVHtwTECkq2LvfvG1tFiFS5tAUAMuPasZw1axaB4wjGQEo6e/acdx84R8FwZO/cqSefRoBJ+GMfnysgvaNGzZs3DwRSEUDgmCOPSACgsMNO00FBCUSVkABUmEkFrKkEwqxkICnYjs3dUSuYuSLSqngjdKgYtQgRjSxB2Kk1tp5NgTuQ0OpHrRz9FkBVNCXZccetf/LTO2LRJBLjUtEa8N5rCFDREBqjzEiGORqfaWR0piq71ol1GQIGNMgxELkqaNqZp8roB4COjxIMOklM1oXYdnnW1zv6Yx/72OR3TAMQDU0Oq4wxAAkNAIEmEWHjvSbpesMADUlKOJTNrt2d3zmXOgklXd9Rx29bxbTGjh13+ZVXaSrRgwiUzUFkNt6AiDATmo6QrZUUjXMc2Viryuhc2WxmeU3XvCGICEYIdo3zuDL+K8kb16j3fvycuZO33EoRjHJYtZyc0xiBKKVgXabKSNQpR9ZdAyNPGR2Cgoxwi6Uk1jlVhSR5Vt9jjz3Pu/jiKpoKGsrBQSIiEiDQyNUdJCJoOt7/lIJBwgrFXwkJABQqIqxhVQArpzViBToSiRx9vQZAs2bN+sT5F4JxHJNBScXKTo0KYzo5j9Z3nC8iZkQVBFVEa1U4peiyjGM0hqJwxyVQdQu41q5GRAMEpKkM1luJJaki0oc+9OGDDnkvWoOQyoHlRAKGh0BHqoqGOCXrDYdorAfqmnqVWYyqsIbXRRW7+Loqc5846fTtd7jgk5dyLIwFgFAMrPSAKkLOhXZ7qBBhlcKC1mpKlY+XU0JEco7eEIkdKkYH3btWpYumUwFVYdht9z0uufQz7TBYy2wMK4qyaQScQWFRRTKWJRkEMKhJ0aAkIec6WpqlznIacZerdi9xAOnEk6oQt3SQUSzOOUgiAkcffdxZH/sYgQEutb0KuQAVSdHkucSIWOGkubp4RISQusYcgjEpRoOEljRyJQ0R6WC7uyu5GzsYFgszEwoYSCoVhOnEE04+4uijARhiAVwWoZl5A9zxnTKzyWoQo4B2it9YKympqjGkqtgpi1l5M7SiUHwjRnGdzQ5tckJCkDKGzGUiiqjGYkpgvQGAsmwbmztnQEESk3NAGDQBoiMqiiJDZ50HhHYRfO4VIUY2xnAStJSECZSMAUVhJmMADBmIoqaK86h0Mo8IrbVVqagK7YPd7CciKoqiCuF24tjrf2eMaGsuVtUUg2v0gGL/ytWPPfLw4OqBnrrv6TObTtjQZ5kak5gJlFNyWcYpmTwvmq28VkuxdM4BS0oMzgAzCkoSIipDAJO9AQE18imQiDiW3mag2Gq1rr766saosQgyfuOxF55/NrdboGxcJjESWeMyiSml5PO8mm1lJWtHZpu/SRuCjQMAGO/jYLvZbJ7/8bkuM0Vob7311med+UHREpiFlYwFVWY23oMIEYGIMUaYFQRDyBoNTfzWXpQ3NEQ0PrPAzCFeddVVo8dtWJbl+I3HXfDRM8t24SyCiq3lqYjWGGHG9azPYX0tlSUZW+mYf/3rXy+75NKibLXbzdNPO2nmzBnKZYrJMJCzKRTWecq8hASqHCMZQus0MlIFNF1rE1VR7TXMeVToJCUYY4x58MEHr7ryyv5VA+0yvO/wQ2bvN6scbGVZjWMEIJvVtCojgRaMASXtoB4cEqYQkdRlNY5RVcEYZM2zTjGPdYJkOCYAtMZYX53YCiE45+bNm3f3fQ9GYYJ08XkfG9WT+eqEpCrznADAOhdD4Wr1cmAg83VYWy+Hrgmy1m8JgDSJr9Wfeuqpz3zqU6ubq8uyedCB+x168BxIQVKEyL5WqwKBKQRby7gIxqiIVBGLCoHCMRqzftSTYJz3+cMPP3rRBRcFbQ+sXn7iB96396zdEEgkkPWAyDEREYtAGj4iUlkSoLEGDMFaZeh0rYiMdOAJI8mCrY2twuUN59ytt97670UvphC4bF9y3tkbje113jvvOQSTZRJChdMDVRElawBAk6C1EhNAqmDTVQBZmck7iMMyXmuWtaKN6NpdHUuTyDn3ne/+z8MPPZRigRI/delFtbpPLBYAEIXZeB9bLZdnwJwErMuag4ONel1RQBS9a68eqPU0WFI1eASjb9uBV7GDCRksy3bmrbO24sJEQhExjmIC4ZKIqhJ4lhARYwg28wrJglGQPM+HDuE88ykJAFhnYmRyRhUsGeEozIQALFDV+AQ1xoqCsCApAhBRCFUegxkK3w2VZ4kx5nleXYyVY6eyP97OOIdaJz42vEq6KC/nUAUY6vWe5/798uevvqbdbMbYnj171vkXzi0HmwDgrCcksgqSgEwsyrynDsxEFgDBGtNBzgAhGQ8A4tEw2maz+eYPhMxsfI1DySFYaw897D2jx44jIm+1bLeNgnUZoEFUUUQBFnA+B0JlTcLO57FoWb9uOYxcBzKMFYay1fLeA8Dhhx9uPSnw2LGjYwikqIhAxKLGOQTkxIhIxooIgZK1KklVNZYsAHb9KjyLQggx7+0TkXcfcMCmkyaHlBq5Q2u8qQFxDG0sorW2Ux19faKLUJ0ORFyduYibbLLR+489emBgoCzbU6ZMCUWhGm1lnyFa72JZQkJCJwjWu5QSF8FZO7REpJPLu5btRADUTU3sZuGWMcY4adKkgw46aGCwpUhbTZ0cyjKr95RFVY+LUmREEhFEANYYg/ceRAAQkhifMceyLInIOBtjJOOKosjr2bpHi5LlPpUloAWVFErnPeS5iOy66y6HvPeIgYEB78h7b61HVUkBVclQjEzWlmUrz3NIMavXoIOEqKgpRgCdhvjER2C6EFERU0rjxo077LBDms0B63D8JuNERFLyPhOGFJMhl1K0WR6LwrkshtIYQ9ZqTBKSiBi3nneGErDEmDbZaONjjjpyoFzlTNp4XB8IpiSkxByttVE4zzyJxMAIFELIbGY9gmgoWt5kKSUw7g0e+8onuU68E4CI876yDKZNm3bMUUcUrZIkjR492nkHiJISkOGYsCqmBBBj9NVdzgxQ+b1QlcAYlQBI5CwQpVCSMZ1zY6TXcE1TvfOvdDNiULfbbttjjjqqf+WKzGKtVkspem8llUSEZETVZXkZovdeRWNIeb0REyuKJIbEeb2nDNFYVFVQQkRReRPfWsc/OPSzhUrFUM2yDFQgpn8vWmKM4RhSEps3tpw6mYwzSIlVRVjUWKucGHTlypWNRqNuvKgCAyKCoyq6LgIhJOttldyybGW/0TR27GhgIWtjSAODrZ7eUUtefnmzzcYbSwggiRNH7zOodP/UARQOOawqZHRlhSBiVfp4vVZdZ0pwjXdV5JYcSmMQRAZXD+w8c6tbfvQ9TmKMgjZjWRBZl9WKZjPPvQqXSfM8wxRiu42IzJo1+kJRIpJxFGP0CMpVHoxtF2Vvb+8bJmI4ZVRVK4JV4z1LnDplyuQttySDHNvWAgFyCikVWd4rkYnQOQdEsSgBxWU1LoPLsrdhbXTmvzIPst5Ga3l/nuczZ+5onFHohFhUEYwnMsKJWRNrp65yYiQQQBJBskigKVlL68UaCACqmue5FO1ank/fbruJW2xBloSjqoChGCM5pxWRr89gPelsAQAMkEFQA8IKPG7cuO12nD6wcqWxSATWGmYVZpfVUypB0NV6mJOKIUOckohmeS4xEWDFFouwBiH0Wm3orrbWAmjmfCOv7bzzTkVRApoYS2sQrMlyiiFUSY6xDNblqACZtyKh3fY9fRBj1Jhiykb12Ri4LAkxiTCwczUwQ3zGRMMhMyCFGII1qJJU0fo8xQitgpk33XzjnWfOKMtSUpnnFV+HiqK1JqTks1qMMfN1RC3b0VprOpvizW27Tm5zB9uCzsVY5jW3y64zW4ODgOytIU3GZWCtSGnzXg6BrI+Jra9LYkRDLgvttve+IiQUiSOI+N5us9b09fXM2GHbQgY5tTMLqGqNI2MAUkoh7+lrDw5a641xquB9jkgSE6j6nt7YbjrnonT24EjtfuiwXud0xxBcvTeVYeNxG+yy085FUUgsHKUUY1Uz0RgvzIRUpujI+FqDywAGOElVkEIAFStbB0GS9b5st5xzUrmwhoIua3YuqtCp3CUoIqggUhatXXfZZcaM6WVRKJcAUOsbBcLgbCoK6xwiShLrM0XjcichMahxBo1JGFyWAVFmI3Oh0o2nvG0NrapCDoiYYgSVBx944F2z9vz4OefOnTv33HPP/cIXv1hGBaUYoyF0zhhnEwugYYWjjzzmH39/0oIhY8gbBmbUiu/ZEDhvYuLAIAAXX3zxLbfcAgApBUB8+OGHjz766LIsTzvtNGYoiqCqRGQrBLpAYrXOWefaRQBEFrDO+SxLrGSsArIAkpU3xmPfzpA7a0SGUckoxqCIgPfGYLsYAIxle3VoDmjiVKbFLy597fUVWaPv3r/87Z8Ln83HjFm+sn+w1XK1mnWZ9fl9d9/3/PNLXa3x9IJniyKooio670MI9Xq9aIehoMJaTSXZWpbKMsYIIrl3jbrPHDmjPfWaiKiioVrme9vtoEiBJbAkFrTGZVmMUVTXdi6MCIohCOnQhh9y2koqW0gqkuqNmrPU01MnVE3ROh9Z7r3nXiAjSoA2iZYxCRKQZUVFSilWWlX5NtC6azVBCCkRUWuwP89Mb905hEYtS2X4xxNPOpfFBKJGFFNk5fUzNQDAWCxjEWMJICkFgwqoPfW8Xqtn1pVliWhcrd4uSkBHJuMEZQAWjAxovM8aoUwqpppBRBxBZ8QAAqRICsojTxYCCGUJzsUYnTeAQiTGam9v7cWXX/rm/OsXPL3Q9fb98fd/+MUdd76+bHkR0yOPPf6H3/3+rrvuLhM//shjf7r73oFm2/r6j27+3p2332Gcq8xua221MN5ivMzc4VRntt7Zep055Zkz3lhSZ8kg3X3vvc1W2/paErI2j0HQWCBTlMl4b/wIa0YJFEmJlACqBAggUOwEIVRQFCG220TgDQEwAufeWYSFC55e+tKr/3ryqaJM9959X0wMaEUpJBYk6/OyCMZlkTWxchLF9Vf7iGIsLYlrOANxVG8t914Sa8JQMis89eyzS5e+5PKagBElAWSFMkQlg0Qao6qSWZu9H3Ud/8cuSRoAAZH1Hjh6b7PcsYTMUaOWI5DtHdVsFasHW0mUnF/dbCVRQXr870+YvJYEXdZIAiEJ2IysIetEwGa1slVkWZ28j/FNdT5d0/RBrCijFJRBGEC8haom8b133XPjf9+4amW/It119z133vnrlf0DReAH/vLQXXfd++cHH0qMD/7l0QcefFjRLlq89NpvXPfkP58aqk+Dw3i5ke2N2TUAVd4Gdgo0OQhlKsOO02fcfvvtKsE61xZShYXPPRvbrbvuuue4447r7++//Y47PnDSiRtuvBEANFcPXH/d/AP23W+rbbYy3i1d/tqPf/ijradMPfjAg8gaIvrZL27PsqzKXwXVF1544Y7b75z6jq29dT099Xlf+wYCLHp+MaH+9te/3HvffbebvoOxtGjRkltuueWggw5qNBqbb755f3//9773vcmTJx9++OFDztD/u7zyIaOQAFFRqCLZKVuNnvqq/tffufsMSsY5l1Lrxv/59jlzz/vvb3/31DPOnDFz5mOPPrzPXntyaI0Z1XvUEe8jYy4474KZM3f/7g9/OmvWrMWLn+lt5Oedf5EU7VimLKvF9FYeQyTgomXrGRURQOqN2sfnnu2zGjNvMn6j+fOuG+xftXLZyk02nbCyfzDL3ajenjIUjb6+otmsKtE7t65KIeuAU+jwqBGMc9xs+5o/7rhjRZKkYubMmZ+56qrXly59YcmLv/rdH/Y+6D2vL1lSluWECRNqjay/v//1V1+ZMGGCybzNrKYQQshqjcTrYRAIAhkjUcHghAnjLzj3HLVWVMePH//Fq695YfGS6bvt+urSF2OMEzeb4G0GIKrrdzPFGLNGvRwsQHnM2NGPP/7oCUcfKQIrViy77LLL9txnryUvvMDMEzef1Gq18jxvteKyFf3f/OZ/X3jh+Y2e2ouLFmfObj5xkpYBOikEHWRqB9fUES9Ud7BqRR8DPsugbI8d3bdwwVMnHHuMoC5fufITn/hEKMp6vb7NDjt84ytfaTR6xo8f//0f3XLyySd/fd51p55+WlEUIeoX/+tLxx93wsfO+cQVV17+7ncf+J//+YVDDz3UuSylUEEc4A2e2I6vFYAAWQWsJYMptEMIDmn8xht/9zv/88tf/hJEWeL11193++13TJ48dQX0b7rppoi4aPHztXq26WabOKeSYuDoaegEXydULylEwDTk7nf1ep7nr7z64rFHHUEGVrz+2tkfPjOkNGHTSRFg80lTf/zTn+20y26tgcFarWZAFzy9cIsttqg3evpXLH/11VcnT57ofcYcUXGdB9O6Gwqo9vb2Ll7y/NGHvUepaA6uOv2kU4495riBgeLlV199x07b33Pv/TNmzBg1eoNnn3lh0/ETxoxqFGW7kTdSSiEElxs0TmRE0GJtuQ7hjLGr5yEAxLJwWQYSGz31W3/+w4ceeohjCGU5/+tfN5Z+8YtfWGtPP+2DC5959s4779xwk42PfO+RL7708jbbTheF5xYtGj9+fCNvDLZbixcvnjBhfO4tp5RlGahyTFkt5zfXkLomCAIQgRgESHHKxM1v/PYNt//8VlUty/LHt/30N7/9/RlnnN7oHf2Fa67edtttk+hv//DHKVts+aNbfnLUUcckxocfevy73/3+rFmzbr31p1/56le33mb7+//8l+2237rjn0Tscmu9DSRV5OSs894CJwAkwBUrVjSb7dWrXgdC1zvWe3/wwYfsOnPG5MmTp02b9t73HTl2w3F77bXXwoVPA8t5537irFNOn33AAbfe/tPxkzbfdc89Lr7oom9/+9t3/vwX195w3TnnnLvw3y/svc9+N3/vB/vccO0TTzxx8IFzPnv5FZdddtnEzSevXLlq7733Xvryy0cfffT4TTY6aM7sdx9wwF333Z/Xavvss8/HP/7xiy666Omnn37iiScOPvjgM8888+abb77ppptuv/32GGOWOQBgVrueIdMhN10FshtSOpgDGUTQGTOn/+PJxwCNVass5OyTT/z9oIMPefrZ5zadOGXueRc2m6tfXrr4D7+5A60h5zTJkheX7vGunquv+WIZ2q+/st2f/vAbIMsK3fprxgyx0Hd4yIaXrCib3HO7ILSA+IObvwvOJVAR8S575cWll1z0yUMOOuQ3v/vDfgfMfuCvD1z6yQu//vWvXnPNNTd//3u77bLztGnTgEiZ38K7MAwLwYq9TgBUJPX19f7yV3ekKMoRSazPFi18+ivfuHb76TsONtsrX1t21dWfnzhxYl9f3xFHHHHFFVfsMH27f/7zH1/98pcGB1c3ajmQckpvWRF1HY2Zrbcaym/deAMICJIaY6x/7aWXX3t12RMPPXLHr345btzYd71rz+22fIewrK8+SoSpbDlvQzFw4Ltnv/uA2YSmgpGAMT/98Y+fffZZQZg5c+fXX3/9/cce/5Wvfenww9/35D+e+ttDjyUOLy5e1BxYNXv//WbMmKEpqYqgGlQlHeGlGQG5rgSsoJoAaKedZt7/wP0KnFTIOOPcL2772ZgNxoHCSy+9PGXK1J123vXgw454/tln83pj1erBZrOJZDcZv+lhRx75+BNPPPfvF/bea49GoyEiRVnU+3q4jKA4HMJ9w9kinKwxsWiDkqs3UquJqOec89FzP3F+uyi9se3Q7untabVav/n175566qlPXXzJn//851WrBl569aUjjzp8q6lbOJepDhG6DJnga3nWuZO+3sk9ktRubT3tHfc9cH9ZBoOAKsbmt/7oRzbLn1n4zGabTuzpHVMGufqaL37mM5/50le/us022/z2D3887rjj5n3tqzNmzHjplZf33msfNBbWUy0Aoh1nTL/rnrtSCOBKAqGs8YNv3bRwwRIwZvfFL/T1jmn09D74l7/1rxj48Y9v/dAZp15//XVfuOaLN37rm+/cfbcddtiWrG21mmRr69Wtq0iAVE456cT3H/8B652k5J0Dhr/+5S+DA83JW0wxzv970eKkMGbsOOvzhc88N2HTp+fPv3bmzJmrV6/+xLnnXnjRJXvuuee8efOuu+7aWEFdjEkpoRK+6UKXoUoKFShbRZT5E+d9/LzzP0FESBQTO+edy0aNGmOtf+75F6bvuNM+e+49evTovz38SJ71rOxfba0bM2bM7nvscfKpp5566qmqlOV1YxwaBxrW6vJ/5Z8lZ6yKqGqKERB9nj311FNHHXXE8ccff9h7j/jm9dd7a1MK86+//gtf+MKGG2540Scv+cIXrq4C0bEM1339G3PPPfdLX/7yt771rZtvvnmfffbZYYcd5s6de/PNN7/04st3/PwXt/34J5+8+PyDDz7Y5/nXvvH1T/3Hf5xxxhnXfv0bA6tWgeroDcY4B2UM186/7vwLLzr80EMWLFhw0003nX322RdccP5NN92U53mMcdGiRWPHjv3a1742b948IsgyJwJV1HO95r7ThlVGrcwyAUDjGBREORQpFJqKGEpJMbYGyZp2u7169eqJEyc2W20EM3WLrYoiIBhQaJfh5h/8cPGSpccef9yf7r632Wxb60GZJVnXiduvYW0MlY2r1gQAVNAyFA4FALSbgxJKZWkODqDC1ltvfczJJ2+yySbHHnvszjvvvHL1qo0njH/88Sf+/dzz22+/g/deOp6iisqAOl2MdFt17iqk6jXV7xSJqGw1UyiIIJYBUrzvvvuOPub9xxx73KTJW/zyV7858qhjPnHeBYsWv/ib3/7+qKOOOenkU/v6RoPzRFYAjfOKa9BBQ4fcibqdVs81dNQSKFl0khgANKWyLBGRYygGB4jo1VdfNS5bvHjxxImT3/GOrVmrenZr5uF3PxQBcPgOHs55riI0KGqt5VimFMpQIEGrOZDa7bvuuuuiSy+95FOfrtfrwpCSNAeLyZOm7rHHnrNnH/jT237e6O1bvmzlv/61ADqRnspSxJG7eg3Weu30i1XZItTQapbtQlNstwZBOYTgXKZJrrjyKmPtlVdedcmFFxpnkWjq1KmTJ2+hqi+99NLln/50b2/vnDlzlEWiIGLus3JgMKVARF3Nl4ZXToWiVqiwlc57Y0wsiyzLQlEyczHYzKyJZWEAgXmD0WPOOOOMnXba6d+LFv/qt78ThFWrBhYsWGitL4ow7N+veumgxYa6W8cus86lokhFm0AlRY4l2E5V6RUrVipiq9X68FlnXvP5Lz755JPPPPfvJPzUgoWDg4OD7SJw2mW33QVBZC03MwJQp4LemtoVdpKigIsSQWMxiJCkjK3BJjDHmI4++ujzzjvv4YcfrtUazWa5wQYbLn3x5ReeX1yGNG7cRg8/8tjzzy+aMWMnEUghZFk24gamoTntxp0rCViAylNXeXdBUmThEApnKJYlgbQHBwCkv78fCCdNmqKEK1euBIBJk6YMtprtdtlut/fY811nf/ScVqv4zW9/v++++594ymmjx2wwuHq19U4JFdg5Z0boXthNIK0kr91NLVCldVb7KYGwckih3W4NhlBWPOdINqb0X//15SVLllx0ycXXzr/eeQ+EW2651WabbZZl2W9/+9tPf/rTJ510EgB4n1lrAYercQzR61Wr+i3Kpliu0twQbZaDaLMM75y1+29/86tO4UOkVruoZc46ShJt7vLct1pti0QCo+s9m260CSCMGbfBsuUr+5avfG7hc9+98TsZ2Us/c/nAQHPcmLE15y3C5pMnBeXlqwe22HJLADO2d9Soek/mfEqJFbIeD5BAgnK0hMuWLdttt91EdPTo0T09Pc65P/3pT3Pnzj377LNPOOGEr33tKyEk5yzi/5G1ARBK9RkBgMSSUAFI0aowoUMEA1irSGmqYJ3LAaDZHNh1150/+rG5p59++qMP/+2HP/j+tK22KMskjO1WOGfuOT+45cfHnXjyBRdc8MkLzmu322CQVJgDkSWlEdkMBEDGOOAqaUAJK4pchAqAr5x7Kx0gsluZwurV/QDcLgZSbMayOdBc/f7jPnDKSadfcuEFxvtYDBpwykDG4hYg4QAAIABJREFUiipRhcpHUCPM1hAQRlEVC2xBHQijUQC06EJM3nlVFGFHBsjUs/y1115bsar/xZdf2ma7bZ97YdF2O+w42C4mbL7ZfffdX2vky1f0AxArJOlmhoiiIeYEoACWE5FFVGvQAQNqh3itoly1aFXUoAEkVXWOgMVgVQ9JB5urp06ZdOWVV86fP//1118/+bTTy8F+i6QcrTXCERQAbRVcNZSBGuhUBKkI1FFVgZEqNntBQiSq4DfJOWO9zbx7dekS7zIO5eDqfk28ctlKTfrKy685X280+qZts90Be+9NyMAJQMk4TAxsJGgXs2dbzdV+tEuaAKyoYWaDJCmQ8cBijSFjonBuEACt9Swgig8/+tiJJ59y4kl05plnhiR5oz59p5mrli1n5g02GHP5564sm80Yiuo6R0IJpbcoIioCQIgkjADErNYid0AvpKpkbJUeYQFAUmYzQTAGOMU8z8pQgmDRaodWMxQtY7B3VM8uu+08Z87sWuaAJbMOVJmjyXMNEpPmJk9iCI0kBSCCTsVfECAwaBWSasXCmVSYyZCAAY5RUkhllISWyhQPfM/B8785/9CD31Or1+ccdOCMnWaO32Tj884//9FHH/3cVdd84YtfbLcHnWISAedSShVgQwSMAVUVFTAEZECqZEMW6eRpOYvCySDWfQ+oVdV2bD6/6Lm+vr7mQFHPer/8n1/+0pe+XBRFf3//+4/7wOmnfuhTF1+ibAmdaCkcISEgEICyAKAKCFRcc5hEFB0IVXWNERBUAJCM7Ryswp6QBIzzqrrvfvvsvd/emc+B0+GHH4qI3ueDg4NF0Uople2iKItW0R6/6YTbbrtt5syZL7/8ar3WKMu2JURjK+AAAkIapnxDtAnQgEGtWAmQnFVlFiUiECVVMqgIxlhWICJOKgJFEZ559tmPzp378ktLr7jic7u8c/eNJ2w8bfttReS+++571z57zT333LLZQhROpUoAjZqSsUZAOUEtr6WUQJkUu1lfFbVDdXNplV9iqyi0iiBVdjiVZWmMaRXtWl4LMYCkRqPBzGWMzrnIqUI3EcLKZcsfeeSRd0zb+v4H/jxt2rSNxm+yy8ydrp03L7bLb95ww7Rp2yxbtmLxC4umbr3Fw48+ste+s6ZMmfLLX/3q4DmHPPWvfxVFQNEsywTBOUcGNIZGrdZqtd75znfedtttJ5544t133/3aa68NDAx85zvfueeeu15++dVdd9318ssvz/PcGPN/gL4FAFZwGZZlaQ2QAwAJKQpkFR9AlwelS8MBICkwx96+xqTJE0895cQPf/DUPM8/e9mnn3ryH7f++EeP/O2vc+YcdPbZZ51y8ol5o+8/v3DNkhf+XcGF0aIxpl0GtK4KeVUprB0aWmNEEjMYY6paB1XXQzxXkoJxWW9vY893zQJIu+2xi3W4zbStNthg7MbjN9pkwvh37bNvDG1AUWGT5cBMBlplM3epYiVw3pShjQacc85lQLaK8HKKAEKmYiiS0IXoQQgHH3zgf33juoXPPvPO3XY5aM7sr37l61/78pc+eOop2263TXtg9ZNP/D3zFkAMAqp6b8uiELLMPETy4xwKKwBUQ1ZVJMQqxSwhgxqqEroEETo0J1UJT4QDZu+74F///Mltt44bN+6QQw6OzQEiUlQwBAYIqjKrBGpFJKVUwU+ICDCJpoqZsRvUoaE0ukp/M4Scwty558yff621/sILL3zooYeuv2HerD12Gzu2b5tpW375S9dceuklN3xzPkI66ojDx288TlUqaKwIWGuJKKYIiH19fcwlGQMAxjhjjMYw5BHG4fxHBZEQQqPea5x7cfGS23/+C2PMR8768AZjRo0Z1fu5yy+TxB/60IfeufuuqT1QtprGmFqt0Wq1KqCnyRyUIiIgoqouz1QkiViokuEJCEUBOmVQhZQEgFAAyBhUFY4lAIDK7u/crZbZrbfeqndUz8fPPeemb/+Pqp543PFjRvUZgzGWztnWqpX1vjGWbZWgo9CBxQOCMaYoCrA+JrEEAoqiyFXSGHFiESHm6dO3G7XB2B2227ae+b1m7XHiKSdeN29eT6N28EFzvvSfXxw/fvycA2d/5zvfqdVqp51+SghtAkgVY1sMeZ4pM1hnCVgAQMhgjJGZgcVb6piUxkhikWicJ+NbA816XjfO3fKTH/SNGfuxj3780Ucf32Ds6BNPPPGGG67vG9Wz4cbjNt18k80mbrrn3ntFDoTCGr13oApl22AnsQMNEEDSZACtNYhYgTiFC5VoDCpQlzFteF2hAghbBEEETQDkiRQBNXlDM6dvP2niZsLRIszYYfouO8187ZWXH3300dGjRwdOVb5X4kDWppQUjM0MS9eyUVY1ilhlPoRQaCdhHxAMSALQlCIgGo8hJOdIgHvqDcTwxN8fu+3WH9ca9YsuOJ+s6V+x7PNXX5Fl2ZFHHsmx3R7sD0WZ1TewRkG4SmNsl8HnDbKGWRCxO743bZZTMtZWZc6M9S7zjz322MyZM7uJhebee+8tisI5Z4lSSs45ay0zg8KECRPmzZt3403/s2zF8j/88Y95o77/7AP223//F5557n3vfa8qzJ8//z2HHjJp6havv/rasmXLPvvZz+6/91777723Jt5ww/EppcHBQQsQihIRMcuScLvdPvWDH7znnnu22mqrLbfccuzYsX19fQsWLNhpp12Y+fjjjx89elSMyRhUxf8DJxURpCRZ5pjbygwAtVoNKrNQlTs3qwIAqAqKzdyo0Y1f/+qOE0444agjDjv62KMlFCnEfffba9/Z+4CkirznXfu8i0UR8fJPf3LPPXYH4cgJEbNavYhqvAGCGNrO52BQUCRFss56TKmqYU7dxdh5FjIYUjlq7KiD3nNg2Ro47tSTwuqBfd+9b4jh0cce2n//vfO+WjmwmgCMNyE0EdFYIo9olDwChBBDlucAoBpb5SAQK6kAk0Ukl4QVCBwatCJMTsuiWRvV9+nL/wMSA2Is2xdecj6EoMwrl7327wX/ahetY498H5TtzIAhhVBYQjUGiNCAaABwZUhZ5pKUZJEyr2UBZFUECLHKe6oQINq9xLGaExzdVz9gzgHAMGPmdMgyKQtlAUJVADTMjArCSpbIGqyqwBFXnJuSSmupCCXZXk4loBCogFbfK3mKiLPZ+E03ufzqK0GgLIoLLr4QvQeRYmDFRy84O7Wbqnr55/4DQMrmAENEi8xE1pJ3ZYpljNYSALVaA426F46iwqoaUvVA3YA5KUGneoPq5M0m/Pxnv9hqysRjjj36mPcdDnkm7baqfuY/PgUAYB202ycd//4Uit6ajyzf+953x228UQVHLotgrXMuA2PQYKvVRANIDIoiAtZwwdQhINPOV0VNAkpkina7p9FDgKEsjj3hOA1x7/32YoXI6bLLP22yLA4OiiQkJEciKe+tq3LSBBoFQzsMIHFM0SgiqfcegJxzwtEaCwaAgYgADDEbp4Cwww47WJ9tMWkiAJx48vHN5a+ffc5Hw+r+9x5+8HsPfw8AAMhVl38GsgyKQoQFFa2LSUVSiAU6k1IgskQUYzQGIwck8vVau7U695a8UxFyhpQCR6tc760DJsH0oQ+fvuU7tkkpzT703cXA6s2n7HfQIQcAcgithx5+YN/9ZmV1LNvMEn1uYwxoLOSujAVrYgmAlhBUExFZJ1EK0BA4eFKTOeXIIArUwQuoIkjFGIDKhtAAKScAcBUeKXHNmSOPOgJUJ2+2SUrhxBOOLwYHFj337ECrfcAB+2W1vNUaMAZtRU5sSIHAOyJCQyIxMViXE7BqVIi+5lsDg8YhiBah7YiMMTZzABBiMMYAhw3Gjbrx2zecduJxH/rwGcAMmZd2SdZedcVlkGWQhNvtLSdPBNUst68teu7XP//Z7rN25zICuVqj3ioiGZe4U15kXTiFYWoiazpKkyFjYoz77LNPq9XqYqs8qxDSk08+acgAwD8e/3tSIIR//OMfQHDnr36pLIteXLL5pImAWKZ4/733LVmyZKMNxvX21CXpe9936H6zZ68cWL3h+HEeSTQ++MADLz6/ZMoWU6sivEsXPx9F//73v5MwSLruxhsB7b33/fmkk0668cZvvfDC4gMPPLCvr+f2229funRpo9EYM2YMInhvY2QAEIE3MML+781aCrFlDCpg5DTYbDvXY6iyx4FhBMpCodW/esNxG9/1p3vaZTkw0IyxP8sySZFLiCl460IIPsuNwkCr7V0+/4Zvxli2mi3r62WMqWwJ+BgZQNBgTKUCIxgkK4xF2anEx4rQYdyHqp5kxcQZW6FSole+vtxb11o5YL3Zetp2O+6w28DKVYhqLUlMCiYmRkmsnOXUareBiJkjl0SUOFprhbVdhswBiqZUusxH1jIFY0yK0TlnXa25elCRvPecBADiihUi4lxWq9XOOussJKjIXTjELKMQS+OyIhZlGUGJyLCqMaZy15YxxCChEGshJSHb4c+rON6GbYGuO5mZU6vfWo+GYrPVIQioNEFEEEEkZSEEEA4xKlaHJxuLRC6xqmARgkMARYbh75U8rc2bRWGtbfWvtuQipxhEBgYqAPrrLy2p9zREpAhFSsEZy8LOZTFxUaZe0zCUiQCCEU15notENKSCSQQEKy50IhBWAEZDDKKqhssZM3faeaddRCAMDBRFgFWr6j29rVYzSxJjSWBEUpbVUooikISPPvaYlFKzHYw1hqgMwqHoHdWrqmQRQIwzABI4Fc1ClCpziKrazpXdpiQIHFNWb7TaQREJoDnYIgAJsYqtc4Kif3W9lsXIUIp1BCwaWUkEUASY2XufODnrAaAIIXIKRVGGSMBRCEVV0QCKBAG1zsSizLKsOdgCAESjrRaiaS1fXsX2ODBShx+IB5re+yqwoaJFGXvHZM7nZdnKska1CbxzAMFaW5ZlWcSeWr0MJRGGxFlGKSkAMQCHNll/3AdOjDGySuRUrlyGQEXZ770PsbQWtt9++5kzdutfuco6IsBmuwTUot0c17tJUjDGGGtjZLDqySpwFXIDxTKmhMmriSzWWqkqXlURGCVRIBAQrcprSkUaT5U3TQFEQktVjTFJhZlB8dRTT7W+DoStZoFkAWmw3SSsDFm2PpQpxhiJTEYmchLkascBYlEGAKsiqChkE0soCmstGpNEB5qts846WxJnBHGgVcRARAJqjUPEsHKVtVZVpVUgaub86NGjP3P5Z0OMLIhk2s0IZECpst9TioT2LcpZWOgUW85jjM5lzDw4OFir1Zxz7XYbEb33HFPS6L0vY7DeJxaDmFJVx50mTdpcUYEg805UNt10vFRYN2NVMG/k43vyFGOAWPNOSKZsOTWVAcEZb4uSnTOhLGqZF8VYFsbmG224waGHHjp16tQFCxbMnz9fmAl1yuSJMUZnqTKMnB1RPXF9mqgAiLVVHTCT+Ubf6A16euudyG0VeRuRi5f1jAI0mqRGDZvXOlqdMIDUrIGYclAwDlhHZ31ExMw+qwGqcnQeMKulUsg4FjXGRY6AWO/pQZvVGmOgQ/e8Ljgg2WG0PmK9otAhAk3MiuCzHFQKJAQ1gJgTAQqXbXQ9edabotTrvYkToVEwPb1jItOojTYDLiGGLPOQxBsbQrDW18hIKgmNrQ2lBFNFHGRqNYgCBiQE8p7LMusdAyyAUmMGm3nBIKtCF4ZLBKqSVPpGj3P1PuccZDaTESky/x9v7x51W1bVB/7mXGvtfc73uHVvvYCqwqriVfIIUIA8LKVjZ/RIbO2ABsFqDSo2Ek3zUF4iETEqER2QgAabdKLt0PjARoiEkY7YZkhEweALlFcBUlQVVN1b932/7+y915pz9h9z7X32+b7vIkboPc4493zn7rPXWnPNNd8Pz344fHHtGQuzBRFi8ApgJkLEMEEgiIGCCm/vnsh6j6pybdLKIrZz7KqdK66EDptVAMbLLDXHALSmzKmGtGpBUJDtWFAVb3aUS9+0W5CCYmmn3eKkA3Z2rzQkEYQQc+5iIqYY2q0FEJoIk5kPGWCCCUzAjEIwQ0iSu2PHt8DAUI7tHtcut7sMJdXMzTJpRrEmRhAQAmywoacYG7BkQ1ikscSIqiLR9s6xxRVXWrdHkUa8xca7qMHSiUaHnmMLGMTLwRkCm2L7GEN0aQb2Fn8KERj1XeF264pjVwMxhqaIxBBibK48cXWz2IKWZmtZQ6vc0u2yG1krArO0DEgNxCADYgs2DAMCWVGKjgBVlTdValtISQtoQSnStltSCnFkRpHCZCm2x695UN6/wIxFswOihhmqiSPIIAVNg1IAiyIhpaZVeMVJs2EYto6dgGUQaQnt4oSJUGTIPmLcORGAuL11vO+KCVJKIjlbSTHC4vbOlUXDFdc+GEMHK03TQAS1LQHXOAjPuxz9yd53FkxQZgJEKo4RJSKYlT4vdnasG6hJTRk8xqJdbCM2AEEJ3Jy48toyVgo20aZJIra7c1XOuPLar9DScQgw6DAkULvLCARTK6qIgRsAKEOAphCgChiaBXJeMEMVqUFRkKIIoDBqFgEwVWw3RM2y3++admvRbsWYVDarz1c6VL+IADwN2OU7Zj527BjGkh6eoe1pRwCamJgYXgQtRqhpKRyjmspQUtNkkRQTx2SqRDyWn8KiiQzLpfdR4qKFshGaGJixbBdmBgrtIgF8yy23fOITn/jIRz5y4403bm9vD8PgNUWcKPtMXIShKa/yi76YvC0qFxFTPXdh78d+/PVXnTgB8rS4NR7US62ocFyIgkLMOacQQmDTonmAmberyGKpbfucg0seIiFQCKHrhn6Q8xf3A6c+ZyJaLrd/77++D2pkBWp6ZJlywHeEjfvSt7HtS8/GCIiR+z63zU7OfUwmIlIopZRzjomNClNz9+dOxbjsuq5tG4COX3H1z775X99552e7SxcCV+cKh4QQieMgpY0pDx1EQyAliGkKEUySq+N7yLltmn4Ydnd29vcvwdsBecWqkC7tdQY2BJGsqm1qQly85S3/9qYbbzDpYyA1ryoWdMxAmIeWTXUqVdUrVxrYmXcufRMTAKi7LowQxMJdd3/+aV/7d5mDmg7D0KTIsf3J17/xyuPHvbf7DKRVq2GOOfchVBNr3/dNiAgwGRCYwGK1yKAbxGINbuG+KzvHr3rfH/7RD7/2Rzl4Yc1AhAuXVq/7iZ+W0rVtOwxdqH2XGfCiyIArHKEtY9SJuJBMZECKUbT2KFURB4KHYxpp5CCSI0WioOB2sf2ff/t3n/sdz3e7CBA+8cm/+pFX/8jWopmvcf5OFFQLwFNJN6+QmlUWi0W3GjjWQ22iQ+4ATSmFEFb7eWf3+H/5vT/8jud9rwiYopru7Bz7rf/4n8xs6Fd9v2qaxmo2EhMRApcyxMgixiHlnM0spaQiQ87bW1tFMyOExEOXi+ZFsxQrKTSrfj+FSByZ08W9HqAQmwkZYkon7z/76le9ZntrEUKtBSvidMAA5RT7vve8pRibofSRg5FCSaz4klOIIsK0ACiEYKZF9pumKUWXW8d+5/9977Oe/Z1iYAVRaEJQ2JVXXvPmf/Uz933uvv2L59o2mNlq6Nt26WEW3irN9QyvFmVjSUQlTJ8BZkZtXORZoyF0Xa2cRCrFNAQys5xzSI0pLbePvfe9f/CKl/+gmqlYSqkU2d058du/83sxpkuXLqYUutUqpUREVoQZWbN74FUx9CWllEu/XLbDUERy0yxWXcfMsW00F1f1mpS6rlssGlVMJkFVVaMQYjeUT33mTlEvhHLZ5imkJgBEJXBwpK8sYSTN09lWLTF6OgIxSEQCh+J1vwNjlk5W8pBC9Cq5iBEAqzKZauEQRMwIkcdUBkXOQ2wSyIqUyGkqA+kYH0IYhsGBlb3AZK3l8N9TAdfNbipiZjHQMHR33vmZ6NGTU/H/2f2llOVyu8sDcSQOq9WqbRpmkjLEGCOxiOScU7vc77rUNDBlMjb4tDk2RPTA665bLLaHPDSpUc33fu7zZeglF6Kx5c6hS1VjjCZmZJFj9sQohpmk1A69EJGzDVgAgMCqAiqweOyKa6+68ipmeH9MJrvn7s8Oq32CeKdUAGIoqp6NzKCUYmQMUtQspCi5FJUmtmIquWzv7pQhg6lfdW2bpu0AwAhd1z3o+uuvOHaFgoppAEkZPv3JT+1sLcvQOwNQmO9UuXy9EO91IyIxNLn0KbYxsebBi8U6MnBIzHFv1d14802L5bYLNww7f+7cmftPHeiWU9ELDGgpSmQptaUUM4sxphCH0nvX8r7PoUmuZRrEt682AAYpqGmXD7r+BinWNlGLcMCpU/de2rtgJTt5cpYzllMVwIPFTBABZuah5EXTDiWnEMXURItKE5PCIoeccwhBtcCsbVPpByJiBHDIQ0HgxXL7+htu8HOqmi+cO3f+7NlAGNd7kG0ALJJDSKWUxWLRdV3btp7wtL+/3yyWWbT6L5mZ3QxoOee2XZZsi62dBzzoOnbvN4ygd9/12b39i2y6tbW1t7fXpARjreWpSCSHJigoF42x8eJyvt5ALFZMIFYWzdJIJatCIidfLxER4vHjV1511bWiMhZsV9F84fyZc+fOWZGU0jAMZuSriCEZtJRSStne3s65H4bSLBuIFitNaIoVVMqNplms9ocQEjNKGULEIEOMjSkFXtz0kJtr0XoXpziWop+7+y4tg+gQmYpKWrR5EC8vDgDqXRoBqPDROQ5EQSSXostlOwwDAI+UiaDVarVoEzF3/X5smpTa1WqVUitKhPAVX3FTSmmirjGlz372r7pun9x7r+obKiLMEBGRHGMjIk2zEJFeynLZ9n32EoIhRSLqhqGJ0dE+90MIwUxUEQKZFidisW1UMWS57rrrdnZ2XY5nHE1dSU2mSsVDLiklZwmOUlPAUiklRlZV4likVB4OIuaSc2ySAaJCHEQlcbAxzCkbmBCgeRhSimZKHLU2FqDq5wwkKhklhcRgjMUKnXnUutNONZinmrh+z+Vo0OUut6YEhogFJimFmUFKVQw+IoCg73PTtkXUKAQmcxZrtex2kRJDI6ZGgUAqQwoRQMk5xlatsl4KTKB+WDVNwyAYyzB4HdCD5oURDU2VzDwaEURWyrocrAYEqGYOwQTOtl3iUwXMq3hJ0wQwRAwmMTobKQipGmSY1KZ1KzMMYqhOCIN5UUwCZZNIPEhpQyrQADJQyUNKyUSZowsEAAvM21UzAtS0nt5gNlZ6v4x26MQ3MLtVxNOanOehZkUAHgzp0CAQSF17sZpCUasmU+2RRzNrmAf9lJxd8K910R3a1TZdp+EpAqrKgXTI3KTa3o5D7USiIIbIEKKXnq65Mrau0FBqowozATu+glhKDjGpFArBvyFYVonE7oHwnPNScooJZkAyVRGLTRCr7ZIIRF6Om1n6IaR0BP4QoIbANcvd16gGImgBs6qRRz37vapO/T2FizlNpcoVMKg/iMg8ggbwYxugpBAPyVNTEBmCQhmu08NADEw4A1MQ+7sHxtU6/1o7Q7sh1lenWph9cxlEJuMqmAgkKoEYTH2376EfY3FyLVliCtXUoWRGABNDBUSgoGpeoZYBNnNyhxCsSIlhIQVMIEYpfUwJZqLKYdZRA+6UUxAENjYLNDYYUQD5egUWwV0Z2hgMpFJiiCbG3lKFCTA1HdsTWAhpGErTRHW01rqbw9A3bQsztcIhwDiXnGItfl7jYkFWlFIE0A1927TZJFEQmJoGCj5Dn38Amdlod3FbG0QFQOCopkSkRkxMl+nDRmIFgFt1/bmumcy0Lbi6XY/E6BTavGGD5c4Jg9SslTF4hmDk6bbEXuZCPW2JCsyAMNbFWD/5cIubL981msXXBNxspFAQtcDkEp+XhplmaEROZMO0+stBZKxM4Zd6Gt6Bgz9BW9QPCQg2pUw7WSYa7WkeTKNjA2cw1ig+Qn0m4ytZTZKvNmrHDoNUJTKMbTZCLUBrBD6iqVCdS/133d2J1wNbXa9NhTls/Rv/qh5vP/NW996/NFUaYx68I0JNy/JeqPVimj0StT3CQQeHgzTnPsZIRKUUZ07zotmeK811qusUwnGnzGs0jY111yVx5/BZ3w44GDkkKYUCB2IxDcQTDFVETJuYKvmGUK1izcC6kOMaenU3Z1trtmaT83caa/bWZrEMr+LrwKpOIZbacZvGx07rrfYDjKiIUYual6BwiIVR4lZTJmRnewABRSVyENNAcVyjTfPEX3+u1xhed98AwgTP6seZNVlwHctNQy6I+BJHswk8fm+Gq14dRkeApvnQNq53Dheng3761KNix2crzK0skYPCoOKQX69Tx72kjefPr/VJwyYSb5y+mjpeYWhmJsReN7q1cUStjRsPdMmdj6ibwqqPYuNiZ1mudb+OmvFfe/1NifcXGOCwx2X+xxeo4/S3u44uzjWfwoziwQh93/dDz/AKVjVx0yFLBgKxC5ymtEG9Np55cGjP/EXNpzHAYGJq3olmND5QYM97Mu+rI1K7+409i9SKWNFNy88IOp29Zv9LAJBLLYFIY6IzTTzDbOh7JqpGLlEyYMznnd4nW6LPZ0bHdZzgIVD4L3kiaej6ztmDqkopIFIdqzdXYWr982lfRsxZU/b1cFW4maBaL4enu2T6vo8xmgOK3DsLERN1e5iJyEZKdp04jaaJ+YNrWuzhEf0KIakIM3smcO4HqPVdp0VMNXBoYur73pesZRNUtN6v2TXbUHLnAh1+t7Fbl2+SqkpVjGrUg5j2JZdSitaA6M2Zq23gjwPZ7dhEREVM1CN/rYg5BjKxqQZiqJILBCAz87VTBShhTcUvd02D+rGrcDCD+kyCG1pVVAzwKNDKJ0Lq+14VpWgt6kNqZMSgqT3jBqnRywyN+SnavMODnM3MeESgKkqIqkMAMFFml2lMRYrXK/TBK52pJWsO0qM1Mm+c3xld0qJiAFGo9QuIiNm0xJT82OZhMLPcD74LPiZNEr+OL0yE7W/AC0hMNzsL25Haxuz56ADZAAAgAElEQVQnk/RnX4wG4AGllcy6ik/BqUKY9FIATAUwWMRGP8VRqPmixvoirmkPDsPIw0EP2IjXoCmjy0dE3JdlHijPPNaeAvPYWRE8cWyqJgMZPzu3X2cUCoTXd87m6pKpGY2dRVR1bH/N9RaYgWfwUYy646bwiHFWdW5z2XRtoxANIVguFCMAGJkIxeiE72iIsq8ORyHJ0T9x84IRtAjH4IP6f/WrjgI3qQFBysA1GeLwc6p4OIMYrwXky4gFRYrDcxxOh6GM2V5xDnzX0yfm9AUx78gSDHUC5MYHDgBKzqWUxXIJEYQAQEXIjGJ0adSNvZPCcWjVujmT9f8eSYHVqiHLbRFulICZaSEiUDDvjA4AEJO00Q9rTTTnI44DOZxtk26IKsiUiYgZhlJyjElVTCmsk1qmH0wPo9mJw2GMHWdSD5SqMq/tqKrKHEUkhmg46MNdrVaLZZjotM0r+qxRdILqAc1yGn0tcVfPxigywk3BMc0VZTi/ZPZKox7v57231ZRHVDe4IdBH5TCbOR0BCp7Bf+Jq1cIBNSIjMlNVBRuP59frsau7BjfhP67mMl3P7aCKu8ERSA8J9XTopiPZxhd9TZp2lWjc1GKXZxs0UzW+PGzjgAHjsieQAO9IFGI01TofqlZwAPNa6GOm/brhXUWvyjZsJHM0KoneOsEUGjZOYGUMojlyEsnM0R1f1de6CQo7dIanyfu4E5s5oBGLChExrakAASZKbKZEzNWQ7WRurqOiqrUGL0EAO4JSH+Acay2/y8MiNcU0EBlISk4x9UOfUmKa78XcEjU9c36ibDYbjEdLD90/yxJRMKPvM5F5TMschuOzDlLtTXp68CzYEWuc/mRvXKtFJnqRu45jDMzul6lAptEgSR6GfBh6LhDMiflcFTvCJe7vamVyj5NVj2OtRzhbBiPMfoXxyTqq33OyO0k8bvVa495kzNKsAomhGfVFW3uSZu8T/mxC7yDDsg2awwYxI/baAxPnU1HVFJKqhUClaAje0TdPIqAd3FnemPYM1DMPJ0/MlTcmicla4+3cjQA1MWUQx+BBkq5+mXmxfZ4Km9nMxK1gAGHNnKbYnJlG642RZjMEIGrM0Y+tqrK3iNPgPg9vu0uB3bg9QR3YoFqXYxuHIXNZtnG5m+bAqoEPm8vCUcxmnKWuJ1odiv5Rxkon1fsm4MpLLs82/tb84wtaqIBDTLF6jEqfY5tMqhhupZTaYTBgNDRBYZgqtirGw3lUFNt0dPmwhgGAiExAVJsAi5hnxfs3GA1EVB24jjQHG6W5AXQ0cNcEh42xdLLjQ7U+U1WbJs5OHcogsQkHWO3MHnq0FHwIFz3rjldDjk0bgKyamAcRBsXAAFZdv1i0Mo/wITCUpqTAGVE7Cgm+kIqjCkBLUXc51rBAqWx4tOoYkffRtjkDGx3HMLLJgXTUWBvGhPl8vOCKJ7W3TcpFUgxqVd9SVRDF4Dm2cwLhTzNAD2NRJaZr2+EGSfakF4+WmY6MT8CpiSuaHpUbvWr6nEyt2cZB7Xw0lZiZjR3rbH0wlcDEYDCGodSwKCL3fxyY5Qi0+ZHcYFFH7rKqjgEElSaYmaNrzZVXhIDVKi+3kqFMz6TLYMghOqZ2FBYdmIxVkJqZpchFLAbyXqUhspTqM/DQxdo4J5BVRUGmZ9BsHzfpbWWfhtE1Xdeh46qJmV1kUzVDBsBIvt+iGiPnojHwnGX/d19WBRfG5djGFK00rmSDbUzL+5uxjVFSGo04NVZ9EmMPs42JVcw//63VjqNEwrV8hwNYlbOkFNz2f+nixX//K78UON12222PfNSj1mKSWpjbS6ewfTcH2UH9YBzYkWYSeCfVBACkaIz80Y9+/H3vex8zP+MZz7jqqhOlaIxrIyGANdugeAApKtJpVeawuV8erUHjh/oDwnv/6/vuuOMOEXne854HszGgjuZL2GQJjkwVdHN+vyn4K42yuQK5ZCfWgcNvvuM3z507t7u7+y3P+pauH9o2uV4NsMfgzYyH03V02PJcprnctb/fvfOd7zx37sytt9761Kc+dR55MWpOHvuwNk0QqkMeAFhnx2+tDZh5O1WeHY21VO7bWrLk3L/97e/Y27t4661PfMpTvsoFglyUA5g2CKWtmdDRwkcdwg4Zk/xvqqh7770n3/72txPR13/91998843AaDCenXZg4zy74jnTNnCYbYjmwGH2jPUB+PMPffj973+/arn9f/32K67YXSPYUdfojuYDzPgQ26j/K2LMYb7JDsPVqv+lX/rFGJvHPe5xT3jCrSML0RprtIbRdHzWEJjw2cZs1yMEcLOJShymfqgRlfEDf/SBP/+zD4P0Wf/o2VdeedxDnOYqUeAw8oy5d2Be6lTnJHc8vQyv+kagqY46BRhKATnRJCPQRz7ysT/4g/cPw/Dc53779vZWJbFHWSNm8MflhK0NAMzYRuXVBy7P2PCkGzMzk+k1+9J09qq/Eq2OxfHL+kOt35TxpVrMxCybZb+nmGVT3XysmompjN/PP+t6iL/NJbP3af3rp9dxRYah+2//7QMO/H/2mleryarviorPyrMB6vLVjnimHJx0/avCQUTyBOScexcM3/CGNwAIIfz2b/+2mZVShpLFIWFi429NB5NiovUBdSqm5inbpW7o7FVKMZNpwmXI/Wows//x7/1PIIQUu6Hf3983My1S79yAlWyMMq1R1pvkiLJGAzVfZt+v6o6XoZThSU96AoAbb3ywSO66bv58kbw5lqiJ+nImlDyACjrOYxM5SlEH4Kc+9akrr7ySiJ7//Oerat9nEfPaiDn3RTq1YRxr9mCdvjuEezLte5mQf37bqt+v0Db72Mc+sru9Q8CLX/iioV/lnIeh8/91XDqMhuMoWvf3IP6oA+TAZWZ7e3uq+u53v9vJ3Fvf+tau63Kpm5LFcamYiZYRE4qZ2AxbxIfWzZlNf3rSkhbxsz10WbL+i594nVv/PvjBD6qWvu83sWXjve7XtGvTiXOIznDJMXmcgHpSoZl1Xada7rzzTmdOL3zhPy1lGIbOEewIKjFSsmlQh+y49KLTKDMImxbTYZyDzDFfJIs4MpeXv/ylMUZm/Nmf/ZlIrjtbimfCzrFiTh4nyllXOpurWlbLFeZ12GyWVXozKUVLNjUbsq36Ts2+//tfCjBz/OhHP+rjjrg3f9nsXSYKbJe5dDp64z1/wxbwfy1HqjEwh+TrTSs11zebpIwvYF/7Ml9H6a1VdfI3O3v+/N2f/UzTNJ/61KdCAIjPnDlzxyfv6Eu++sTVD3jAAwhkTAZ1AWaMxNx45toMT+tBDPP4xqpLDcOwWq0+/elP7+zsnDlzxlPYTp069aEPfQhMD33oQ5smcoiAjua9SXBSwL0kax/1zB5KBJ4k5RACoGIlhJDz8PnP33f+/MWdnR3Tslguu/3VHR//RCmFiB7zqEePJg0YZCYKzfWMuqRJd60RgOvleZQxM6NJCcDHPvpRT/G9cP58k0KK8ROf+MTQ5dTGRzzsFo4EVa6dHOsejWqoRwfRBMwNXKt7tyGdO4H70z/90Pb28p577vFvuq77+Mc/3nXDVVdddc011ywWDUBqZdSMDZC1V5CmpW7+c0B3JTXDvDlHLrlt2qHPH/7wX6bU3n33Zw1ChLPnTn/2rrsuXLhw/PjxG2+8sVrBwK7XHhYNaynayac2DbiOkdm4Tp8+ffLkSVW99957fQtOnTr1mc98pu/zAx74wGuuvSpwEM01/yUcXIiOjiUbxfIjU26m7NGc8/0nT508eXK5XJ4+e0ZEmibeffdnl8tWRG666abd3d0ZvDZdvrY+g1+IDhh7O0XXU33cixcv3nXXXcMwnDt3ThWLxcK/OXf+zFVXXvPgBz/4qAdO34mD3c2nBKkLP7ROq0F9R8DZramf+9y9d9115zXXPOD8+fOllLZNn/nMZ2LkUvQhD7lpd/cKMxERT3k5dPGmO+ey6nKNWjYCWY3rBXla6smTJ8+eO7VcLs+dP980zTB0n/zkJ82slHLDDTecOHECmGolTwarw+Z6PVLtmBm4xv+dxAed2Jm6NDGywTmDHu/Z1D/K9Dr8/ZwzH1RN1vevFZEvhQLxha4N6WNasapqEZteKqaqVbN5+zt+M6QIgtcFAEBEMUaO4SUveYmYdkPv4ttBabGMorqPYTI9fw12My/B5l/mnM3kh171ykA1ZJOIAA6xiakF06+97ddVi1fuVMtZulxWZvkg8E3ESrZBbBAb1Ia1TKHroYv2WTq1/LTbngpCTO2EKAxq04LAH/yjP55JG7PXIeXJd1BMi8ok9c5e9eq6zhnS1taWB6fRaLEC+KaH3Hz27PmiorMRDj/HIZltyDbopqyks42eXn/xlx8FuGmXHBKH5G7gEBui8DVf8/RctM9DUemGlZr1+YCU6vB0YJZN/Bn1DC1qg44AFxvGQ6Ei8sEP/gkzL5fbTuycMLVtC+Bpt331xohrNXfClqImRbO//E+tUzqonU+b85Ov/+nq6qaQUgtwjI2/Xv7yV4qI68c556ooTydbzarGWDa0pwqGtTqjZkPJrk6p5X/4jP+ZA1Ly0qgEgJmbpiHg3e/6j3MqMTtoxSetWnxpxaSYbAB5AvaoRU16hqi953d+lziG2ITYTOttmgbA7bff7ifFnzxBclLuRx2iquNOBLL5SzcRoO6IHsKrrs9q9uzn3A5C23rHQGZmotA0DVF4xzveMREHMZ1PRqyIDRtKwBqjHAOy2KCW/bfTZqhWC4Gpdd2gZs/77ucjJkoNpQoH4kgcAX7nf3jXkEXUsisv41EddT4RKxNqzQBlYupVGyoXmIHjizBprZMA/qYxVIAL1Id4F1wkH0f//03VmFaiBlVPkahRzB5wSaNdl0FExGN8qpQSUxIRHrtWeHgMHE+J1TRwKFImHRMAESYX0SwSRqspvI4OFQQOnjYBoOQ80Vtmdn1fVUvOzOyB8E1MIlLEb2jEoJgbFWnqgq3VRuwSg8LMFFoAQFSY2BtjpJRgXOrnwMQKG3JHjBijmMIFXqLqRh+jAU3Vn2owgxjEYEwjJ7BZhD4RamR98JTs/f1OVWNsiIg5mlkIoe/7YRiYmAhFyuyn8KfVJ2NaoxpkImrz7Z6LbTnnmp+lWUVC4tQ0UgYzy7mPobrBY4y5ZGZWq9LTTDS2KmV5qWIz8xQTb6BS8YcIY4bAhCeKYRi8rKxq7T8IwCutEpGU4pDUg5VR1lcgZvJAK1HTedLvfKXTJPb390PiECMgIgJoKUW1SCkMr7BAQO0jUkpxOrl+oKnZqHCsv62ghq8fFjgCaJs2l9y2jSpykcVWK2LMGMuEQFUJwUUDP1YToCb9dHQYCNVQdT1gNvHbas6NmaoyIY4hjlJ0ubXlE/MiF/6T6SB7htIMUDNfndKEWgylUdNy7VYVqnO82sCxpolFStd1HIJ3KsKogvjJ6rrOFMxsY44X1QQSx5MxhEaPiNZxfd1Plm+uoZIsFeEAmLUN18+STYuVwnFDITZBjEyEABDNSqcB7qkzM8bGvlDVfXU6xVMghF/R1iPQAQJutuF7n3bu8Npm/zVnLfVUA0fpXfzXaGRftksnj2CtMEOu7rkZybFtXWiGmR7zqEe++odetb29/dk773zrW/9PInzNbV/9Dd/wDRcvXnz6058OKLOjHlJgTDEPVRskMq5O/xo6tfbcusZIjBqlBwUspPSN3/iNAI4dO/ae97zn9977XgDf/m3f9ohHPGJ/f/8xj3o0U4SBEZgZHioLos3IcUIwM3dZEgJQqgrhSecEAF4vjxEI/L8977v/7tP/3mKx+Pmf/zef/PSnYXjNa3+YDBT4+gdfx4HM1HN0RyVX69EiBoyIvEDkCGRy3rWJPwAZETEZUXjdT/xY3+Uiw8+95a1nz53Z2d75gZd9f78aTlx1/Nprri5lgFJqkk2/3Qy78ERx3zJC8O10CaDWMJ7ewYA+7KE3/8hrfhjgc+fO/MIv/OKFCxce87hHP/vZzxq6/OCvuB5qgSBliJFD7QtiNLNJzMyW4zeTD5hitQuurY08/1EM/OhHfuVrX/PDAE6fPv2Wt7wFZk9+0lc985nPXK1WD3vEw2OIzsJ16kRSc+bXg1VkqmOsA/AqY5ut1N+/6Zn/MA/7KbX33HPXz/+7X2DCNz3zmU9+ypO61fC1T78tRi4yMFUZqDKyCuVKvKqpzjaaoRF5wO1oKTPkXEIIKSxuf863/Z1HPy41i3e/+93v/4M/JKJv/7bn3nTTTd3e/q2PvbVaSSewjA+oyjuFtW+2WlPmURzrsI4U3WnsYaf2sIfe/KpXvqJZtOfOnP/Zt/xMIDz+8Y//R8/6pnPnzt12221E3uqRR5ydufjnIQ9hirUxrnJOvZEIo4CiR6VTwMuBfOd3/OPHPPqW48dOvO03fu2P//hPY+QXfM/3XHPtVSp4/OMfywxVcQ/2xsptbrsOVbqbm8gMY0SfzSRwJq/gTrCSvR3cM57xvzzgAddsb2//1jvf9Ud/9H4A/+QFL/iKGx58/uKFxzz6kSrCHNajAmPcs5s0GAZvcb1hMF9HftDBLzdtR6PJaGakmhmmTI8yUk0mqcNOlcmYcMgRdED7G1XsL7ONSs3ESp6ZiUYdeXNdOipyYpKLmfT9SrX85V98iAlNCj/+Yz+qkkvu58vv+9XowvUvZGYx2vBVrudT7UU6aoKSh85MpAz+8De/6V8ygZk/8IEPmFkZspuaypC1uNPYHW6yYTjaHELUVIvaUH22aqZWBiuDDMOoI4sOXTa1b/7mb+ZI3iEn596nnmWw0UGq45KmHx7wA7tuW/8YLUs2bfHo+ZcyuJXyiU94PAGP/MpH1C9NVLJKNpOc+4NGxfEPkerOtQMzmVkeRvtDUS2lDHt7F83k85+/54ordgH8wA+8RLXkfjCtu9x1+47G1WlfwTU9alAb5o7BuqEO0rnX0F+leon9+ZKLqX3yE3dcfeVVBHz/i19iopLL0PXuUu5X3YalSA88f+O/1qMfWulkHC5lMJP3vOc/ExAY/9cv/DvTMnS9G0LziL1+8+SVnXB1/N+1A7wONDlvxUxNsklWEyurLP0gubzhDW9oYmLQh//8L0ytGhFHC+bhEzE/FOs/Z3Y3LfVuEXH0mPDE3J+vdt/n7w3EBLzyFS+re2dShrwRNOGHe3zUgcM4TqDoaGAcAWuXI3oz6NW1vfqHfjBFblL48If+zLRMJMKhrfNQDtmYz4FrNiMxy6ZFJPvLcVKH3krWoXdfvmrphpVYeeUrXhYDEfDpT90xYd1B8/JhWjfblzl2zScz/xzn1qe50jupjhhDAMc/L6dzHFFVkNYSkwukm6OsRxtDygAc9Zwv7TUqoWY2BhljXe7C1dVaAQmYen+aUZMWT//a/6GU8rCHPoIQCCS5llwkDikQMasWcyWDCLX83OjNXJfiANYxbKxFY/IyUMohqUIUqsaBbrzpIV/ztU/XIrvbO2XIAMCwoiFF03WRR1UVGFFt4mlTPiIB1XfMsLEhmREMIWLopWkToCgCComDFDz2MY+77777tpdbQ5cZRBS0aGpTlRZtep+8/Gae585UdSgjQwWsjUtWwOs2edk7g1FAP3Qi8oQnPnFnd/cRD3/40PdEtYxmiLHk7OmTjqBjfGyNUV7LbmY2mgTnIx64QgjL5bKUAuDrvu7r7r333oc+/GFmZEYqZkZarGm8GSKaZmEy+qZtksASecdyjGa5aTOnz5PVd7SHpCYOeUgpqWoueWtn+6ue8uTVavXIRz4SRKqaUgLR0OemafNQUvL8Xn+rNiJ2sG9E82PM/T56vX6+c87XXnvt0776qWb2oOuuUyOOaayj2Dg2GKCiTKNpY1PFOgzVOq4FM9OxkxbEgqe7B7r++uuf8KQn7u7uLhZNt1rFGFnH7jj1MVUjN/ICl2LG1aQ5DW6zY0JwS6DCyoCUkmntsjz0fUppb+9Su0hf+/TbANx8881wARccYjQd1aeRFNVs89p/cTai/2nBdJ0EutYtZiHfc5CLlhhZtADQYrfccssTnvCE7e3tnZ0dx2Q3/FafFqi2B5wZZWzUpdYYVXV3AmDCbhQZ44hVQUyBoldsCyAqQ+YYUmpV9bGPfexXf/VTmWPbtm7a8uLKNMt1p7kt18bY38k6ZY699ShPITCj9SAAY+H0kXPoZT5jHbN82XS5oz0fZgYoHZVutl7GyDZwGfbzJbwUQjCajFH+HZFnawNgsB9+7+8NGIhyyQC8tK2OlXedA3uPBLelmglH0jHns8YebCSBTYk7U4mCeqJKKRRqKQgCeRh4kRK8DeFEu9RUlWM1odIm1GtuxMyjUEdlAF7wqJrRTDEM3WLRDLlrUmMKWO0xMeSBjFMbhy7HJjBx13eLZmHrnufzknnT3vGmydFsLLejs3A1RimlpJi8RLb/0Ote0KyGioiklEbvz0RsePwwpqeteQYdXeZjvLxg/tggAAAGLQ1HFQ/LqeXwshRT8jZwGxCcrI41AdRJzzr0nh1RbE0cPaBOAeKaxamqMVQuYmNJlZwzUfDSxQfyG8zMyEvfMWzTOsIAqR4qpzFdWUoM67gdhzaAPFiM0WrwPebpRpidYZecrNY8HE1hNKewDECyBu/ybUDA0PepjWIaOHhpHMzqDB41TqXBtWSyrU9JhXbt1FxvUzBX7C3+wLGCoYcH6LpOZYxFLXJYA41GGYP0wKKnlCkCbCryMKfso0wJWwtNo1BmufQpplxyE1snBd4ZaO7ncDgwx0pTRqsPHUxvqvOxMZWyYhTNRHkAgHesgBKgHCsLZwZB+2HVpIXDwausA1jX3TxIw4+itxP1oLVFy0WlQBFfIrbxhVzlZmt+NU3JYJOrdkZsvtjEk7/NVbEQ6/xBj9+YKq2OPBdsUQGQFpEmJACrfuUuRPd9Nalxjc4d2m4ALVZASsqozcA4UCQv7kY0VpErWbORMQcoNdxkFYN4X40ismgWYiIiTUy1VzDA5iEaXH22pM60XKhxzudOrEixZlcaRi98MRSBwGpNCzJPmrJiQ6KE2o4sllKILHJSSKA4lJ4RYgqmMFIyPsA2VAdiMCVGsHWRWlOIkihmNVPrgffmZ/5t6IZu0Sz2u/2UWkeVOJaHMphaGRFO3XdSXanGgaJV94k7pEwhqopwOMaxSgMykgT3tBNR5IYAQih5iJGZojffmZzepAYwGQfv9jm5SqECK+YyL6aqR75GnpecISoyhBAY3OfeY/Byzk1qfB8jR9PKMrNIag4W+ag4aUTGPLIJIxErAmVeVzuerxfAZFVoUjvIICLLZhtgMbFKYqadHEs3qrNhjrUc/KRVmkKKFTOtpRLFUkhVTRcFECMrLGsJHFfdvlPw6aDx+nmb5xGmpmSUOHFN7qxUEgyFZM1mRoFqvUglGIdABMrSxxBzySlGHcWOUsqi2SpaIjf90C+aCK00c2yfVYEzxlbUk+8uEMc8UShcT1Hj9So2fGbGIBUrgcJkO3B1uZTiYXJM7MjmYSCBw7za6ZHzYUR2uUTJnyAGVTX2EqqVfDFRII+jyRwag5SiHCCSU0xDHjyahsGrfpVSmleRmMtXqsXdW76PRMHZ3iabH7sejGI9iZV5aTx/rIMOQG0BRO4RumyBPHxR15gTXx+xJtNhdsOXm21g5BxVxte8GrpBeiGdvkTFIU8v8bZcHRF5zzstQqHaBqqZiWurWgqAY5sEAIEocdPGrRSi1ax4FtMu7w3SC4Q4mkBEQ2BvbSKm3qrP/1RVL/xgU96+qLElTkpVJM85g2105iOFZhnbJiwY5OKkiAyyP0g3WDYCUyQKbtsN0Tw0SxUxLEopATTpT1NDGHN+s3FV6UutNE3TxmXDDY2dMUF67tJZYxUuZjbmTjPAqqVpmn7VxSYxgreB8g42ItI07TD0RBwCd12/tbXMMgBqNAZWGAdj0nB853gtaMQEaJahy31fOnD0uPa5AxAu6Tep7/umaVxNHKUZhtZkeDYgsIhwJAeLFxMKFNrYNrGd2r0opNehy71Pb1KbyHAAgSflyUONvTVTUTHRkCLUSikpNSKSOBQTXyljHmYCItpebEeLEQkEUx2067QbNJMdvV4zqyJFDJ4f41FqHt2UYuMI4EEKkwLtbCNSaNNikRbsTJuhkL70fe6zZqNxvWYwZiDG6AiTNcdUu/u1bSul1PQCNu+cMArZo1W8GqksoWlTuwhLAk33GazXzgd1ycCMmBLgISTqCQpOH6V2SKxyPXEggIgC4E1fjMjTPgAQgoikEFJsm9i42DSVE1fFUPq+rMRESYmIAmuRw6TJSImCmXjVOEbgSLkvsQlQKqW4cRJACCFXa9X8DK0zV8wsMsfQtKlNFDAWFBHTPuc+d0ICxkRFiUiyApiGwMib+zws20WWwYvoLJfbwzCMbI9GK8qELV4dNUBgZpHjIi2a1GwWXp5JMBQARAapqoilFEopIQQQum4I0UIIsFE2BbyCTQqxFJ3SfFCVLy8UQ97VK8aGGV4JowaYmHlIBpGJ1sJKqjVcomp2o+n6y3sZtFiI0ZnHO9/1W295688+6MHX9dqDp4mpR6Sp2qQiAAjEfR68O9tljAMGUjUjC02IBPv8Pfd9z3d+3zc/45uZJFBQxX2n73vB9333lQ84sbfaCykR8YjxwKgJuqRWG15qzW9yOJOay/w6s7AajbqgIXG8eHbv13/lbUFj5EDEH/nYh3/wn738muuuWeU9BO6HslxuV7YRSIoLJmnoJaUERs6976/zrRACSA+1rq3DBaJ+r/vKhz/qn7/mxy1LjIkIv/HO//vn/s2/fsgtN5/bOwe2wKmWvAOrFjBcAIwcFaZFPCZ1GIaU2ukQEgUiI4KqGqk3yyPj7Wb7M3fc+cLve/EzvvEZTKHkPiT+5z/xY395x180y8bDJ8nWMUXTjJ12ezCxU7oQWLVMC2MbS/eRBmKfDwRtaO695+TrX/dTj3303/SBKAcAACAASURBVAkIUgQB3/Vd37nYbfe7PQSqXI3C2LzAwwudSFVZ26lzle29tjFtWMnZvKWQ+jJp1sz12LFjn/74p3/9l9921bGr2AJYvuv536VRLZIWBZOv10mYyzGYRA1aN8HMeUghVkl5fpESs5mpSEBoYnP/fWd/5Rf//bHtXaZEoPvP3n/7t91+w83Xd3mfIqlZKcXTNnPOMTQcMAxDCEHUj7kHNJMBHu58JNvwSTJztEiFf/Hf/iKUQq0EDtHyih98xalzJymgy33btkPJhDhWI69yd4wx5wG1O6Q6tNUoxTgMA7O5mXijbpoxgZft1sc+8vFf/eVfveGBN/Rdv7XY9pyST3zqjpe98qXXXHd1N3ShCV3XNYtkckQGggHMUVXJy38aGdVClGSXI2R2sO00wMYpNjC769Of/cnXvf4Jj31ijA3MzOTeM/c9+/ZvecRXPrzL+0pKAS76iAiUmqbxFKhqLc8aQhyLKkoIkQiliBfirZAnnZ8ORYmJtVikKIMFik1o3vpzb2VzEh/gMvTo4/ItjFq7QrJTq67rDHGxaAAtUmBqRsTGRKWYD19bEI/yb6hO4wBgGAbv02tGbq411EovzNx3XbtoIgcDAogYBhTRJkb3/hyRh/qlvQw6SEhRRRQSIp8+e/off9dzb33yrRpFIbWdgpiH7plZ0exx4jR2Y6bR9YtN51gdgWBmiRerS3vbW4u/+NO/PHXvSQ6sUkoemrR18eLF6x78wJe/6mVnL53jFEXylALmnVOJqCo3KTkbJoPvznj+eXPEmg1OAJS2mq1XfP8riNlgYFMtq27/yU/9quc899mrsiokFGIeihmlFJiqKYM5MMWcs0LaRcVFALGevUkPm1t8iYCgfPHMpd982zsIVEwsD7EJJ0/e9/zv/Z5HPf4re+08Ul9ESCMRxcSrfn+xWKhqyeqwDSGoiJPyqUA9RrO4avG4Zd+alhef/Min7/6ru5i45JKlcGoudOe/70Xfe+11D8iWpz3ZMGAzi4hnU1ht4BxVSwwMKG2YleAGnhCCFgvgRbP9a7/0a6vhknkePkAE0f7Vr3ntub2znNiZPRGRsVt53EBpZk1Mnk+nqqltuq7zJDidpQKsHVEEIzMzd7BVRVbzFbvH/9VPvenk6ZPXnLimW62aZbO1u/WiV7xov+wFTjQ2u+R5LoIZgFgbRy/MLEtpUrCN1JCqMgJQSCklhab0+YFXPej1/+Knz186s729TSYAXbx44ZbHPOLFL3txsf7C3oXY1AbUJhpjLKoi0jTJrSyu0zhKl1KaJlV5dBxxXC8DoIAL5y7edN3NP/KDr1XSGBqvJTXkPjaxkLz4ZS9JbeCG97u9ra0t7xHsRdIIGC1CCeBJujcg58wcY2RYmQxKNso6bCRZH3jNdW/4qX959tzp6x94/XKxlFw4EnM4c/7UrU9+3PNe8N3nL54ppG2buq6reakH8QQ5l5SSynrHXVmvBfkP6ui66WXw3Sc2SNarT1z7G7/6ts/f97kQn2JaCIGY7z976im3fdU/+d9fsN/tdXkVElNAKaWJbc4SqBZ2DIFzzk3T5qKu6uXSe1iEH+E0ZvJu4psWyTFyGSSFNloIFt/0hp8hJlXlyxt+osuwng3IjMVi8fa3/4c3v/nNw7D/lKc85Sde91NbWws1K1JibEqpqFmKqmpKtWWsWU2x8QbafipqhTSCKGDE0HaxgImZFhG1EJv4O7/zX570pCcc3z3GZOZthL9A2bMvxcUpDKu+WTZEUJixnTl3+r5T9/bUFStG6pL8xDbaGIZhcGww9vNZnMBhZtSq22AWKQJcBt3a2jp7sdx7+r4Utw3eUZQAcKS91d7950/dde89qY0ICIHcWeJWb+fz1UhqmlLyve/7lbNkgHl28NxCWjSn0JDSdrujZAaRojEtmHm/37+wd/H0udP3Xzo1aE7toqhutVt7e3uh8gNm5iLGHCLzkLtJkhDJk/9/DsX6j0Gyaq9iJVsOIXmD7u3dnc/dd/dVp471GIzFA5aCRWLveg8n3E2zSCl1eZh6KDkKlTK4/c2KECV40x8oEbFx0uaee+/a3jlWpKTUKKRAiuZTZ07t655E3dTEqiVXxBwtVTWrLJfLru8Xy2YYOjL3RlQ7rYulHElEJGtAuubY1Zf2L+11Kw+uFxGKrKSfP3nP2f1zsQmDDBNbHU3AtemeDLltGs8pEVRrmJmN1ZHXE2VAzDyihpEC6uHKmi/tX7qwdzYtg5jEyAQ6f+n8PafuLlSKZppq0Lr3yxO4OE4W1O7+wcELqJe23CR/LowrM7Pxam8gCpf2L2WVQME9rUPJl/Yvnj57/8lz9xlJaEIpg9NHAG27VNWhZAaJ2PZiu5SBiJRcuDTVA/L1enQVQIyVV/0+MPWYQWiCQi/uXTh5/0lKVpBDE06ePckhuKLT930bk5mllPrTK4BjjJ4MWE8NUGRgbObxuKphTMZd1527eMbYXBoIMRqkaKFI+93e3Z+78+z+OWMLgcSqYDHzWlU8CaAY3QADQXXLVwPgUfTBEcMvx1KfD5QuXbp05tyZYkWQ2ZgCFxUwnb5w9t7T952/eJaCDjKExI6ZKbVsbGYptV23X4WtwIBrfuRN3sSsmrIPQx+1QLJkJaVgzU6ze3HvwjzW48grTpJd08Rc+j/5kw+96lWvete73vXAB1790pe+9Fu/9Vt/67feKSJmeu7ihWPHjjGh64bFojlz5sKJE1dUpkpERKdPn7766qsB3H///VdffbWqqqEYLl66dPXxXVMiEUD7bjAKy+22iL3oRS/6/d//ffFO24j05WUZAACFd5Mmom5YcSTL4AU13LgfnJm93LhXd5IyNFuxbduu61B7QicRWbTNkY83ReQ2NhRCSIkpgJWzZCZtOHZ5SClxDFnL1s6SGqiWmEJsl27lC01DRs7I27jIpahq0zSr1Wr72HIo0qY4GogYo8ijpEE5xohMTZuYeczFo1xyu1w0iwTGYqtNlIQRKQ2lb7dTU2PDQERJyV3i2+2OqormGJNZ8rZUm6sc/VLGcYvPnDzLkUUkUMo5hxj2V5farTYum1yGTBoRiJgRIBqa5G6z7SuWQ1+KDFs77SS7qKqipDYwIRhqRw4KTFrMAoVAMSKGlPLgpdxKjLGT/ZRSbMJyd5ExKAuMJr8f1ffgibsxpGRxsWg0iJg0ywZgHgNZJ3gSGQpv7Sy1N4GF1MTUFmhAULMABSMsYqMpLFiLjfS6Rn+41sGGuN2UflCywAy1GJk5roa+jalCcMbhEqBMZhatGbUNBEW7ldIimRlT0MgGCyFs726f3rs/NF4RrYZFAmC3boFULYQoIse2t0MIly5dcr+OO2B83Mko5wHcAeFYWmaVtlkETmLq7Y9CEzhFZU1tWuzu7O9fWLaLUsru9o6IlKKpjdwGQkgUSykerqYqbRNde26aRknZWKkaA9m4GkoyccPO3ksZQlqAKefMibd2t5a7rUDaplGIW/cTpdz127s1SJrYGm6cZ1xx5e6q77bTIms21aaJNeOVyMc18x4fkQoWW23bti6fARQ5EQUDDMyxSYu2xVKDEFkEzIhttNevQ6E0EOec0yKICJNFDr7qtZg1CyCZDGVrc8UYc5EQt5ZLsLVtq6oxJG/+SIEphnaxiH1CUFYJMZKGditFiiWrqXLkZdxmRtd17SKUUhYxtW3bl15VU4yllHYrTv6MeTSkqIpK2kpBIzL3ubvixDGDYYTYkVf0LvSBuOQhxXjfvZ9bLBY33XRT24Y3vvGNv//77yfgve997wtf+E93d0487WlPe+Mb33j+wqW//w+etbe3d8stt1xxxRVvetObbr/99tSED33oQ547/bu/+7vPec5zfvS1P/rRj37sud/xPAAPv/nmX/vVX3rb2972//ynd585fe4jH/v4z/4fb1WjOz7xyec///m//Mu/HJpEMB3dHl/Gi8EcVERIXPxs27aGQcAPvaoKWc3Dd9mh6zqMFmohDYFF1ymjU1AWwEZGVsDx0v7+8d3lYtGUS5pCUtlXcJNaKUZkbdvqSs2UI62G1WKxIKbSF+/JKqLMIefMIRCRwJrlIov3ZrAxNGh+aYxcyoBCYSvknBmRyNzbXLIqDIGHrmhUoqBWYowpxNWlvRQ5cMpDibGRXAKzCUyxXGx1Xdc0cez2OI+4w/TZLdo55za2ZRAyjhTdtAIoRWMi5kBgFhRVgoTARbTre+YYuDa9GKQwc0xxf39/e9nAgzubwIWIgrCRkpoyKQzERkQppjwombWpHcqAgC53SF6JgSeZbuwpatldiMyqdvbC2d3dK3LOlU/YFN1b5eKiYkQiImrEUY1yloDkjj0CZSkcQ9YsQhTIoEXVKYtxzSbJqqYaODbtKAiXEtsmxugNOVErFtiIP57v4ZqJC+nVF+yWLsC6vW57Z8kcpSgzh8SiGQRmVm+nAYCgKkbuUdJShkuXuuXOrtseZ+tkQI1qxr+aqqJ0w5W71wyipVigpCpm4pgfUypW9nvhFBWIKQzDwEQpeakba5royaeLrXYYhq3Fou97Y9ra3RqGwcjUhwOm9yIqYsvl0lldjNELoTep6a3PeVBIX4ZFm7p+iG0opW+aJi2bnHOb2pyziKaUimps2m7omdlMQJaaWEQmxdP5AQikBpMihsBZZMg5hBgRVZSIEqcyiBlCSKUUg7p0zxzVwGsur7VYkEqIZCapCfDovsRFZCasK3HA2MuPaqmO+hhimArDukF2t4li6IY+jtFxBmOKBFZFUeVgTdOASYuJqZScOHFsVnv7O7tbw9AtFou+WzVNw/8fa98dbllR5btC1d77nHO7b+emiQ3YioiCCIKSBlBHVEQRR0XAhIiY4zxHxIQJMYyYGGfE54w6g44gYkBRggEBhRkFAWFQaZrY4aZz9t5VtdZ6f9Q+t2836Izvvfr647vdXneqtGqtX3BY10MuvKoysvdOVbdJ1uVNAZU9Wcq0DEWi/uL+aDRSU35ohgrHOGsAUhGVmMaaS0cdddRBBx20ww47PP7xj7/gggue9rSnbdkyfdppp/3oRz+69tpr7rjjjosvvuTd7373YYcddv311y5btuyWW25xjr797W+/6lWvuvrqqz/3uc+deOKJP/nJTz7/+c/XTX388cd/7h/Ov/a6ny9bueLjH/+4iFx77bUXX3rpeeed9953v+cpTzl67a67fvITf09ERkjMDznM/v9umGeUZd4DAIiluh0xs+UAEyBP55wtYaTQJhVo6mCKbR3quk2NqBhmqAMydAbL1OntdGUkGEz0QoyjtslhKLM3UbQsTKQhtWLK3hlA1e+ZYdtG74qqqFStbUOoQwwiUeu6nZsbiRgQq4JhFy7Oo/fyDyGFnDQPIZTexxRN1LsSgKKKAmUtDmJ2zmV4VYyxVxWoZiKeODatqsYYm9ACwKiuASCkiIhJI3TZDF34XwDlwmewmYAQcOm9jGt0CqIIiJY0JoliKdOYUhI0CiGFkERsNGraNnpXhhDMsNfrhRhjEMwYJFPtBHnQ0JIlBcnLqIoVvhDJMSd2EHVCQEZE6MAM3Z8YBYDMsK7bGKWq+qNhk7MWNv8Zc7oGwLJspe8Ky/MFbQV1zhlCa9EVRUyp7FXIFFLIeJs8ABxm6iMysyRMUac3zbZNjG1KSWdnh8wekBAJsy7RePwAIVIH198Or5hdoxF40JsAIM9FjJGIVC2JdQc1MVMAQ1PI9cXRqMlDi9mjYp5fuk0/du8LiM77/HYddjOPW2JFSCmFFADVeZ87RTSVZZmxbQSoCozYDJu2bQGgGbUppaYJzCwS27btqobZznN8xMmcA3Y4PTvFzJm9MU/qZOQctPmC2xiL0qmmqqpmZmZMcwFczFCShTa1TWzqEEKaV9nKQJutcxO4ix8IgbDs96IkAKiqCgHTWH8pSnTOOaQQAhH5slgIiplvC/smtClFHQ2b0VwdQgqj1hTG68M8ULQbEt23xowt3CqxlkOK/IOCppQyG1RFNCUAqIrCzNq2bduGvZvPY5tJWfnhcCgio9Go4CJGGc6OVAEEyrIMTchIgQ6JYFtzFWA0X6+1BXIVGVr2Z5ojYjAj7y0G9g4Rv/AP57/rnWf+529uOOecc77xjYu/9KUv3XP3hhOOf97MzOj+++8/5phn3njjjRdccEFdxzPOOOPUU08VsbVr1z72sY+NMa5du3bfffc1s1WrVm3evPHuu+8+7bTT6lGb2pF/+lN3XLHiiEMPA9HVK1f1ej1EyKMTEQlBVNg9fObn/2MzhXxq9pUTkFxRSJpsrHOWC5IOCdQkyOTE8lxnI+eYeVjPEdFoNJKF/I+t0AgFQum+v/S8K4qi2dIgoKp6djFpHhm+4KJwddM451I0TVaVA406Mz1aPFg8OShKXzWhRWZfFkHSli1bCle2acRjoj5tJUkAAJS+TElTSosHhYmVrgBlFTAC74uchs6LWs5HO+ekCcDOkWd0/X6f2bdJlBAYUhuGTSoKDhKiNFSwiSgCmSgCKSpmHiNJEiLKknbOuRjVFVkpuJPMUpCsr8RARN4hiZhzbsmSFSmqiCxfVqWUhsPZnh+0bayqwkSI2DnX1o1DSpYQ0FABAZXAgIiYPDPHNjjnFMyxz+sILLDlyamYPEOWLF5kZkVRJREAEJGIEjUCJEDrBJ1ybTgfrjJWHoEYRFtCrQpvmqIBIjp0IbXoqK5r9NjdGggNc0UXshgZuUUTi7wrENEIVBWZhs2waRrsZuZWk+dM7VGMWasOgWmsLdjtQDERUIzimGKbPBfBAqAxG2O3YzEzGbV1s3jRZFmWWYaPiAxgenqWyAEIoAAYdGzW7n0BoQ0tCnnvkwQzyWjN7BzsC85Hiq6XJXh2c7PDkgtElCA9XxVVv6P1oYYQnKO50VAk9Xq9tm1pQU51YUlcNJrC5OSkjJ0WAUGTCYg5y4XSVls1DSH50mnSyUWTIABAKcqgv7iqeiGE/HjMtHlqE5IVvpdnOyrovFpb17VohnVdL51YikxNaBOYgw6A4NmH2Bio92xNTCkTHrPugmaMteE8dpZAcfmSlYiY6R2iCqij0ShZAoBOLWJbouZYGdDG5FwzwzbFZWWRtVQMsHAODJgY0RiR0DRFdsqlV8iS2Vr4EsRCbDy7fr9wRFVVgXAIqdcrk8rU7BSZ81QCbAWidw9hAECK6tgriCZlcwgU69jrDWRb+G0u9sI87gbAgaGJogMkZ5rOPPPMNTvs8rrXvX7nXdcceeSRBxxw8JYtW9auXfuzn10TQmjbttcbfPWr/7Jx48a99lq3fv0GRGSCqvSq2uv1EJjJy9hpcunk4IrLL59cPBgNA4F85UsXuKICNmYUiYyAiP3+hPecRD2TgSwgkSxsCtsoxf/ftyxbVlVVhBRNUkpUEBFBxwDogA2mKkFGw/C2N79zbm6EaCG15F0Tmpe85CXHPOsYaZr5S26ta3bJKvOeLctRq/Z6EwDI5NSMiNhh1JhSapqmHJSqQMTGogKSbNnksttvuu3d734396o20/pUl61Y9rG//+RwOCz7DkxwjOfpMP4GOR4kcmoyRnGgiDjHRpBSiqDonSUUEUNgdpKiK4vYxiUTi75z8aUXXPC/fdkDQmWbGw4P+6vD3vCGNwxHs96zINgCiDBZDpLyeqPkXAgjFSGglEJRFmIppWS5/GxKzMQOFEFAQZqY+mX/c585/6qrrur1+20KiDSsR69+9elHPfUo0hhjZPOMGNvEvgBTtBwmZ2r/+HTvIMbofRElzLtiWCdlOGbeapf9AaC3vPFt92y4l5kNVAzE5P0f/MBOO62GravYQnodqGZ+mREhEcbUqiVHDgHrIA6c5yJ/TMccY/TMY8feXC1FZue5OO9Tn/7JVT9l7xBNQJumeenLX/KMY5+Vo3IymtcuGYsJ0NYpjkDjcwYkyIwtcoiA5NB7r6OEOXQlzpEpIkoIw5nZV5/2GgQKkpxzomHpsmXnnvtxWPC2gJ0sQlfrACx9iY6aYWOokK1RLCESI8cgJgoEainX3syQ2RuiivR7vR9dftXnz/8i+xI0sYM2tY/ff/+3vu3NdYgW0nzm+aHIQyIXpM1iwDDGZyIiIxOQ975tW2WtShckqSoapKQ5I1qwe+NrX//gxs1ELkgzMTExNTXzsU+cu2bnVTG1qOacG6eDtkYSAKYL6A7OFQCEwMQglgC0YKeoUVogJASR5JwzyVUK3Q4HNZyaO+1lr0KmrFOW++XTn/nUVoIGGm2Pp8qduwAXgFqWZds2AOCdI6AkyXOhIEwdRT9pRDNJkmNT712IrUfnPce2Za7Oetd77rzj9wDMzKoSJbzl7W973H6PpbFx7LzYJXXsIiKDzDmlLO7C6LxLIeYz+J+pFjjIHWSgZsR08sknH3Xk0+q63vfx+33xi1/ca+9HHXDA/osXL3nJyS997nOPe9Xpr/znr3z5nX/39pecctIrTj3tC1/8p3V77K4S773nrpQa9v6BTZvrNpVVcd+9D3hHhz354Jee+PzTTn/9G9701ne84x1NtI1T06apiXMzUxtVREP6/ne++/wTn49kyYTBBCCn80JIhXem2Z27y+gTUM4jGAgTdpoEf0nLlWIAIKMCveeiiUEBjDqlECTGpGjqPY+Gs7dcf9vbznxr0SvEku8Xs8PZxzzuMVECkGUunqpwd8oTQ1RTRFRLiKh5wkdxgCLA7ASSWgRCJOfIkyCBSoqGlECpcCGEClmbePbHPkpVUSIholgSbas+qQbT6L0XhQTGGe0XBZ1XyHdGIsqsXeTOCpIIlTSSKBgjkQEkBcJokT2HKIi8dHLZB885R0wMNaqUVdVlqyvHxCYJDGiB7jRZN+7NhJnQyAG1HIO1HtnIBERR2dgMMaKZKSGgKIgr3cyW4cH7H3Lq6S+p25Hz/VHbLJrsqQXRtigqh4UkyaNdQQEhw4rySREsk4eBPIskAHBAY/C24pjVhYiKguBMYq8YTG2cfvEJJx919OHDZiiAyloMPHrMGW0AYPYhNADQ6/XquvXk8nxWVYWInH/NNFdUgUhygA8m4Iiz8u74vpATCP2qbEbt4x633+vf+LpRPWtkZlL1y9jO5lKKY44i0MHfiyghR62KYCCd3IZk0gwhooCIiQEqSJRARJxtqo0Bc/o9sANJoZ5tzjnnk4uXLI7W+soEomDr2AFih0sD7LKdAIwEipZBhMwJVEgBgNBl0R0in9c/xUTIYETokiXV4B2LNqKxLBZ/8lOfHc1tGkz4OjRl3yVLCubzSkTgiQEtxsjkVIF9EaMgyTwJrBPV6EC6JBhRwZFP1qaUcFzrZ0YERk2Vp+GWzS878WVPPORJozgDZExVNaiiBoVUeoemCYByPlDNDDXXxQHRUA0B0AQcOAQzSIiGQApkqObytyEPDlLGRqsSAQBpB4diIGslzNZnf+zDi5ctzbjtLqWJkD3NHJPFRNlOYD4iWAhJIDOzJC37iVzVQgDHLkskgCijGZoR5ggViW0rQFy9IzH1vjecDk87+tkn/M1zp2a29PpFE5uJiX4+vSBzZg0RGyJaEjBjRDFjYrCMzDDB1gGDmQdOqkgwBpbMr7E2v21AFqczQ0nx0Xvv/dOfXf3587/wr/964RFHHPHik08S06uuuuqjHznnh5dd9sUv/uNTjz56amb6G9+48Iorf/qRcz76pQu+yM59/OMfX7p0aVT74Ac/2O/3fUkfOfejixcv/tpXvnLepz799Qu/+t73v+9FLzz+huv/Y5/H7oXO7b777me+653E/NnPfva73//eMc8+ZvHkRFbgy8JBmlJRFJqMMiGLzECSGqETMeeYgQEUTP5fpA9xLNC0NcukiJZFBjAbJWEJBz7hwCXLlmABjbRUkoiEEHzBaqqKGS0bY+uck45hkK80xvh3Z9J5fKduBVRYXg0MDMzE8klZgNRWrFrZX7JYR01Z+aRxZjjjCo8IvnCjUd3rL1JVkQTzR3ulsaix5XtZV8LKq6la5yoO43SBGWIMyfcXp6imsPPOO0/NTLvCGZkBzNWjwWDQhJbQnHOY8qF7Poba5kvOA1htazzZIU5Is3R8JvAAlw4RydiR23WnnWfq2Rhg1WCHYT0d4sgVLqXksSAAIwoSMiGfjMBAcSvnoMtTzyd4uqfSjM+BTkCJ578zqZvoT+ywas307JQf9IKFVpuoTU4ioFrU1nsvpqPRqCgqTN11BUQxI3/yXw0AGNw8hnXMDNcFsXTuegIjNHLEO++409TsZiNhT7Oz01kCABHbLALhWBLU7agonXUMXujCJFQwogUhrqLm9EL3XjYu9nbKUNpJZQivWLZy5epVs+0WVyZw1tQtItZ1W/VKjepKH1IwzAgRdeZhPiYfn2Lnu3f8s873r4hVVdUGaWMzmJhQTd6VO67aKSwZJGuWFZQwDkezReEyuM5Caq11TIyQJTaaJiP1twcEL6C6A8wnGQA6sTaEJMKkjEQqpNavejuu3nEmVMgg5kZNbWZlr5K6JSAkFlPK1jjZLCcfOHCc7rdOf3PhkNaxnBrAeHftajMZiUtkpghoUDrPiCuWr5xcvRwAJLSF93U7MgR2PoYgYKBa+CKlaIRKkGF+4wzzfIVywSvD9s1QDRXBdWAwINVUOh80iMhgMLAkFnHp4iWrV69ZvGRRHUfLy6WjphYRV1Qd+jbzTdEIKcsrs+Nkaf6GeZXI3YELzFce2hxkUhUxM+YMzm5r1370ox9NSdlRTFFECN1Z734XAKRUE/PZ73v//Q9sece73vOcE0540+vfoAlf9MKTyVMB9rJTXgwAbZKXnHJyamvn+A1vebOIGXtROOCA/VSSxbRi5ernPuf42DR/fczRf33M0REhptRzHgHEEhG5gjsDJcucz4RIBXGGF5JBJg//v8CusMOYKW09wM7XIbuVHAAswKJFi1avXj2K9YS3hGlqaqrwRd0MFy1aFNuAaClGIkiWmFm2/9wLHgtpXwAAIABJREFUyh4PdzDCHLlDl9ZloLzx/PAHP7IC++RGczPLVy0/8MlPzOZeANDrDVQhRik8e+IYUkoBiLOSnm0reZZPCR1WHcb6vthp4Dji1CZEquv20ku/24QaGetQ77jTTo/e5zEpJc+OGGKMXY1se4IrjV9imxeCzuFg/AjjhQANJSRlLX1x790bvvnNbw7DyHGvkXafffdau+eubWyRUcSIWTBs49AAC+b2VprFdlnYefI+oWW92q4DmPnWW29Vi1FCNIUSH/eEx04umwCzoihiCh0YSdUVLqXg4aFlNoJcvx7D7cm6hGpHL7dtFzwAAmDADXff9+1vXjKMcwlTSO2j93n02rVrkymYFb0qF2/NrFcVIjEn/8lItr3UfGNgnAf7z99obGvTxQRmiHjFFVf0Bn11QWDoPB5+2BEqaVF/0LYto5MQneckoikxO3h4gyianxQ0Pm7mMAjVmtGoqsomRkmpV1bTU1OXfPvitpn2lTWpXrlm1eP331dEvStDbPplqZqYMLuLM7miKJPGh1XwNYSHCPzN/29WFEWsY4mcuSm33357/a1vNTBnDiTRoYcf1itdCAGSFr1eMjXryt35IDfuJgPI8UDX5ocabQ2DCAzHXibbgaUJDMgoxkTAP778Cu5755xzjKBHHHGYgQGT815FvHN1DICGC0w+DLeRMBhfc37uEFgXVy74s/VRPRdN0/SrfgwyGo2WLVpuZrfc/NuLLrqoiXNcYAjN/gc8YdWqVZkTRkTEnFJIKVaenCtStJTS/JpkC6a24faMk+1aZ8mpYgBqIOycczwcDnv9QQjJeSYkZFCF0NZV30tozznnnL//1Ofe/e53n3322cc/59h2FHu97HwHqt22ZkDe9xBMUiuApnmhB+ectImZgNmDgFmUhN4XzsUIjABM2OmOADMBmKTEeZeFzn8sB/Q01iT/i5qNraK36S4Dgox2zJfNutgqIkDwohefOKxrdOb7jhyc+4mP77Dj6qIoRqMRAaqmQdVrQwOIogkelnsyPgVsr9ABoKqASExqXcdlhs5Nv/lNa7EiByqDuwcHHvTE0ITBoJekNVVR6Pf7TT2nlrwrzLaFoD1EvSDvFuO4mDAHzqIOOob/cDi87rrr6nbkSz9qR/umdMBBT6zbUUoJRIlIoZs0Y9xRFyt1gsy2/cjO33W87mylDyGiZ5dS2rhx4w033BAsFn7wwJYHV++4fIddVpspolNLANyEtuoXIja+1ML0dH6S+TLANhtVLpFt/wXQfv/739fN3OxwxveqOtXr9tpzxcolKcR2VDv2pfethJiS955cTvSRYhZPo/EtCMDQtrL0cJwCJgN7uMHonZvetPmX119fp1FEHcV65Zod1u65ByiaWd02RFR6l1KKqWHm+aij8/aCsbKfARowsG4vhLvgs3RGAB3Q86abbhJLWBpx7A2KIw4/ykxHo8Z7750PKUrS7EmlKd+kO1EtvHtet3DhMgoEYL5gRFfXQ8c8xuGkG274FUCTtBZMu83sevCTnjhq6hCCIx+jqErQ6AquqqpNkdkkxbFd/Liys+Ab2p/YylIbqnIi1a0QlWV52223/fG+DVYkYGgb2Pfx+5X9CQAsiiqEAEw5IEBEAchRHeZgussDLFwLti+sdt/B5jXLukfMEQkAELoY5LbbblPGJOIdld4deuihzrkYU5JQVZWZ+qpMEjM4cNvj1LgH/wdGq9t8hJQKX8YmuqLIklP9fv/uu9fDDRakSRZU0157PzqXoABAxFISJCuKwlTatgVDVxZJBU23Fti2XxofvjnVROTaNpRVkbH5qjoYDJKYK5yo5MVU1Kp+T6Vl7wHojW9+w+nJ2Ptk0Ov72KovOaXgGAFBgVNKpfNmyK4g0JSDbYYYxbPPqEx0DJC8xwSaFCpHMQIRKSQmyjsNGBK6FKPzHgGCiPdsCmrGSPBwocqfb2hqWUi1ixkf9hoLjggKb3/725etWJEwBmnIwY477qiamElNeqVPCUdtw46oUx/Z/lp/Upxm2/A018+1U9Czt7/9rdXEoM9eTQRkamrzksWTc6PZoiiAyRKENjn2BJYLs51O9zadTttvqzafbQBGMrSmblasXCqSlq9cdu6558wO5xTUyOp2NDs7DYTe+yw3BONEzcLLjffDBTeyrYjSBY9BMF4CMrUwpXTggQee+b6/nR7NpGS9RRMzw83ToynvvWoHSqyqqk2tQ7fgOn/m4Dx/0/HvZMbf+LnaFI897thnH/eMIAEIE+immY2xbUrnFZDR1XVNBfcH1XA08lzoggTCfAyIQDCPoNvqw0Hz8fhDW2zq/fZ97Ec++pHNo2lhMAebZzYHUQRix2RSeD83M131SjJQTQycJRr/1MjOiL8sEtTVNs2U5k9i3cpuJm9+85vX7LRDLUPREXuY2jyNQJmZP5ydK3tVkgYVHnJk1+1ut3AA5zOHGbR1U1WVc05SS1SE2ExOLvrwhz84PftA1WMBEUtz9ZwlIGQipzGVZQ/A182IKGUBgqJw2/n4jtvWt8+FIlv4AM6pqvdeAeqmeempxz/jOc+ZrjcFCUz9YT0XdZhd3IlcEgU2s60WMACASLYA4jwOQ7pTxZ9ZwR86lbO8/+tf/8bVO++AiKPRXL8opmenjDDG2CmBmkiQsiy2lVrIEcmC1+8cQBZOn21+f2tfGCIQEQloSlpVVUppZmbqGc981kkvf1HdDoFBJE7PzoiIIQMQEaeUsItKFR0Tckpbk+qwzUqlC/MWD31rR0QisayKejQqKw5Nc9f6DW1MKuRKBwDr1q1DBO+xruuicJbEyBS49P7eTVsWTUyiYq/sUJVtMxITV/W98ymBc52NxP2bNw76i3xVogEwtaN6bm5u2bIl6+9Zv/OuuwgYox+NpN9jI0gCRIAIKRqisaNMCjPruEpjqWpLMboFWiv/46YAbNtrw8x/MEMzJCQkcgwF7LLbbit3WNnGRjGRg6YZVVWXLqzrFkBd4Ykxxui9Tw8/Df7c5gEdCM8QFMihI2ae2rS5jGEWsK1HZb8siqJpGs9F20ZDLKuJEBtfsklSVfJuu+SYjf+b17acBN/mNVVBbdDrTc1OAVNKacO998yN5nzlRaSoPJoVvmxjgKTMbNrZJI15xVs/5YK7/vcREzMnFSKcHc09+OCDm2Y2V72JjVOb0aWqXyYVEfXo27bFUp0v4GG+57b/8hCZoIf+sqEayFwzc//99zYxtCly4QaLK02kyVTBUvCuiBrruq6qShUWStcZwsMlnLc2tJxzWPiJtQNkWUKEDffdu2VuShiwIFc5UfHEdV177xN2SkpF4WOMC88x81TkP/nuf/qzRJWpqc0JIpcoUIu0E9VAgWKUejRXFb0Ygyuy3EsiyoftP9N0jEvrWll61YRoWVYPEZO09z+wIcTh7JwmCwBQ9goR8b5omlA6Pzc3NxiUzBxVnONM9HuIJKhmS7HxLR/yqbNSA8PMzOyqyUWKMGqbO39/R6t10SvaZsp7by555+thXRUle6coYoqiQDyvhITdvR4ylh5mCP25eGWunnOl27jxAfCoqgw2LanX64W2MTBjEJVMJSHn2rbhbbMR2xfn/sctY74VgNGaEMqyRwXNzc08+OADs8OpZKnX64UQeoOJ0Co6CG3MK9o4gFODzt7GtklI/ck3XbjnOdHI7EGt1y8B9Zqrf/6c555wxJFHtY0Y2U677PzpT3/ayEnSqtdDUGAEVQRMSZ7z7OM+85nP7P/ofQBBkiBSWfUBIGUNfSQwIOfF7H/97d8dfPDBrzn15c6RpnDzzb95y9v+9pJLLnnlK1/1ve9/P2cdS88qYKjELisveY+AmDHgzFy3oSqrthUCdJ4AcayP9he0rbKj4xEz7yZkAEpGnU32VjnqZcuXLl06qTChKMjQxGZ6erpwvt/vm9loNGdJ2jb2JgZ1XTv+b5gyC1sGihqN08eUIwiJllauWsH9CpOWK1eM6rnRaFQwG+HkoN9GqZvWF66u5wrHvV6vDu34tJFfaZsAHzKRraOzLfxiqpoWT0wCYdErV65c0a/75Klt28zvSyEsmphomoYIkiabF3tauH50ikYPfTl9yA9dHJwrb2Wvt2KHFX7Ci+Bi5jbNzY5miVy/HGDQqiwDhm1193TrO277IpmwNp+cHdtAZyGh8YQk7Q2qFatX1m1DjoHhgY33OudIsFf1VCSaMpkphBAAqNNhBR33zkOzKFs/wvw/jjNE832hwOgcLV+5tJrsCWkrqQmtWUTDif7AzCSF/P/dqm6NNu/i9dB6WFY7Xrht53e3+UQoAICSwxWrl00sXhSk4aICSNObpoqqP+gv6oFVRTU7nE4aMkZx20T2fH+h/elwJ6RIBMwcQ9svKnLkCl6+asVwFp1HdCgS5+ZGiweLmQstFRG957qZLUpO1pksZSGfh73+diOqK06AJVMAjDH2Jnrg2FCrfrlqzao2DpPp8iXVzMyMsi8LN7lsQEQbZ2cpa+ZKUptP2i8ABW6T/FTL8LntTum4NXuzcIVVRN8vDXXJssnlK5dlpi2pbd64qd/vcVWE1FauCCmq4nB2VFWF2YJ5sc0z5I627Rbu8cjTfAKY75nsu8zszKzoFeRQJJYDv3TpZH+RR8QmhMFgUDdpMJhIKU0OlsTUzNUzarHMSrVJfOHGahcPO4X/ZHMZLUpYmJlKEpH99tvvom9erAqKRoQhpZtv/i0Rfeuir7/yla/YvOnBS7516YtOPGXn3XZZ1O/fu379J7///WOf8cy9HvtoQPz9H+76t298fY9H7Hncsc8uCFKKF37j64NFk0QcQgSFW2655ZKLv7H33nv3B9WixYvP+cjHAdwtv73JEV3675c881nH7L3f4xTs3nvv/dKXvvzMY57R65d77rn7/Q8+8OUvf3nXXdc+57jji6IgAlMABPy/ErHaTrB661fLqctxFTWZRo1gcNrpr6j6ZZDoCm7a0ZMOOeSMM85IIVx22WV33XXX6aefvmXLpqochDYu3DMWZki2vf3C7A3gOCGBZAaaLDWxGTb1O896pyB48jE0a9asefWrX40IN/36N1/9twvfeeZZ7AsCduiYqWkaZNouq9HdGW27f88GUjCehyqaUhg1w9/dceeb3/qW0WgOHYvIfvvve8IJJ3jv/+1rX7v33ntf+/rXQ+eumacWAti2G7CNf1jYI1snwHzqX0yRIWjzq5//6tWvfXWbWsf9UT333Ocee+BBT/S+/Pi5n1i39hHHn/C8pm7Bz2sijy+FBgsnHuB4C8n/qLpt/KjYiWeE1H71X//l8ssvUzABixJe/dpXr1m1uih6Z7/vgwceeOAxz3z6lnqKPXWGdjldsXWibr1pJzm8YOGm+YcB0FyeRgMwRUgoP//pzza+6XVNDIoQU3rms4998pOfzMxf/vKX21H9qtNfORrNOe/b0HjvwLYbmvqQ3CPM/zU7/yls47uXn216buad7/o7X5WGghR7vfJ9Z733G1//5vW/+s/FS5aY6EmnnLR0xWTSduGeMV8jXlAsVs0AKjTDvHMrgDFj1vjKOIK2bf/4x7ve8tY3xHbkHNSh3WuvR5566mmf/vRnNz64xfly+fLlL33Zyc4VKQb0vOCNCE1yGenPtu4w10kyMyFA3Y7aFL/05Qsu+d63kwbv/dzM6Mwz3/mfN91w+eU/WFxNMPOJL395b1D1qgKJRAVEkZEy0v8hJcDtvuHYWPFhfs1QFQFBR+3s1HDmw+d+qNNgNVtU9d915plf+tKX7lq/HjxOLl924oknkseJ3qIQG2TojNOAyEDH4DQCeLh0uQJs85yKOpYwtwzAJYdNaJxzhvatb138q/+41lBFYkrpZa941WjUfP3Cby5bvrJt22Of/cx99nl0kyyl5FwnfPBw3/m/b50E+vwCJyKzs8P7739gbm4EDBOLF1VVddxxxx1wwAH7PW7vdevWvfjFL162bMXRRz/19ttvrUejs/7uHW96zaufcvQRF17yrTW77Hr4kUefddZ7vvZv37jk4m//y5e+8NrTX3XXvQ8c+dS//pd//tejjnzar39981OfeviHPvC+95/9nhWrdtq8actTn3bMPfdteMELXrTjDiuef9xxRx516I+u/mk5mDj4iU8666z3/N2Z77zppl/fdPOvn/70p59xxhn/ftFF//ufv/Ktb31bgvSKrA/6P3nHbdpWF09mBUmmRM4MDQyZcqIIgdTEQFevXn32ue8ajRpkAKY2NkS0cuXKZjQqfXXpJd9Zv379s5913OLJSTCMIVRVaSCq6mkMkcROMcXG3trzPH6irC1hqkLMCKiSgHnljqvO/sj750KjhCBgIFVVqSZf9X7605/GGK+//vqnPO2vp2emSs8mCmYFuzoFIsx6ebmqLyKFLzLWUCQCKKKpGlP20UQAQIejpj7w4IM+tMsuw6b2vrMpXb16jURVtJt/89uZmZl7N2xYuXq1gYlp3uaISFJkdpmgQAbz1tZqqTu95cwbAgGOcUFGhFOzUye/7JR7N9wTrGaHKZKZ7brrLqUvbv/dHzbet2nmweljn3ksKqoAOwKzeeRnJikgGqAlSyUVqpqj5vmVyLriLiADGKDjKOGtf/vWuq5j0yqC9z5KGAx6RVHc8ptbZ6Zmrr32uqc9/a8ZWLUzJ8jdxY41BTBxGacBCmBqAqhGpqAKwsSSa4rYVTu7XDzh3Gj2OX9z/KFHHBpVcGx9sfuuu6FoatIdN98mIg/es3HZymUxhML3OiP6nKgBUFUHvEBXXxRUQDwwds4ckjEeAB03EAySypLlSz5y7gdDKyFFYEMSSxFA77rrrqOOOuqZzzrun7/85a9+9avvOPNvH9h0b1H47l7OiYrquIAsAgAGmCTBvPUvk2UfGhMmAiYAa2Pad7/9PvKx9zetgEnerPuDyhPfs/6eV512xp7rHnXmmWdedcVVT336kXUdAcAMGcnUyMbyvQusAPMuiIBdTknNl04kigoyiip5M4C2CWe9512bp+uQIjsjIog4uWjRhvV37/uYfU5/2WkXf/uSz3zqvA9/7KMbH7h/ol85s2TKxCGkTusj6yZIYnRE2XlPDTUrqgGoSPc1cNt6E2JH41m6ctl7PvAuQ2hTBCPPDFG89+v/8MfjT3jefk/Y/5Pnfeq73/3+i1/8ombY8PZFK11wtWyuhwaSh/l8RUdUjTJpRs3M1IgZHYkZICTToiyHw+Fb3vbGB+57ULJQPGiMcec1O/70ml/svvuer3/dG6+77rp/+MLnPvnJjzFwkgSOHFOMERlFxFFBAI1EzBDlhbmKBa88n6dyIYSq7JuomrJzvV7vjjvuOPnkk0NIc/XcC0980ete9zoR+fznP79sycTXvvaV17/pjXvuse6ib34bADSmz5z3qcOffNCy5ZPnn/+53R651+F/9ZQ1O+326tNf9+xnPu2DZ/2vy77/nd/ceieVg2uuvbFX9M4999yzzz77Fae9dN263c96zwcUbNmyFaYgIp///GfXrd31+l/+/NZbf3vDr29+xzve8frXnXHiC154+OGHhhB+f9cfexODD33oQ64omQGRk4EjSim4v0SPxAASKAFJDEXhEBDH/tVgGYoNHUQLGAyQ4OAnH2Rm6FhVyWHTNFXVDyHcdNNNS5csf9LBh1x80SWvec1rN27eWJT9vNwYZOE5ZEcppb6vYozsGQAYUERIqSgqjVPRxJddJhcRRFUgLlm29DETA1f16hiqqtKUiCg07caNG+/dcN9b3viWz51//lOf8vTSFQRJNOWyB5c+xmhC4EFEELBwXlSSJWLufAjM2DtQAjCZz/8wrdph5erVK7M0RYwxs3SJ6LprfrHLLrusXbv2B9//4Rmvec3U7JQlLQdVCEFEiJiRTKwoPBGppsIVUVrPnWAOEZHguAiJaqqmhuCcW7Vm1Zo1q7nM/NdMUYwFFz+58upnP+u511/z8xtv/M/HH7R/whjiCLs52q0peeMXEYccU8vsDbcqYG7lkXc9bmgmAHvv82hQK4pKVcWSiKimfjW47LIfnHTSKd++9Lu3/+6OXfbYpSiKJrRm5tmZmXVSeIqI7DCmlhxR9ulLCZkVLNPys6DIwpEGRgK209qdd3vEWkuSRfoyGsoR//CKH++3z75lWV595dUn/M0JRtY2jSudQcp7bbeuIKCJIWBnfKsi4h2LJgAgx/NuRQunNxI+5jGP9kVfcgUUIkhyzpVl+cc/3vWTn/zk17/+9bHHPattY683iLEFAMc+JUFmgJQBP52DTgreOQDISjwZ+JdSKv0YqmDoPK9cuXLJspVFOZCUnCMJEclSEFC77ZZb7777ntHc3JOedEg9atn5bHjMjIicYgSgLJKfM8Oq0AnJAHc2l8axDUBYVmWSyMyGIKrVoP+IR65DLg0yfR0YuF9V/aK8+64/Xn/tddddc93Tn3ZMaNrCuRACALDnGBMza4iELiuzMTN1HQpg6pzL6uuQ1ea182TdmgPO2vimBkAOD3jiE8i77AlfOh+GLaI5526/9baY0l133XXaMce0o9Yxp9ShV+ZNDMlAIMdcnUxR1gEqXAkACQzJiEgsialDLopCTZJI5uojYdSoSX3pd95t11123jlPyly7ZPKl8/ffc++vfvWrK6+88rBDDq+K3lwdHJKKxdhk2xtikqAKUlSFRMH8Kf4sAJeqshp/DDK1um4e97jHXXbZZZdffvn11137pje8MYU40es7pLYeOeeKsjQkZpZoE4Pe8qWTQDgx0a/r4dzc3O9+97tLvn3pv3z1K+9973tF09Klk1VVFR723OMRMcaZmZk9dts1hXrpsslly5Z5V6oAM3hfppTQQWhr53nTpk1r1qwBgKIoBoPBxOLFV1111Re/+MVDDjv0Ix/5iC3oOXYPNY7+bxoBKei8AD0Rpaj5QECQiyyMmI/gjtAlCaKxbeumGYWmZaS2bpZOLvv3C//9Ebvv+di99/nud7+XknpfOPYZCFX5yvvOQDRbaHjvU4iiAkDdoBwbFeRwHDFrDLpkGlJEproeqqW5ubmQUq7T/vyn1zzqUY/aY489RqPRPffcky2MPHkJ4rlAo8KVRVFlM6+knZRbtgI1M0c8bwNgZp7YE5tZjLGNUcGipOFwNpNIm+GoYPezn/z8Cfs94aADDrr5pltmZ4cpaVn2mmGLSgRsApZMVTV1jnJtbMexG+J8zrrzn8C8l2T7EEQDhphS0zQhNCmltm2bUXvLzbc+4fEHPPngQ35y5VW9omqagMgMyIgEOcTvFGKJQUGJKITAgGCmSTIZhQAJmIAJkAARGIFTSgo2Mzdbt00KEUFLX23atOnee+5/3GP3O2D/A3942eWTi5bUo5bBla4iI4dOYjKzrHeU/UcJKKWU+1REyrIcvxEiEFsXmRIiAyKimEYJyVJdD1MKqjqcnSuL4rqfXbP/vvs98QlPvPFXN/SqfgxS+L5pHgzM2ft2Xv9ufBows15RQlcRTWMdui4ioSz5gJxX/JRCjG2MMaWERs2oZaLND2686w/rd95p1yuvuHpubtSOAiIDZEhLgYgpqojlU3Iu5ypo7t+8cRG5LFirqohsxCFpm2JSCbFR1aZpVLUejpjIEW9Yf8/GBzbtsHrHb37zm4PBIlXQmAp2DCxByrLnvZ+bm3POEZCamllWI8/CkaFN3nvnHDOnpGDonM8bWEopqUYJo3aUx3YzqvPKMDU1c+ftd65ZvcOPf/zjpgmMrvuTRwVx4UuJiohV1c97FREgGiI2TWNmhC6ncBYgzcap3wVNTaKlmdnpGGNIcXpuNj+YI974wKa7/rB+x9U7/uD7P6yKXj1Xl84zdI4Mecmdv1qelaimMXnnYmqTBALMoSwaeHaoFkJIURgZNW8ozrkis6HNhJhFpG1bVQ0hIAAatXW48/Y7ly9ZfuONN95///2IyOzJqF/2myaoghk65wpXxjYHQFY4j9sSg7ZrrtvpANk5s5AnABHEqLE17zl3g3OuKMg5YvYhhGwDMj09fcMNNzxmn71//OMf77HHHjvtvvsD901/+rwPzw7TP33+07vuuvP09PRtt932qH32vvKqK57w+Mftu+++F1544VOe/lf/+ZvfPPjgg2amYMkAEMuylLadnJwcjUaHHHLIBRdccOKLXnj11Vfff//9991zz/nnn3/5Dy/fPDX9yEfu9b73nj0xGDAjAGZTl79o24gSPXtEdM7loLuqKiJHmrIZC+bNP8O1xsmWbs6YEZFI2vzgxttvv92xv/vuexj42muv3X///UZ1jY6yJFfeFZizJh1kBWxHHCWlNsUY0dB7rzEBoSOX1EwEkZhZxUCkKAoxFUQd+wZdf/31vbL/oQ980ERuvOGXxxxzTD2cUktl0RPLyrJJVQb9ibZtC3KJJR+kmD0ZoKJDx+g0gRlmQrsjxwUisJmBmXNOYxKRQa8/vWXq9ttvJ6Irf3zFcHZ2w/oNO+2yk0Zl9kSEJo6dSXLELWAIgYCzTGHP+bquoU8d9Uw7sY0scRrb2JHGRQWytZdDhV5Z3flfd87NDD/36c+CpTv/cOfU1JT3Xi0BmilmWUYaexRLEgZSM+89AGWnTEesZtt4OYwZcFn5oyxLieoLauva2H53y++mpqY+8Ym/DyGs33BX0zRkhIoi4phNreBCRFCzSqBn4mSpcM6zz2KrzXTrqWB2BtLRALfmi4kM2GEbG0eMiIXzsYm9Xm/Dhg3r16//7qXfAeKNGzff8tvf7rTbrkjYBnUeUTvmcn4YMwA1SWYCHnk4Glb9Ku9bmMAMQRWzVDsgWFcuzyFqhlkw+tiGpYv6sU1HHnnkkUc+dWJi4nl/87y56ZmVO6wUiTHFyhUppgTa6/XynCIDJgbQYVsjIgOboXMFCIQQfEEqBkhEzkFyjhNkNxrSBIVn54pso3LSSSdNTi6Nkl5+6stOOeXFkjLrjZwrRNq2bbW1RZOLRDJ+oeP/lb5MkLLAARxUAAAgAElEQVSuVNPURa+o21FVFSImqkDI6Agoi+cURQGqCOw9Skop6pFHHv2i554wMbnkBaec/Ps77nz0uj1Tkrw7qoEGkRBXLvaELoSQlcdEjAENgNERujFxEk2BgKXDkuVFfB5ip957FS25IO8ASMFZSMw+JT322GP32W/fJoUTTzppbm5uoj8ITYMFZeRN3jYEIdfqOssWcqpqYN55ABDLG7ZDZI2JyJWOETm7FZihiSAZEptaSklNs00ss1cNWbd0n332edlLX1pV1Tve+b/+44YbDj3i0KyQk5IuHiwOKaUQAAAdmxkqOt7GevLhtw0EbkNblr0Yo/fU7/evv/76Aw88aG5uNFi8SDVdc801vV5PJMZIjlmTFEUxMTGBDDusWXP+P37hy1/8x5nh3Pd+/COs+l//t4sPPPCQBzfef/KLXsDsz/vMZ497znP2fNSjt2zZNKrn3nnmOw45aP/DDzksme66y7oMrgCAonRclOx6phzbeMpLX3rtT3+x2y6777P3Y1YsX77jDms23LV+3/32lWSnnfrK5UsXgwIRxBCK4i8+bXj2YoIGRNzGplf0RvWwO3VqNinu5kzHnEIEM0QGMOd8SqlX9C6++OJHPmLd5z/3ubnZ0aXf/c555/391772tbptSudTbPPA8t4XXMQ6Lu8vyYbtZtm7yedgUKK4wqkKMzuzkBISEuWjJ4QmAJMiErnS+dt+e1sKcu4nz9k0M3XPffd+4EMfPuaYY4hc6QrvyrnREAxLV5IaqmULIBGpvG9jQ4AmIFGz2G0CYEQCsqzHpChmIsJojtjMmL1zxfe+880nH/zkM844Q0S+873vXvi1C9/1nndNz86AAoIRYgwxgy9FpF/18uEmn6iqsl/DEDNgX8eCH0oA4MmjWYEe1JImJAKgGMNgctHXL7zwtFecdtBBBy+ZnHj/B973vR9c9rwXPn84uwUM1QjAGB0CMjoAqqoqV1MYKabYqwYpSaZOZgY1ISAkWjDJc78gWjNselVv0F/0rYsueetb37rXXnsvGkz83ZnvuPJHVxx21BEhhHyRlJLvF/lElK0e29AWRRFTAqaCnSX1rvRcaEzz+9m2hBXQKM44z8bsiVn0ih/96EdHH330KaecYoYXXfKt733ve29805u2zEw5JrKMNujqq2PYAZauyLKv/WqQLDFyDjmRiABUuvth9pQAUDFiJkQBQ2DU7OBm1/7iF8PZ0X/91+8XVf01q9fMzk0DQFVVZAQC+QglMYKoI5akQFaVfSYvSTUZCHhXECCBiikomZoIIKEhJE1M6L0PoWWisixntkxfctHFa3be5Sc/++lBBx1kBkzkvQ8hpNAWRWFkapq9cg1MUipdAQApBvWQNcyTUfbFEVFHnlSjKBOBmJkpJnKsimLCBlVVNU1z1ZU/WVRN3HTTTcPh8JGPWCcizF7EGLHwVROboleoAhkWORsJSAwGFtrkyXfzBR0DZxOgDHSYFwjIHawAZGQWEVgajZYqXwlSFiS/8kdX3HTrrTffessej3jExOLF9fSMcwwg2tGAYEy8VUXo9XoEaGZV1Y8xlT4ngRSRQcGh81wQudA03hMBgzKYMYx50KiemdGZIRE1o7r0nZflbbfc+o1vfGPLli233377SSe9sDsYIIrCaNggmXPOIpJiv+yHOji3UOEm18sAMud0nLlyuT/yX2IIhx1++Gg0ytWYqJCl5n/5y+uZAFF/8YtfGDkEvv76a0Xs0u9coiluvv++VTvsYOxa1Ssu/+5992/sL5roFwwEzzz22Uc+7RlTM6NVq5aDAYn88sYbNz5wz9IVyxF7SHTTLTeKwfXXXUeg2jaf/Yd/AqTvXfb9F7zgBZ8579N33HHnCc8/HhG/ddHFD2x8ENmvWL7CAFQse7OY6V/kPp5rPTEm8t5EPbvRaBRTlJiSiqFKXnG6JaZTDBaJkKg79yG60q1cvurUl5/6u1tvU8N99n7M849/3tTUlpiiSGLqbKtFJGFi5qmpKUDMVA/nWVVjm/JZvoe9lKX1gQHBRFsNIIBozhUalTw1w5G60sxedspLN2y4p5Vm+dJlz3vOc7ds2dIvXF3Xs3HYnxjUMaSUUJRc1llTBE0pFb4CARDwXEzPzsRRU/qeWabLasJsFs+ZBx41ImKMEQXXrVu3fMmyTQ88qAr77/eEquzPTs3GlIDMBEUjGQRpoBMBDACAyJXzdd2aQdM0TRNSCtl5TswMRVE9cYoxaULECBHIHHlQHY1Ghx566Lp16+bm5rZsfvAZxz5jy3Bm06YHc1Yq+zibipmoQttGVBdi7PtBSsm5IpdbUlIzyyJOikAgY80PBUwxtr0eWTITaEZtPReectRTdlizanZ2emrLphe84AVTM1vauhER53yUmESChPh/2HvzMLuqKlF8rT2cc2+NqYwkzDMhhCgkCIE8RbGbMCn4bLsZ1FYaEBAagaBIi4poI2qeQUWUQW3k1zbg1Khtg0FUkHmKDCpziAkhQw13OOfsYf3+WPfuOnWnqkpK3/u6e39+eHPr3LP3XnvtNQ/GdE/rIULvII6KjisbO+89JUmWpYYEl+dhgpJHNzZBEAARUOotd7qtVqvzdtxxrz32eW3T64jyoIMOKnYXRkZGqtVqV1eXdRycatkDKQGdIxNZZ7wAJC4qEyvwNDI4AoJc5uqNXr0nIWrtn0AIYb3zRADCEUgSWSU7/LAj/vjii69t2LDj3Hl/+553D28djIoxEVXLiQKBiNbbkZGRge5pHHispHDeCcBqueKsVSJKK9YpgFqQBUghhVDkCMCREuzV48YmSaU6ZOHd7373+j+9/urLryw7/Ig3HLTIppm1Pk1TrTV6zKqZ8QYcOO3AkyevFPvngYvXVqvVLMu88LZqdUGnSWYBpZSA4AV554UQ1jmXWa1jZ5x1ftPmrYceurSv7+m1r7y6w9x5V558amWkEmkpBKYmk1rbaopIxvsyVqrVqnMeSHA+mCcfx0Vy5I1XKLPEZGBiFRtvSIzGn4eYVcJa7ULvrdZakEiSDDwNU+ntbz1qw4YNw8PDCxcuXLL00C1btvREcZaljCJ1UUY44QktACTZiOrRWWoqlUqko1qbA6kkCLJULVdNYqQEZxw447nEPiKB8JJ7OFnnJELmCaMoIsIss87i3nvvPTJYHdyyVSp5ycUrCnFsM2tMqguxNV4oaTMLCl3iCAk0daue0lAptPttNzjdzxGB1hoAszQVMnaOUOgsSwuFCCVY40XENRS9Emi57KhU1SwtRvGM6bO4IphEYUw2a+Y0NskCCPCkNc6aNSNJrRSiIMml6czZOzjnCcg7SK2NY1WulnuK3QgxZOgl7b7rbied9L/nzpn3/PPPX3fdtbGOnLczp89wBFmSFQqR1GgtBx9MgmfwMNbEUWwzR+R0rJSQMwdmzhiYYcF5LhvHLismU0AgsNZmWQibZkIIcnD88cfbzHK+oCd63/veV6qWVaStzajeXB0RBYmBgYHMWfLgwSGid6SUKhQKfT39OA/Zbm699Y5AouR4DU4v8iiEqGTptGnTtdTzZu8QkapUSioWDuGd73xnag06p5Sw1hNCrxTee+V9j+5m5UlrjUJmJtM6inWhv6dPxtp6H8nYGKMFIKIXtf7ViCh8rXO4c06SfMtb3mKSDFE6SyRwp513TU1S6O4ql0cKOiLw4J0HIqIyVABQSpWaFBGLxRg87jB77owZMzhAU6C05LkOHRKAIwkopXRoHThW7KSA4447xqQqkpHz6QyYLos6I+etk14oUijIQOq9L2BxzuyRofXDsS4ytygoBSB6evqmzxgQXJyOuLCjIwQgDeBRZN57IqmEAnDO2qLu2vm4nRKXOecKUWHeTnM9B0t5cpmRqJRSHq0HKOhYySiOC8Y4pYXWMQqBBDvMnhMlkSJFRLKeVpmXUpDAewfohZScz8l2g+NOOD6tBRSR9wP77Ld3tVodmD6NrTohrIi4C6xzA93Te3t7vSeBwmZOa9nb1Ttvhx3LtgSAkJN9a7GyiITggaz3UiswXgIKR29Z9ua3HfXXQgiTuUq1RAoAkZ1k5EAI4dHOGBiY3jfQ09XlnQMHvICeYndfT39Pd99cFqS8ZTuB8xF4D84CeFAEUjgPAgmcLejIJOb4444txL3OQzVLh0tDKpKAruZsTzKlNQkoDQ/PnTs3iiKAWoVjISCzJBTUDBsx6FhXs+rMgekudVJKQw4AiPv6oSMA70EAainB07SB6UsPP0I6RMTXt26ZNWd2llZZTfQIjpwQwlu346x5AwMz+LJ4D84brbRJM63jQhT39/VFsQYALXWSJFJLj75uhxw1UrF/yxgHAJn3UiuJAgwdf9w7pJRYVMPl0nBWmT59AI0jorFsAwnJoyUEiaov7h0YGIijIjeKk1IReGNMf2/fzOmzit2xSa3Wkjs3CyGJiBw4tCCtkKBIg0dAaVwmkNivPnvmnCUHvynSBWv90MigVOTIIVLmbKSL3ntPBgBUn1JKVW01wqinp2fcAiNs5BHcLNpkNopj74WUwnno7o69ByIfFyT7jLXSzjkltfOO6a8nL3XElZ+lQKVVZjIpNYLgPs+KpHGmGGtjHQohlQJCqSIA4Tx0xSoxWXexG8ijktwTa6+99nr6d7974YUXd9ppF60lChAehZQKhJMAAM6BUsIYw7g7qaGV9o6UluSRiGYOzPzK9V/9zW9+k7rMC88IgXVrOABYIB1JYwz7t9GT916gIgfB3W1c5tAxaZBCcGwGIkYieuX5V8485UOc1s5xSr3dvS/+4cWvfOmrQ0NDKpLs1RRCOCBwniRJks4bAVIoNI64BKzLTCS0Emi9sUgglJTSZgk7aVytD4BXgMJJAWisIQdao9a6t7vvoQceefVP61KXkUDnKJKKAyUJRK26FHubBXE8ODlvrS9GRWstQq0avyOfORPHsTGpBFRaZFmmlKoOpQt2XQgAEoWUkgim9fZ97bqv7rn/Hqy5CqGM5xKk4L1XKCQJ760Tvpbk5LzkMkEUE5ESRAoSn5FARRI8KpIg0KHx3nZHPS/94ZUzP/AhIIiiyHvw5Hu7em78+k3F/gJYyJmJWCyUHgnJCAECoyzLag2mmVBy5QmPKAT307bWFnSBnDfOggRE1EKvfWHt3x53itbaeuOtIwVKRVd/9guJqwqQAIJbKtVKP9RIAuOS01pWs1p53czZrrhQzVJuoMZFMjh1iyHPX9YiPgkR0Vs3rbf/d488PefiOda4YrGI6Ie2lK76zFVcj7kWDco1+8POvZdaWM/BgqilsklVSmk9RVGUpUZI9FBrP4Moa9Gf6ImoEBX/9NK63p5+ttE663q7+554ZM01V395uFoSQhA5AocgHQlBQkkEIEfWC26NjYK8ty5WcZJkWsaAaDwpJTx4jz6SKk1TrWPvrUeQgIoUeClRk/MkJAJIKT1YBdFXVn4l7ioYl6FGb6wGhYiGvFLKWYtCWLCAKKV2xgqufIrCORcL5ZwTSllrOZJKauURuDukRFFUhWfX/OGCD10kBKRJVijE1loV6YG+/icefmLTpk2VpMxiotaadzdaooqLV4IHrPkFhZSWAAR66zQI4YmInPAWSMbaW6NISlEvilVrKykAPANNChFB/NIfX3nzp95KREppInJE06fNePThJ0Y+/+VKOkIOlBKZcVprZ2qyrAfn0ACQ9Ei11lvAIT02cwAgMLLWIWIURUlWUbpW192amoCrhUQSjqxDp7xWie5Y/ZYh0CK9qIOTecxfawltTdmTzZVMct/wikSLP3G2HdTyG4gYA8cGdE/RCLt2ziRZNbUmV/G7pm3UTMuIDhw3uBdCKBYGQTbALWSZ5VuyIKKWuqi6av0BhQAARzYxSZZl3vv8pFzxyaMXxJ1+JYFzhMyBvOEu0MjFwz0XXg1VlwEQJZGTiEpGRRWHuGQEtM6mNjXOOOeYMko+d/RAwtcTZwUBoGe6yRHJvOC8fyzkZPHDAEAeIxV16W6lVIjsRsQtI5tzuwtnV2tq4pxTSnmyjsh7r6XkX3HIEwCgIF9Lc5GCAGv3gSU1AMCBvoHQasV7n9k0tan1tgmfa8tGYm0PpKy1UneWiLhwFXBBRo81xODGrETE4NJCKqULMlZScZAoEBqXVW01c1mtsVCbbGcikgprWpcQhOitJURmxbxrBoi1NvQOysONodhd6NYy4mg0AEhNUkkrbOurP+thLO4ZmwoV8XaEEM5YAEBZi94JywvP86Xj9WipYxUroUMcV2qSxCSuVk02YAXWNGSAWtMngdZmkaolhCFIZ6yKtPcE9aKWYwrJssSJsqALUVSoN64nAPDgjDGJSbiiaH61+S24Ws9g6ZyLlTbGkEAhhIR6d6+xmBDipCWISMVxVNRC1lJugQCEdVm4L1RvG0VEIVU21z7Aewfs4fPe1y6XlC4zHARBCPwlJ+o1Fe1GzgnlrSmUkYrjONaoa61HEIlcNaumJmU+TeCABOIYus3ER9ThGVCIhRKTuVrXxYAnNSpcc+IiywvgAUAJVdCFSMVNlcrGjGa28X9/1HlGbYQAtSl8f3gz1DPI2oGJ5S8AEPWQrcxkHHPZ8nmsk4NwCfnNwfIQZqxhZBt9qfZXQAJiM0LnQvH8TgihrmNvC+XyGcLyRtecAy9Lrd57JVVmMgBQSglszEIfndfW9tj82pbDkZVCOu94kcYarbTzTgqZmYxfJYUEgDRL4yjuXMwrT/5qIG0DT2afSiqGhjGG98XNrfJPBjDCWFRpBmk997AWudRyXiIKmENAWZbFUUz1woNUT6BBRAaLxNZRHnUiMmZttfs+3n6tsxxpAQCT3m+trSkwDQ1PthTmiAhFDdm4n2tLCI8ZvrapgEKNf/c+v7xaQ4imeYlIChkA67yz1kZR1E4IDmfHyFZnG/Xgyab70nb53kshrbPceSIgtq9L7AFD+PjaXfjm9dQxx/N9ZPiEI2hLfxCNMZGO8rvoDP+W9Krz+H+RbUB7ovbnmKLz+wm8J89XLk93GohIGDgWTQMLZKmqeca2fQUAwrxMVZnCTmBnkF9huLTtFtwweC4mrJGO+D0dpg79kGEs6WkHVapfy0A3mcCxQMT7DbyEiLRsm87ZEknawTMAM3zocIitll1Tgif7W34yT01qjci8V0phrWIhZibjq45tyFwz2+i83zzhy2PRpPcbWl1N7BoSeJ7I17uuwSTvC8/Fbp46qc3pRm2KXjNgOe0DmAnVZpxQgH5gG9yXEyZ8XxrWAAACRcer2mk9+XvBayCoazxjv2/3hnDKLN0ygnX4SUt8y8O89a/+32Qbf5mRNwi0BRNSZjI2OtfkQe5J38b+15AjE14bjAD5fwI0Bt+EwRpGw6kzeW23l6CWhbsXcCXoCuMeN989gYJ5ZAPytdzv6HRjZf+WzxuXISJfKn65c46ZsSfPhhrIC+lttI0xpLNeuAWgLTxZKqy17PU+aDzjAmT0BMcCk3KO6w7aauC+4fInaRJybJ13xphCXGAeqaTqoF01bLkmhrfXrvKYE6TXdnjbbr/NYkFex2oeHFzUjLptK8H7UUmcv8hr5wGRGrSN5iFQ8D3l68nYa6zpUEUiT47zC4JW96XdfoMyFDhc2HjeShHA3k7bGBX2G0rk1ot8sMzRLIM2v4ftVIzhzIC10uPeXxh7hTuP/3Zso4W81lE6Zl0b6nScQ6HZ3zCpWVo+0PkZnpTVRva9d3gy/+bt1M84lgEA0jQNwdkdpuMPDSDtsIa8VTBctjBp2CmDWk24EMA4Wg4RhyqwI4Ghymc6wfd3mLTDvOExqlvJeaeBzYf9TuTgwnsmMmmWZVprrFesy8do/flGPSC1NiMAsD1wm+cd38wCAAB57aRms+KYwDbnO1k60HnUKvfIWiEGNmIHEj/BN0CT7NXy87jvYVDkzdoToR6T2v5/O7YBE77q+efZhRtQc1Lkph1h7byAMAXLlUTEtSUmhdaTsvWFJfEsjHOcgMKMc4LTjcsIa6WNAIQQaZoyYKMoYg7NNvSJc4vJDk4a4N0FqW2CwJnIkw2jXuC61gIvy7I4jpMkKRQKQSLhGITOsl47I1Xn55k5ERHnAQSoTnC/zVpUJz0jhz/MmJmAQp2XjLvmMPL+jPyCW87O8zJe5bcZwDvBkYcwTPigA8OAHMusu1VGl9dh/eOuKnyekBG4fu68Kr5fHYhVw/Ia5mo3/juyDWhlq2kHpiAFM04EUXFS1wBaHU8QP9v9hJ2lHLbLRbQ6iwyTYhLtfmuMiaKI5wpYPoVTB3jyDZdS8vXm7wPn4IcnwpsbjrIzPAMhg/qBbo+MOVmAMzxZCWBzHOtzeXtXB2NIA8rlJfqWI8/yw8+3Yb95ftBBgg7QoHoxHkRMkoQX0CFkIHwI16Hl/Wq38nCbOJuSg9ZY8G/nZm+efXuUsFD4Ly9T5q9MHvjbv57OJxjYZ55MTUrrmsj4b8o28mNcwNXKZji3devWlStXOufe+c53HnbYYeGBlr/dToxkDHvooYe+//3vW2vPO++8nXfeOdDcbXhby8U0n/6tt976yCOPKKU+9alPQV1rHpdHNijUzRPlB5eM5Qvmvb/hhhteeOGF3Xbb7ayzzpq4VWobjAws44+MjKxcuXJ4ePitb33r8uXLG55pluinhLIE1W1wcPDaa6/dunXrX//1Xx911FH81wDeiZCVQJTHXRJjy1NPPfWtb33Le3/yyScfdNBBDc9MZL8t58rzkoYX3nPPPXfccUcUReeee+7cuXMnKGNNSu1rnrdUKn3uc5+z1h555JHLly8PQsm483aYZSLrCUIPz/Wf//mfd955Z7FYvPDCC4vFIssEQWnrAIrmo2+pB3QmNQAQgH/BBRcMDAxMUMaduOw1+oP/GR2GtTZ8fuKJJwBAKfXpT386fMmZgEQUkrYmNVidtNaybhteyJ+/9KUv8TH95je/Ce9nahuieMOHSY3823guLpT79re/PZjasywzxmzbvsadnWtWE9GCBQsAYKeddiKiJEl4MWyinZK5fH0QkTHmT3/60/Tp0wHgzDPPDA/wevI/mZKpefA2eYrnnnuup6cHEc8999xw9FM4F9X3y5+dc7/4xS8YhW688cb8X8PJWmu3AdT8k3BM1tqwkc985jMAoLV+7LHH+K9TiEIMzPy8/N+1a9cCgBDi7LPP5ifDhQr/nNpjDSNc2yzLLrnkEob2ww8/HB5ogNXUzks5EkREF110ES/gmWeeCVue8iv857Ig/5cZUsrXXnvtt7/9bV9f37PPPssK4FNPPXXPPfeMjIzsvffe++67b94PNml1jwN76nolACilnnvuuT/+8Y/FYvGZZ57hWKP7778/y7Jyubx48eIddtghSK9QT/CZrNEsmBFYwH/ggQc2bNgwe/bswcFBVvP//d//vaury1q7bNmyYrE4Va7UIAauXr2a3QylUolNCqtXr+a6TEceeSRrOdvvsg4jy7K77767WCy+8sor1WoVEV955ZV77rlnaGho7ty5S5YsgVZuye0fbKyoVCq/+tWvoih68cUX+Q6vX7/+vvvu27Bhw+67737QQQdNuUdnw4YNDz30UE9Pz4MPPsg2sSeffPKXv/zlyMjIggUL9thjD67ez4adbXh/EJ9Z8JdSPvXUU3/84x+nTZv2hz/8gY1F99133+bNm5MkOeKII/r7+6dkX1yaIfilyuXy6tWrC4XCli1bAAARn3vuuYcffnjDhg177rnn/Pnzw5WcwjPND768a9asefnll2fNmsUX1nu/Zs2aLVu2VCqVZcuWTZ8+fVyL4rbNy1EeSqnf//73zz33XH9//8svv8wn8utf/3rdunVpmi5ZsmTWrFlTNW9tTC0X+q83rLW33347N5EPmMeFbIUQ55xzjvc+y7Jtfn+DDFKtVq21LLPwdEw3A0G55ZZbmqXjbZ7ae5+maZZl3KY0eM+Cgq+1fuihh7ZzoobBexRCFIvFgIeIyPRr1113ff3116dkgzx4m2vWrAkT5eEppVy6dCmL3n8OgZRfeN999zEwmXAUCgVeg5TysMMOCyg0VZqH9/6KK64AgCiKAlcIG7/gggtYNKac8D7ZKfJqBGulJ510khCCARtQl2f/4Q9/OCX7yk9NRNba1atXa62jKAoUmWELAKeccgrV9fgpnL1hMABPPPFEnjRIfix8aK1vv/12xq4/h9ZORHx/zzjjDD7uEKDInBURf/CDH0y5Rjtl3O+/6uBjCHAPEZyMjq7WJwchl0Y7qYH1SNDwTagEEN6MiCFEJMwY5nL15kuTGlT3QPJV5wXwNsPUiMgY37kc5qQGK1VUp+ZQv2k8FwCwrYwxfhv21WFeAIjjmPfL/2RNrtbfbeokwfzg0wnnSHVHcVgDIrLWRVMXHRvek2VZvfVLDalYw2hQa7YBb/M/YczkejksEHAnwXAjpkplhLHBXXxxAgvkLwOu1ur3/Jl9tyx40dhE98Ahaj2y6kR8CuclGq0vEAiIMYavDAcr8kWDHEymavyPS3z88dprr/385z/v7+9/+umnL730UgA44YQTPvjBD1Yqlfnz5y9atChYGLbBWBTi99kgw7Tj2WefffDBB/v6+m699dZbbrlFKbVixYrFixePjIy87W1v23HHHUMYKxsZtsGYE9gDW1HuueeedevWTZs27ROf+MRjjz3mvb/lllvYdHbCCSf09PRM6uUTGbfddhs7Ei+66KL169f39vZ+4xvfMMb09vYec8wxVDegbT/F4Z2Wy+U77rhDCLFu3brLLrusUqm85S1vOffcc9M03XnnnZctWwZT5P1uOQYHB3/2s58ppdatW3fJJZdkWXbMMceceeaZ5XJ5t912W7JkCdtetie/oWG88MILDz74oFLqySefvPLKK733Z5xxxnHHHVcqlRYtWrTffvuxbXPiMQgNg3KuaSbljz766NNPP10sFm+77bZ//dd/BYDPfvaz++yzT5Ikb91vdfQAACAASURBVH/722fPnj0l+4JcMhMAbN68+ec//7nWev369eeff75SaunSpStWrBgaGtpjjz0OPfTQ/JWcQsacH8aYRx999Nlnn501a9bKlStXr16NiF/4whd22WWXJEne9ra3zZkzZ8oXEMzUzKueeOKJZ599tqen5+tf//pPf/pT7/0Xv/jFXXfddcqBXxtTq7z81xtBDbfWPvLIIwAghLjiiiuorp8yh99m+0ZQopkHeO+DB5WIVq5cycd077335n8SnGDBgbwN++JfsYWBiKrVKhEtX75cSlkoFGytY2tGU+pSC9IZ1f2oCxcuBIA999yTiEqlEv/JGJN39G3njCwF837Xrl07Y8YMKeU555xDRMFWM+WKPI+8kcQ59/zzz3d1dUkpzzvvPLZNTbnTOMzFmHnXXXcx3bz++uupvl+WxLczqiK4WwPS8sleddVVbJ5as2ZN+NNUjTy4wr1zzr366qssYfCxBgNsfmt/DiNkMFDz3lesWAEAiPjYY48x/KkeDTHls+fxiuqk4MILLwQAKeXzzz/PwA+xJ1M4/sclPs7gXA020c6bN+/0008noiVLlhAR23aCsDbZ9CIerGGwpMmiH5svWNBevHjxmWeeaa3deeedue+pG5sCymoKTd6bGoI4eWvOOWYVJ5544rx581jPiKKIsWQK9Ws2+LJX0xhTKBROPvnkF198cd68eQDQ1dWVZVkwkdOU2m34bT09Paeccsrw8PDSpUsZhqxvsXa/Dfpi5xHexqawadOmnX766SMjI29961v5iBnCU+v/h7rhCADmzp176qmnKqXmz58PAHyy+TQgxqhtm8XXE/65RDSHoi5cuPDUU0/t6ekZGBiAqc5O9/VsG5er7+mc6+7u/sAHPiClPProo6EeNM8IzD+k7Uu7azdCTi5bhA4//PDTTz9dKcX4zMfKutEUTsqDU6ygbsRmOBx11FGbN29GRPbx8MlOefIseupYYhQAoEUh9P9WI4SLNISduAkUpp3IaCgvkScfDSU3fD3lsFZNffvCM/JmsUC88veKJZrORRq2bdIwhc8l2ea373MltrZz0NiEgHBe+TTD/N3mx6bwhudZb8NZ8z8DTKYQzlQXrlu+Py/ibA85C78NG8k7pbYzm7LdjFD3cOTB5esZ2izJYT1DvuXsU07Bm9E43J2GlU8tKPK3tZkchZVMuWkODXkBwE1mwo0BAC6phogUmt3kWmXUblc++7/NBD5XQqteirl1ohb8GWzKnUeDX6HDkwFZwz8ncr19LkuTr1AIlg2khMb4lvIwqb0j91/2VLedN6QcU91B15AeyNvsvNngZ2v4b4fng8icz2kK2/Rjw4tzGxwjBnZOg2rIes3T3Pz99N7XGjbg6LKp9l8CGC2fSlTrBsL9JzpM3bDBwO3y+bcTER3CudA2eYnzRGesuNC6gU3tguZK8iF4AEDRWvAMEgkAMKgpV9Ypf6bQUScLUQwNaNMBi/Kp8vzfhmJobmx6f/Oc+XnDXITck2b8rHuWw/Ja9TbILtt5vvmXUL5hFwEiOqphuLVWKhUKqmLuh4zPLlemfiL3N9yvUGdvIlYTNETILIEIwHuEWg/ketvC0JnnvwzbyN8E1qyxKek0jJbr7DBCKAWLXSFKJ1AfVy9vxcR0LHo1b59nHL2K7ZTDvIATJOj8hQ+qUohlmshGxt17nukG2hqwMOy3neDTYRmBRAZiHcwpgZHkLS21YCHPXShyUyAAhHquo5PyNeugawduxBaAhvyYAO1KpdLV1TUR/Gm334mgfYBDeL5arRaLReD2qGPYBhMLaNxvrbZra3LP8V0herWlJ5kfCEc57poncncCVoTD5bJdgT3nCTcRjb0jY25Hw7xUb+3UYW1+bJFHl6tx6cbWZdme853ICEwrgJfhAATOWqlHZSYPNFpdODcbEhARiBxNnhjtyj82EckSxrANAADvgQAEjdbZR1evLCxzx1MjXhNgG/nlBpWq5Zb+Mjwj3IFAC4goWAm3f3AwJWM82+7zFDNfV6NGanO/HXMhxlDY/MVoK+Xl5d8G6wcT2Zbkb/tHeG3wsuS3nFcRYLxr1owDzfSrgZFAXbKrKTSeIMcMELEdhIEAxl6z/Aj3p8HOE5hu3hTTAZ6TNRF0Jk9BzWI7jLVWqVpXt/y2Rn815h0eiNpVWg8Ywl4K3nJgyVR3ngVfQocaR5Pab4O5jKknC3OQi9TKsoxj37FWVzy/y3btDzphOLsP2fkRbmX4eV6qy+Pw9u+33ci72ca8k4C8B4FJkvBxCDXamQbzMjf/fxt8bjcYvIGJ+omlLbdlG7VOyChaso2azpF/Uftl1R5oX+LmL8k2IEfm8oVrtllMaBj56w11Aa1Bx4e6rApjjSRjhOQ2F6PDZah1rKvfar6QYWqqJ0NMUNsI68zvq3kEBT/vjwkGbpnrRkl1G13LV7V7fx6t8/yeqWee2deIeN1IFV7b0kgVPrfTNpoBFchH3ikSANv6LZPH7QZBPvwwjzyBanvvBRK00jZqPx+j64+jbfB14EFNzoPAoSeFP+OOvEYOY314zcqr974z2xg7OrGNoF3l5ciGKteseQQbWsv3TBXtasCigF3eOqW1dTUbr3NOyNEmhs1sY3xPddO8fOJ5CcyNVwVSQL4BMQhuqlz/waQEUg/ggVw4RQq+9AnbB/8yA+tOPEbWarXKiWYT/O2423H1AQCFQiFo34FVMEY2y2uEbKEMkAvTyXHPgkUnlhdYTA5FyKFub+ElMTpO1X6DJM5xflC/AHzlfK5cR570578MdCo/2i2AuQ6/Pzg2wvNCCMIxN4eIgAiIsKkvXMOTDaOhUi+DjqfL86oOjDC//rbTNI0G8pRnWs65LMvClxyNRiAaOAHWdkYIY1/V9GR+BE9yUKSCYgEAPK+sN4Gf+H0Zd/DtCExCKVWtVoMpMiCqcy5N0zaQFE23o/mbxmGtLRQKHKHrvU/TNPwJ6+VS8jmh7d4zVcSNX5KmaUgC5b2rSFtnw1+llOQ9sqI89qbwkU+EQOWHqKfvYL2nfe1tY1/euFpDXgLiGFpPAABeAtSUCI+EgLLmpyBA5CZq+e5dCJ6C3R1z5hfKm7Ja63R/SW2juQh5kiTY3lY72bUFMT8kRnR3dze/sFwuM+FzTd3W2nS9BCJ2VncqgMwkO0TdBbOVcy7YH5jqTZW0CABpmhYKhWCP5okqlQq30AgMcuK8qmFfDXyFKywVi8W8LMwlFratvFK7eRsUCy6+EpbEW+Ng+UlxYmhzC8KfWn4vpQzNOZhwM9uY/M5aD19vPsY74ipk+UX6XAWUrq6uqeIcQa4vFAqYMwcF2Z85Fl+WNE1FzaXfDO0JaeRhMJxZ2whgZMUipGrxXeZ7NKn7sg2WKwZsb29v3jsdYjg5KYTRTGtdrVanqn0ZmygCZQhn0TkcQGGjvTcv6I3+A4GlNgD0UG8vDIQea/8gIiAHBJDrV0xUawjZbMMaY+CamIdtSgaDW2vNVOYnP/nJddddt/vuu09h/j0fsDEmjuO1a9e+973vPe6444LWPzIy8qEPfWiXXXYplUosHTeMRqF4YrZLKWW1WtVaa623bNly8803B2Po888/f/HFF++9996MfNtGvjsMY8zuu+9+6aWXshNPKfWjH/3o5ptvnjt3bhCdgtIzWUrnxyY38E43bNhw6qmnHn/88VA3A375y1/+/e9/XywWp3B3gV0VCoU//vGPV1999V577UX1OJnzzz9f1NN0g141qZdP6rG1a9feeOON7HtXSn3oQx/iuz3ZTXUYgUpqrTds2HDttdf29/cz76xWq6eddtquu+4KAEzKp8oXyHSQN7Jq1Sp2ywUj2OWXX75u3bru7m6s+wUnsuX8DepghCwUCs8+++w3vvGNuXPnsggSx7H3/sUXX7zwwgvDfQkC2VRst+0QQnAN0yuvvHLRokV8EES0adOmD37wg5wMy/qW975QKEwV22ZKmA96VEpx4e08ijYwwrEsq0bmwYOQnbDaEwiftyBDLn7XO5A4SQPXX24EEsbesI0bN3784x9fsmTJFGZaBUZNRA8//PCTTz4ZghOEEJs2bTrwwAMvvfRSVoQ9NKJjLTB0rCsIQhxam3PJR2p9+MMfBgAhBG9qw4YNp5xyyrvf/e5gqupsuJzsWLdu3bXXXkv16je8x0svvfTAAw8MegZvtp0UNq50FgJD+fPvfve7hx9+GBGDxD04OPjpT3967ty5UyuAs5dSSnnrrbeuX79+n332QUSW9ZxzX/va14LxfaoyqhrIUwDLF7/4xY0bN86fPz9NU+fczJkzP/OZz0xtGher4CxxX3nllZs3bx4YGOCsz5deeunwww+/5JJL/FRXcoU64z/nnHOYK7Csw6Yha+1NN92UDzicEN5OwOnKl/Tqq6/evHnz3LlzQxdCRFy/fv3f/d3fvec97/FTUdtmgoOR7bvf/e5LL720aNEiNjhLKbdu3Xr44Yd/9KMfDS4W11RSbHtGoBs8XZqmn/jEJ/LWqpajPn2dqb6ydu2Xv3wNIZLxs2fPPvOss2bMGLDWemu7CjFZi1oYa5RSxhoAoZX89ne+ve/eex126KFPPPrYGxYdeONN3zr8f715n33nE6D3oCR4DwJr3nbvSSn09eDioOsEav4XMFVhzmvtvS+VSiMjI67exjIwXrZlSRREBKK2PKWUcXY0FLLJxQoCsZ7FppQql8vGGKyX0GEqUyqVvPdbt26VUhLWSG0Ils2SlKUerLfz5BgSluXbHSfVHc69vb1cJiT//datW7MsGxoaYhEmmJKD7BycIoyX3OAv5MF1JutcIYPfE/jlpk2byuVyEGQa4M8BwXEcs84XZuG1scjJ28knJEJdAxgcHHS5ovEAwPXstm7d2gATrMdTsk7AZ8H7ZZC2owth2c653t7eoaGhOXPmYN09473nyijDw8MNunIDGksB3nshNcuPAIBCBW6H+Siguss62OWCd6G/v39kZETmihOXy2Vr7eDgIIyVMMIKse7iZhEhTdNiscjbb3eOUHdQz5w5s1Kp8Gp5UiFEuVx2zg0ODuLYkFlsin0IyJBPM2zHaXhts2bN4gIYYXn8kzRNt27dGsI6ApIEC74xRkWa0SmKIqRaOU4pJXii9pFyADAwMMAye1ibqCdXbdq0yVrLNzScRcuXCCTvPQoVKC+fYP5MG8635XuIqL+/P01Trv8WcN5az/Vzy+VyuVwmIiFG4ek9BF28Lql7yiWEhfD3dkDg3QX3ZKFQSJIkEIdwHA1oo8KiEYUx2TPPPHPrrbd++ZprTDW78847ly1b9vjjj3vwxUIxS6uRjryzApXzjlBoKY2DmbN36OnpW736ri994eo77vjJ7Fkz+7p7aqRZgCdOgtcEIAR4D5yrQk1S9l9s5MHBRIqte3m2QfVitxKFECI1WYiyUJEO4k8z2wjaA+OQHFtala8xf8/mcqEkZzaFKJ3e3l5GwXDewThDRPk0qOZNMZYE22i4YDyd1jqwDSYrrHKVy2W2A/CFZ+NpHMcyl+3VjtzwOvPqC88Yx3Ecxzg29RoAbL3NspQySZLu7m5+Q6DvURRx1436xfB+bMoCvzwQDn5t2KDM1Q/Of+At8NTMLdig1+5GhWvD1oMA0nCI/H0wfLeLx2NiYR319PSw4sKfa2mVE2MbnFqUPwKenffbcv3W2u7ubsYoAODeUNA+DS0vZzDS5qcLeBv2yw9QPVWTrwYfVldXF9Nxjgfhb9oZgZkBt5wxTMoInLdSQj2kJY5jQghow7HvxWIxTVNyvqXvMMAnP2OwRPGXeXQKnLjle4CcUspYz7ESxhilY+7gDZNhG+HmhnCAgH48wkqEAH7Mey+ECsKWUpG1lsgFiwLUlYkObr/8LLzxiZgiBIJD8AgI9YNfsGDBsccee+KJJ95wwzeNMeVy+fHHH1/2v5YdcdjSa796jRDqhZde/Kujjz744IMv/+QVUsLLL7+cpukt/3LzL1fffe8v79m6deuWLVuyLDvrrHPf9KbD3vGOd1aTZNPmLRdffPFZZ529+E2HfOVrXzeefPu4uT/3CCQVciQA6pQi3J8Q9ZRlWaFQEPW8hOYnG14ejjlPa3y97lh4rEZSnZcowJMzVgDGOuIbwpWog0pkjNE6jqJCh001UFLIkU5eT/gv84w4jrkqYl9fHxGxj5ejSqIoYm6RjwTLjwCBgGRhdw2id37XzPaYpiRJEkAk6iGPAMCz5/tP5N/T/MI8SPNaVP4cGZ5BedJah3T6zufI4Gp5kQK08/jTDCIm/aHgGNZLcrWbN//zhg223G+7Z4LbXCnFXMfXQ/JbTh3IU2eSEfabXwajAVNt1hTDBhmAzLpajjBpy/PFnPLEU0dakrc2M5HSnHvBGm1SzbSKnQdAWalUtNYoRUuewe9vxwwoJ50Esa8lTMIGGUu5nBqDnT3t4x5x/j35ewRNuJTHtDyJD6ZvhgM/li/KKYTgfiSd4R/eOS7D4FF3iXsPUto0AYCRkZHf/e53LrV333038/MTTjjh9lu/t2TRGxctWrjv/gu++H++fPrpZ7zrb969/JjjN24e/PWv7+2K9PLly3+35snDjzjsqi9cPX//BZdffvnmzZsfevC3V1/1xWOOOeZnP/vZypVfunP16kv/6bJFixaddtpp/f29ABACkP9vjfzphv/mBVVAYGsAInZ1dSVJglJ0iCRpSdFazhgGp/sqpZIkEUKEaqxM5iqVSojhqVarUdS2OES4e+0mhbrwzjjHFToRkbvdcRMIyCUoEBHPjq3sMM3bgSZ0b7lOln2YP2E9TpdJG9QdGGxR6fwqGMurAjnI/xfqal+1WmWBbnh4uK+vr1wuR1HEoSPt3tzw/pZbplyIwSjOjB0jIyNKxywRZ1nmPHR3d+eRbdxtNrw2P3U77YFhy8YNObbTV3hJwztbfmheYaBH/M+gDmqth4eHmdSG2Ac+3M52kgYUYuLVcCUDnKtZFkVRHEfVajUuFtI0zUzmvQcSIeqJLS0N7K3d1JA7uGY8D4fb7phYrPSEaZoyg1Q6LpVKwSowwSNuJgstwQ5Qi7zlL5lpsRMojovlclmp0dh0JimdU74D3Rh3hfmhjDWR0oAIzrFh4dFHH73yyitdanfYYYe77rprzZo1++yzz7Jlyyg1K1asuO3220973/s+ePpZ37r5lssvv3zWjGmIaB3NmjVr+vTpEEXoyTt39y9Wf/Xr36xUswsuuvD6m67/02sbDj7kkGXLlhln99pn7w0bX+vr62mAS83g8xdnIs2HFBBIa62l6unpYQupc65YLKIUg4ODNaWPcvjUBvR5iQlyohP/VQmpY2UzI4QoFKJqtdrd3R1FERsqrHd9/f0AkCSZMSYuFMi3VvaDyBbeHPaV/yYsKejCfLW6u7t7enpkrpZGtVoNUS55I1VLcoNjRwMkIXfrWMuRUvb29rpcVRJrLV/7crnMIbYM/wZa3DBLfiO1tUkBgAijoEACJWTPwHTnnNQKANgSWEmqWZYp0ehrpSYG2XCp8nsMqJL/JkAJESOte/v6nMslcyFWq2ndSDUKnLr8hM0vad77KJBRAhCCDz8RSIg4Y8YAELHJi6euJpm1Fscq+S1xI/+hA7nkNHKsWzZ6e3t9vbAVa1dJknjv4zju7FNpPtPm5YXPWmuFIqlWC4VCNUl6e3v7lfKebWtorSeiarUqVcRlV5q32UyOmxfTfO7NvwqPTZ8xgw8KWLUFwXuHsb5b/kxNAS/h4PILGH2mnq86ei7hf4jWeSIaGBhwzjkPvX09vp5nw1JgoVBgLWSyjKHzUFppIkIhyFqTZcaYI4888t/+7d/I+ChS1tHatWsrlQoCCq2NMca45cuPffrpp3/w4x+f8I4Tb7/1tq7uHlb5Y6XBWG5MyCEZxUJEddBYa62v5UyFIqCA+JdXOPK3MeBrjpmPDiHENddcc//991eSKgsyWZbtvuce3PcGACDH+WsRUKIR7fLiWwMiYj1ovSb7A3L47Ac+8IFKJXHOeSCttTX+1ltv7e7uds5hG59Qh2vZLFJh3SJkjOnu7l6zZs25557LuhQ7Nvbff/9vfetbmzdvZhKAHRvtNRCyZrmpYeNdXV3f/e53V61a1d/fz8wpSZKTTz75ggsu2Lp1a7FYlPVi8sGyF6xPWNdOfFPjtjHnOPZApZQrVqy4//77M2u4T+qmTZs++8+fO+qoo7IkzUMpDDFepeuG692wx4Bj991338c+9rHevmmlUonl8SWHHLpq1ao6Jc0dDRP0XCEmamoR0Qxz/msz2/iH00///e9/76km/YyMjFz3jev3228/8o2WtLDfltvM08f87FJKjvZhR9GWLVve9a53VSoVV6/aWSwWb7755nHJVrt588sLoJYowFsPnsWLGTNnfuTCjzz40COhtcHg4OCqVave9KY3MUsLCuu4RLOdrBCOuBn/awgJ/l0nnbRp81bG2EKhUK4k3/ve92bMmMFPjYIx59touZ4x0kAbkSU8yR+KxeKaNWvOO++8KIrKlSSKIiVx7ty5119/PdsqGA7Nl6XdpNCEyS1Hvc6MJxQCySPihg0b0jTVqLwDRFy8eHGpVPrq1766dPEhn/rUp+74jztPPfXUvfbe7xOf/PSNN/1LajJjzMjIiNbznn/+efB+ZHjQG/u3f/M3F1+84vobb7zq8/+8cOHCvmn9g8NDjE9bt241xhDWyyKMgrX+4c8fTNUwUf7++1yei9b6Rz/60cjIyGnve2+lUmFhqtjdFcz9+YXW1t80C4w9iQbmxHHTPBeg5xibJ5544vNfuHq//farVlMhBILs7u4mgeC8aBMZknfmh021lJvCMqSUXLpueHj41Vdf/d73vsd/Ys85h12xVTS4+FqCMb+dUWjkRv55RDTGrF27loiuvvrqSqUCAEKIGTNmVKtVzvkKdb1EPaqtgccHWtMMWMipUOFXWusXXnhh3333Pe8fz+fYJ2vtfvvPZ4rWYV/5fwa+1cALG+hLIDFMW0ul0rp16/6/L67kAxJC9PZNYwsSIo6VRgEACDCYucNmG1hy/gP/SWDeQY1Syscff/yEE0445tjjucOY1nqHHXaQUjpqG1jZgCrNEMh/Zr+CECIUI3j88cevueaanXbaKVhBWYLEXA3zicC55XThAwKQ80IKqZC8X7NmzQEHHHDWWWcNjgwLISKpdtllF6aSSZYKIdpVwB0F+1gVpyXRbCZKo8AneOqpp8798PmHHnooh64lqenv78cxGiTkPneCQ8P2gyjQvAY+bg6veumll2655RapIgCwJp05cyYLhSE+Kr/BzmNchsFDEZCUEoQAZ6SUu+y08/vf//5iVHTOCQkEgCjv/sUvVqy46O6f33nDDTccfPDBN9544wUXXPiuE99x6invOeqty9a/8tL+++y95I0HHrDowO//4PsfOvvcgZkzzj733FJqL/rIBfvuu/dXVn2pVEnOPfsctnKeccYZM2fORAIAD4BIvpZV/pdSOVqy9HBODZS3UCjsueee559/Pnv8iAilqFar7V7eQLwCUuY/55/ncF5EJHDWWEQSiFqpBQsWHHDAAd6DUspktf5cIES7SIIOZBpzkRJhkYxPVA8Y6+npWbBgAcdTEQJ44rDaUI9k4rBtIOsNwCEidipMmzbtDW94Q7Va5WgupuDsCQ8Bsmwug7GXCus+2IbNhjvWcKZExCL8vHnzFi5cWAt+RVmpVDqHZVAu0DM/XTOcG2hNHp0Uir7unoMPeoMnLBaLjnylnAgu2kEEWDtQIqrVXMBGH0mdGYiGedugsSOq+Ut33nnngw8+uBZkjLJarWZZ1q5OfDO9yKMrosxN5wFqsUZcUUZryZFp++yzz/777x8YGBtqOvCM5qkD5rSk5iQQQCJ68KSAwGdK4u67737AooWZ8YioJCblikAiqAUgkGt7xGHWllem+YibnwRy6J0gv/8B89+4eLHNLKLUGkcqqScn2PxA20LZRukGEgqeWyICkCNQnqwAcM50dxXjSIHAJYccSkRaaymEMakxDuoKKN+jCbKNljSkeSgENM5rKUBq8On8/ffdd98FiMA8I0myQiHaacedbv7Ov0gpgRwBTuvr+fZN3yQiKaSx5v2nnaokAsDN37tVCPDOAUpAuviij1yy4iNAkGXVHWbOOP/D5wipCOjCC/4RuUQGEXhLRCgRUXgCImC0tiZVWgORtVap2JMXQhCAJ4uIAtB7jyRwHGFiogNzflRRjxBn2DlHSkXO+GKh6DwphZVqCiQInFLKGWutLcYF9kpprTHHe1pKTA3HYx1FWqLzzrpICkAyziqEhx9+cPPgVu/AOZJSL168GIzTkQzhdN57gUT19B9PvsG54gk9gcAWqgDkXGG8zSzL7r333jiOCQRIESu9ZMkSgtF670y0vLfee4mjrXgAx3BK3mleo2/ceL122fDQ1t/85jfsjSei2XPm7rvvvoAOUHgOBMqSfPhjgyDWUiQEAAFIAN46icL7ekKMc1LKV1999d57f1sqlaRSDnCvvfaaNWsGeCtFLYQ07DcPmZbQy+83fA70UdQrb8eRAnLWpPf+6h4LKJTOrJ02bfqBB74BPZC3WioiYb0RQhDvsUnebGCHDWwjv1QpwHsE54XykRTPPffcr371qyzLhNSlanLIIYcUCpH3jvdrjInionPOutHiKDVjFwFS/aSAACRQqPLkAQEIrYV62o30ZK3NlIoeffTxjRs3+np/8sWLFyOiJxQoGCayVsucuJqFrGei5A+xHREnIkKwICMhyCToUoRCLPGFF1761b2PVLKKAKQ0Xbj/vnNmT7fGImqqTecQgEMTldbGOJQCUDoAQMlshUI/EpT5s8aczbAZ34R3EVkJ5omnn7QqosQLEpb8QYvfWCjEjqx0IABJEtc6R8SW0nx7Gd9zSSEHYEFIMoKAAAiFJ0/kJRhnKiDUz39xd1FrJaRx32WucQAAIABJREFUdvr0afvvfwAREHqhpM1SIYT3FhE50IscRFHkgdhCPkGOkh+1yBlnQUgQUjhrpdLOglDCky8UoiyzkZZSamtSpYT3VkvNFZtTk2mtEbCSVGMdZZkpFouevJSKmCdYj8A45IUQQB5RcAU58haIhBQIYLJMRwVEQKzZepWKAXyamDiOLWf0AAGAQEXgOGysVvh6Si1alHN78EWN4/i22257+eWXR0ZGhJLVavV973//mWeeWa6MZFkWKS2E4KJM2zIdQhRFmUk0Yawj4zJnDFkrEG6++WYvZKRiKXWSZLfccstATx95myRZHGsOrDQmYzvSuGlczYPvIQuM1to0Ta+77rpKpYJCZc7uv//+hxx2aFIuj5bOrhEp0lojAasFhUIhs5MqcuAVCjKZc27Lli1XX301s43h4eG/O/nUBQsWlMtlDroXQnTIbZzgBoOJgFWcBx54YP1rG40xBKJUrfzTZZ/Yeee3VUeGBCJnC3Z197IS1iE9rdN0Y/3YjD8SsDQ0tGrVqsFSWRWK1rv58xesWrJksFTuLnYZkyGi8w6l8N5b8hFObt5WookHgDiO77zzzkcefTzLskKxe6RS/fxVVx+4aKHPqgCekx4qlUqxWETvmXyMN5MAAEAPIAB9FBW4AjGRM8ZEsXLO3XzzzVJKXkChULj++uu7u7u99UQUMhz5vlA9NreDz6zlGpz3DlAhAHhwWVdB3XfffS+u3zhULvX3dg9u3Pj5K6+YN3eGUiIzVqoIgVjRrqVbcmF/BOcJAPz2Ew9vIyX/7fbb4Ef/EXtVjLvStHr9jd+MYokAgkBHuuISBAQS1hkp9KSUD2beHmA0mw+EByhGyhjjbQrkrLVfvfY6NJkzRmq10047rVq1ylqrI1mtVotxlC8hIYQQSqVZxtrYtm1aAZFEgRKyNI0KQghhrZdCOAdSimpm4qiWJxJUHiZSmXVKR5k1SqliIUaAYqFIzktUCODZe6kEggIA46ySioCMyWKtnLNSyqRa1VoLqXWkPBC5Wi8ARORY7LhQACIV6SxLdBQZ6wBAK22tB/BKKgKHMDV59kGeDZefv7fWLliw4B/+4R+q1aojnyTJAQsXsslIKZVZI6WUWmXWCEBrrVCTq0ZQS/PxYK113kmp4riAKK655qvzFxzgPXEbr6SSeGsAQCllHXF9PUCpdJwkiVJc1QdhbHoRtiwHBgAAUkouU9Hf3w8APT093/nOd/r6+lAI58h7n6VZiDNWSrEnio0SQgjuG2PcpAt5OedQCKXUnnvu+cMf/jAUGc2Mq1QqHDrJvtZStVosFpn4Thy/g1gKArnFGIFDQUmSvOc977n0so8LIQDRA6SZGx4eKShJAChEsatmo28Xpz/x0SCu9vb23nrrrbrYZQgQhSMaGRnh8lkclRupKDWZlKiUgskySmSFgHUOAACPgoQcHCldcMEFJ59ymjEGUAolSuXEGCOIPAEKRYC1El7EPDIn8NbK57KG0XpBWZZIqdM05WVXKykRrVq1ap999uEWIERUKpWMMVLVqvdLKZ3NON/T1/uGTY5tABTi2GUpEaBQQDQ0NPTe9773nAv+UUhIDPVodKkpl4eiSNeib1F4csbYKIrJW+ecVJG1FkFy9eBtHjV6qGPj/Gcv++Sbj3w7OBAAUsLQSEVKAdYIIZMkEcWIyHnj4qi4HbXv/CjnJp+mBsA7chyX+L3vfa9bq1ij9SAEVCrVSGsgX4wLxqRRFFljahYCRO9tsVhMUyOEpPa+rg6jpm2AhyiOna0i4tDQkMkcSiBwhHL2rJlE4MhJKQEpS9MojomEABguVQuFyLoMUJg0KxYKKCR5AAIEQWQRRWoyraJKkiGa3q6ilso7J4FKg0M90/qHh0u9fZHzIAQ6bySiB2I/mzHOWfDeqQgBwHmnlSQSRKCkMJYA/Z8jBCtvD0FE59z8+fNPOunE4eERHUdCCFuLko4rlQo/GevIGGPJR3HbPIDOw9oMEeM4TpLEO5eldmhoaPPmLYJE4NaRVM45LoedZV4IiKKIndUTkhbHjlAwjk1e1tpKpcKsiB0hAOC959xma21qRtsgBviMa7ZuGgIkgRBExJUShoeH2aglVcRJUr29vexW4cgx/ll7LX6ckRcF2LhfqVScB35/rKTzHmhMXZkgmm3DdM32SSICwCyzmwbXR13dSZYWCl1SCACI47hYiACgVBmJlCb05Nuy+XE32GDFklKWy+VSqZQkidZxNUkYnplzhWIU6yjLMo7FiOM42IsmMF9NGYrjOMtsHMdCiCxL2AtdLpeTpDI8PNzd3W2M6erqiuO4XEmYP2VZJgWGwJ7JVnLlwfxGkFeIoLWoVT2BDZs29/Z0bS0ZBa6gJXjf1dXrPFQqFURUOrbWCCSttbFOS+Vc0/mSAJx0PUoPPsuyNE2HS2VXsbHSqUv6+npMWgVPhWJXhQU6qVzmjDGTbaMEANiUWS7YbSbjSDj2/5XKwyIubN2aoJJSoqqFcdciD6216EkpqbuLSZp6wGqaeAexlNt2sVStWTgK75wQ4v7773/335wyf7+F1bTiwO222x7f/va3JbDS7Z3zUayNMUJEQPie//03V1312QUH7CsEFIsxW4wIwBMggkBhrJE68gCXfPTSRYsW/cPpf4/kJPk1jz326SuvvOHb3zn6mHeu/uU93nuJPtbobSa05jg1pSV4QKkAXBQp46yxXqvYWhAStJYsOyg9NbXG8vd8rC3be28BqK+/l4CyLOvqKgyPDGeZHRgYcJYQcWRkBBHjuGCtnayc6rzRUotIe2Ot9Ygy0hIR+/qmzZwxUwB4D54sOZ8laV9/7/rXNnb39QoCtkoD1kovTFZqC8bl4NHp6+vr6upito2A5UoZUT708AM2M0uXLvWxNsawkivrNawma8kBACJyzmdZNn36dJ6UAw2ch1KplKbpfffdN32g/41vfGO5XIbJV82rdR0gAABPSAQIhIiebKEYcXSvlFJIOTQ8JEABQFd378aNG/v6+rJ6TnWapu1bjLfdV0sOSgJVHCml5s6d6wEJMEkzInrxuefXvfqqt05KecihS7z3IMg5pyZrHKOahwkghNYKT+gJdVTo7u7mmsT9/b2lUkkK0d/f+/ia321Y96dDDjmkUOQI2kRrRbWAcjHabj0vizfQUxJJkkRRwXubZZkQtSr9PT09PT09XBiG8+BeeOGFNKv5Y3fZZZdQZyGUQpjUZgHAGFMsFISDtJIWrPMgokjFEcybMwMBZHfRJgnZKgD8x89+ssuue+6z/wJOWQVyQI6ItBJcT4+t5eHMiEPSJrMYj8KRkzru6+3t6eou9gARZC42abW7WCgNDt11738esezNldSAgv6urrSabLOci3WJIhyQMSaOpBTaOTdr+gwg39/fbQGcdTZJC5EGga+99tr0mQNZkvZ2dW3ZtPmhu+9ZfOibuvr6M592dxXSNJ08FwPgSCryHkkIKYlslmW77LLLHT/99yhSDojtFa9vfN267MH7H1h+7NFbX9t8772/Pfrtx0+b1lMdKVdL1R//4IeHHX7o3LnzLNLQ4Mgv775nl512OuigNygJSshf33uvKnR7REueCF5/7bXH7v9tVzEuDw/39Q3ccNO3lIYNrw1Fwv/qrp8uXXro3F13M9ak5eRnP/uPw950qFJy3o4zh0vDd9111+zZOxy+9H8hgnPgPelIKO6tO6XVdoNVhOpR83feeef5559fKpWkVoVCYWhk+HOf+9zWrVvPPPPMaiU955xz/v7v31cuV9mwNqlTQKpVfKvFz0hR0IXXX9tYTbP/86Uv9/T2qlptA1qx4iKN4uabv3/dN2+69fs/KEba1QsOQj1Bb1Lb9N4Xi0UuW+a9X7t27RVXXGGM0XFUKpV23HHHj330Yx+/7ONZlgnA66+//utf/3reZI/14KLJSuXee6mUtfb++++//PLLS6USAGRZtvTwZe9617suu+yy2bNnv/Ti8729vStXrmTOManRwP7ZwcvneMcddySpYSKSJMkpp516wAEHRDpes2bN8ccfv3r16t13371cLtey5bdJeW8ACHlME/Pqq69edvknkjQtdvdUkmS33fa48B/P/+yVV86YMWOXnXaOomjRGw8UQig1ad4PTcoxAHhP3ntr7e233/6HP/zBWmszAwBnnHHGHnvtefbZ53mEOXPmLDhwYbFYTNOqGgdnQ5air/2TAKDW+reuojkAGBzcsnLlyp6ermDlu/zyy3/84x9veO31rq6u+++//8QTTzzn7LO2bNkSalV1zh5vtVuvlLTWUpbGcQxxZIy56667Xts8lNq0oHVleOjsM8/Ycd7Ms88+e8niQ7/17e/+1fLjTjnt1JHSSF93l8mSmj/Ge9HoQ8Km4Pnx1oIIgJ7ESLnytWu+9tOf/GdWzSKlM1ddseKip1584ZMfv3z58mOvvOrz1/3Ld2bvMKeaZBInPUsO/gQ4Wi9bqYg856jbjRs3rlhxMQs6Hmj27NmXfuTC3z/zzDdvuCHJ0pVf/pJS6oXnnv/HD5/35qOOuubar331m9/sG5hWSRO5rdYaBZ4QEAVYY1B4tlpEkSqXqypWRFipVI4++ug999q9q1D86KWXHHL4mxDkVZ/90mOPPFSQ8ftOPvVv/+6kc84562e/uHPeLru95ci/evtRRz9w731HvvmIf77yk5d9/GN3/fq3Sw5beuO3bvrqNV95+eW1b1126Hvf/e677vz5jrvs+vqGDUcffcyaZ55Zvnz5rIHeJYv2/fB5H/rVAw/09M9805Ijlh993LVfu27j6+t/e/8973jncUuWLLn3tw/utef+/3LTDVkKWqM12VSpGsBxEWNzyrjE6dlnn/3SSy+xJaeaJkKI2TvMmTZt2vv+/u9XfPSjRx31V0uXLl1+3LFdXV0y0i4znSvONw9EBE8oUGudGle1pre3/3OfvaqUVjPj2H7CxuIoUnNmzuKMUBKFKIorlbIQQivduQFZu/1ySd00TefNm/eVr3xlcHCQrzHO2aGvr69SLn/q8k9y9MWxxx67fv36gYGBYncXEbF9VqACRKDJ2Wq11mmS/NVfL58xczbbMQqFQqVSmdbfa036hauviqJoeHj4pJNOYqNZKME2cfqCiATkIVhvwFp7xhlnvPzyy0mS0PRpUqk0TXu6ioVC4U/rNlzztWuPePNbhssVY0yxWKxUKkIINmK0S65sB9J8+BPzqvkL9v/cP3/ekk/SFKVK03TenB2co76+vtNPP/0Niw60xhmXZVlmjIvjgjOTgqdHAET2Y/HggEP8+Mf/ae3atTZLEVFLNMZM6+v50Q9+OGuHOf/0iY8DQFJNrLU9PT3eGmuMFhIA/KhWMU6DPEQ0ppZeY4xTSq1cuXJ4eDjUO2HGsGLFCudBCDjllNOWL18+PDzMldDaVX4cdxARolcqcmQrI6ULL16x5pmXvBBRpL0z1ZH+gYGBhx9+WGu94mOXPPHkM5de/qkPfPC9JaJqtRpHSkn0JosixdE6tZ6k9T1NfBmBW///7X17lF1llefe3+Oc+6hHKpVUKkVIJcir0RmDIQQQBgwDAoOCuHCJA0HSslqaVnAQECRgupEQ/mAtaOThUhsUcRwcUNvpYc3ChgYEAg2JCAQEVBDyIKlU6nXvPed8397zxz7nq5NKKk6xup3V7d1/JDc3Vec732u/928zwrobb9o2POIyAkIbaUfJnN6eK7/0t19bc+1RHz5hYOHgHXfdufaGrzdaqdZq5mJj8s0YIPjlkySxBghgwcL9b//b20YbTWBPRGxgdvesVqtVq1QPOOCAV1/7dWQjo/T3v/v9c89d+enProw6av/9/v/xxUsuaY02ojhyWbKvgachg4iAymdkjCH2ALBp06ajjjoGEYdHh8877/wrr7xyaGjoJz998IBFixcu2u+Kq75yyMF/tuTgJexgYmzsjtu+ceLJxw8eOHj77bfv/74Dly474rzzV64899wV/+nYy7/4l/fe892nfvni7LlzX/31G53dXTetvfGLF//Vly//8on/+4Qb1q6r1WpKWxtDs5Gs++bty5Ycun3bOxs2bHjplTdWrly55mur33nr3WOPO5qINm7c+NfXX3/lVde8suk3hBDFgABKWyaH/6LQ/0IhK8Y5d+aZZwoL0MYwMCI68oKYvWTJEnE+bN68WfqowMyPhXOuEsUuSxyzthaItbKfveACh6A1AIPPMtSq1Rwj744//ri7vnOPGBaCv4+IWZa3P3sPc5SgyODg4EEHHVROBGLmRqMxOjparVY3bdqUpunAwAARhQg5M5PPY88zIpE6S5YsWb58eehKjYgSXImi6Ec/+tGdd955+eWXd3R0jI6OzvDxU+eolHKenXOnnHIKAGhjyHulNRE1Go0sy1avXn37Xd+86KKLZs+ezQU+WIDnmtFYwb0ZLD8Cnr9gv7/4y4ucAAkDKlRJkgFAd3f32rVrfeY+8YlPfOrTZ2dZprRK01TPMJMKAIT9MjKCRUQAJqIzzjgDEbVYEuTSJImq8fpnntqyfXTlBZ+jzK1Z87WFA/OTJEHPNrIQ6hum+vcxnwqUJQoH4BmllFImjs3KlStDQxT5MDIysmvXrmqt45577lm4cOHixYOjIyPhgL2HvANkMEo57xDBKJOl2cmnnHrSqREBELNSaADGR8dOOfmj9/zd3avOPz/xcNVVX51oUa1aB8qyLDMalVI+zcrd5N4zMYA29lPnfBpVBKgwz451CFSvVX/z2uuHL1mGWm3b9i5P3qwZjVA+DEVPIwQgFUWayaVp2j9v/ucuXJV5jrTywB5AA2Zj4/vvv//hhx/+y5d+BQDM/M4775x04n8G7wcHB//PY49BAZCK78lVYwDRZZlWMSAoVK1W6/DDD3/8iSeSJAMNxthms9XR0dHd3Z2maU9PjyS3KKVQQbVaXbx4MQAMDg7+9KF/iDo6169ff80116Cns88+e8eOHb29vT09PcQgZVY7d+58/+kfBeb+/v5Zs2aFIIIxZtasWaC16LabN2/+yPEnNxp+3ry+3t5eRHzggQdWrVo1PDz63770leVHLo80OAcA2XuwNkLkM/j0y16pcJRFaSKisfERrbV3UnCjJChdr9eBqFaRYEae9yXbg0ocBRSYcni+MHpJmZdRuCi7U2iK1sCMzM1Go+m9tZZdRuRAoTXgvQcLwTtcfs+g58rsplxIwXeS9xGM0inOEEk/zR/ofGhNWKlUhoeHL7744ptvvlnqRQTTiTwopZmdpEFzqfiuzDq5qFMLgBOISITA4JOk3L05vLlzbunSpWvWrLn11luPO+44+XVRTsvh8aDOy4HhonMi7g7gkwe6tSXOu8aGxcmybFZPzxVfuWpgYOCRRx7ZsWPHQw89dM6nzjbGhC5y1lrRxbBofBJeda/rHwYNEycicjQ6Mi7SdVLGJnDttddUKpXt27efffbZxx1/bE9PTy5vCpSzcCZDh/bwJYTIcFH+yQgICAwSmgKARrPpnVPAWmtk32g05lb7JkbHzjrrrFM//l9+cO99N95447fuvCNziTEmTZPYWGttI2lNyST0npTK5yJfmqLjb/nWiMSFErIhFOpFkiT333//fffdNzw8IgVeU4aQ9aQSIqTIe5k4FejxOgfwd0op8OyAlLHj4+MEFQ+sFLH37GlWd+czT/2iv7//si9ffss37nzwwQeXLjs8mUiBvJJCVE9KKamcLr0Da53z9PL1lAO213I5RERUjpxrtJiTkCCLyiPz6qu/eu211z325PqxVtI7MKCKB8LeCBHDoGF/5cwLRIqSek+QDFpmBiJGAGOjxGV+bIxANYkJCbVSyNYTau18qjUCKK1trgqzYkIAkKbjWmsmYs6v3pQDvA9S3jljbZIkEhMTyFvnCACssWmaKaVqtZpYo9bGFRu5JK1Wq6Ch0Wq99MomsOaFF1444IAD5s/rP+2UU//+x/f/5MH/edppp73voAO3bn9327ZtBuHFX/0ytlHf/P6nn30GALZu3To2MY6IcWQMgo20MQaci2t159zBBx/8s5/9rFbTTz+9fnh4OEmSjRs3vvrqq6+88sptt902Pt6cmHDaAirF78kXHD6IHS0feBoSRiPJRRJNlehfrVb7/e9/H0V2+/bt8+fPzwEVAMtI9wLiJiFfIhKPkPTBhhIjyAkne3Uws6hy1tpKpRIZy8xyUTs6OgQEMLQrD/ct8C9BcxKgMAAo9/Pw3k9BCsHdSR4rDUd37tx5xRVXfOtb3/rQhz4k/iIZUQ4ZFcDyArQJxc2XhZIfCLxGXixUTu1Jgg4bx/Hg4ODy5ctFUeWicjCICiwwqaAQSMLNpU0pleCbppCowDJxeec0TT9xxpkLFy7cvHlzkiQ7duwIsp8LQOzAuJVSsiayOAGVhIv60OnG1dOQFPr09/d3d3fL8dtrYAOLkvsQCRABL7kMxbjAzExIpdNERIJ+L0pDZ2enT5L99ttvZHRXpGDRosGJ8VFpJpNkLUGzlxQJl+XIKFw43CR6YW04Xb5arU9hI0EvVkpVq1U5vXJK77777mOPPbajo6NSqZRVHLlKgS/L7IJsDv7JkPEflgI5b4bGqCQlxAgSHLIk4/3jo4/M329g/0WLLrnkkmfXP50l3vksqAuI6JgQ0Rd9PphBKaSiXlYujpxVKWkqA87vTogwifxf/jAwMPDtu//ujjvuWLx48THHHN1MhIPDNM/hoBjJCugCFD1v8U3eKMjT/bUWFx8xepBMc5S8a/kAAuuglXiAnXcAsN/C/X/zu98CwNtvv71o0SKJ2wKA1iiHWVAE8f/NEDTK6CzLKtWYi6y4Rx999KSTTmq1WsoqAPXwww9v27ZNgmzDw8O+ldbjyo4dOwCBNF+z5rr7fvS9J558/BdPPlnr7Fp+5HGvvrjpt2+8cdBBB37yrNOv//raFSccv+SI5U889vjHTz/9b/5mzbIl/2HTxg2//c3r8wcWpGk6NLRdAUhzPdC22Uh27tz1pUu+dOaZZ//ZIR+Y1dVdjSsdHR3f++69f/+//sE5WrFixaxZVZcGuIUZOwqx1PUsROT2AaANhAoVa8ISZgYQX3rppatWrVq4cOFRRx6xYKB/bGyMgVCh1ZFcP2EushlB9Q4YjlIuNwmlAFCgoYK4wpQCa+34yGi1GjvnoliPj45cfc3qDRs2fOELX7jyy5ctWLAgv9LkwpUQbiI2jeASctG1QhUNfySHaooTJhwUZm+sSrNWR0fH6R8/r1Kp3HXXXUNDQxdeeOEHP/jBznrH+Pi4YyeIQ0EohmpHOYuhJbUwRCxSQnmfWkyWZeeff/773//+jRs3HnPMMQMDA9IGMbybiGSZQmCyckulNlApVc6F2b2ntM3LzbQSbuWybNmyZUcuP1pr9fijj3z2vHNDQjMAMDlrjHMkD8+yTPYRAMbGxjo7O8P13ndH2PKUy+9z7rnnfuADH3jhhReWLl26ePHi8fFxBcCUl6+WZyeDVioVSXwQgVcohrlPKz858g9WABBZKz9fq9V8lhARg/qvK8/78wsv2rJly6OPPnrddauzzOfaTJoaScAllLkoBUpBq5VWK5HIZrk1WmvnQmlxyEbBQswQFxDiHR0djUbj3Xff/fGPf/zggw/mmhlN3rLAJUV+CNS5PDm4BETzEL2n1WrFcazye6LynYccHNCT1EJTs5Gcf8Gqz3zmnEYr2fTK6yvPP89a7TKltQIGk+PWWJeRNpFzBKAQgQiUEoADDrqR6G1xHAuw0D6OLqNCzts1IiiF/PaWLd/+zt1vb97a2dt71plnTEw0lScVKea9O4Ww6O8iIpxLXde891rpZrNZr1dlQTx5ozQiyqCg8m3QQBmRiNWf//zn37jrm5vf3bpu3bpLL7303JXnfeHiv3pr27Z//KdH77z72y7L4th677mQtUGdLSvW083XiLXiHSEykT/hIx8ZHh5m0gQeNDhHcWTffPNNSXh95eVNxiry8NrrrxLB4089kWXJPz/39L0/uFejAlBvvPryU08+2zt37kEHLfLsLvjzVSedetrQ8K77f/D9ZiuLrP71a68984snjj7ySEJEG23d/DZ52PTSi5FB4PQ7d9/Dxqz/52fW3fD1Qw89dHhoZMWJx0dR9Nxzzz333HPKRh9acoQnMAahgG6O4+o+tnNPEusPi472klQqGbR7305J5YRJtwMzt1qtFStWHHLIIVu2bDnqqKPGxsYkfzyKooxT0U8nJiaC5BAdR5isfBDGJ91bEXMc4HwUAkR0DEqpOIoajZa2Ks0YlL7uujU2rg+Pjsyd3TsxMZHfcGSpI8n71bRakp7ERcs54TutVss512w2hc1N180CIb+x4+PjP/zhD51zMpAUcIyPjyul4kpN2ldEUZT6LEkSycgKR80Y02w2G41GWSvfd5awaMe33HLLCy+8cMYZZwwODo6MjPhS21ExcWQLJGoNJU9OmqbC2cu92ctsWqSmvKE1uQOklSTMaGy8du1aWUAiEuR2JieMTNRewVxiZjEihaMJMHiwWfc6r+ky3G6//faXX375Yx/72GGHHbZ161aRwcIyYHdkEe99WEwAEGUzy7Jms5llGZWA9MtiQwtGjnRfJid665w5cx544IFfPP3U5y74bL1eH941hIgOQYSoOGPF5S0ep0olYgZRETxl3vtWK1VomlkzT9zP+ZX8Kb7QvC+TiBlr7X333RdcoFpNBg7lKimlJIQm6x+4p5iPYhwHyym0HwZQAIQ5GKoHAFSZRjXenKhXa5VK5Sc/+enzz2885zMr5++/aGx0RAOnjoB9KqEXayXlIRg3WZZIcz0oLDm5L865Vqsl7GK6kwsAXBQdIxCCU8C1ev3oYz+8cHDx4PsOHHp3yBrFQM1mNp3mpJSy1jYaja6ursnYmAgJ5xBAKSWFYmnqqtVqlqQAk4BXjBB0aEJMk8Z/XPLBW265hRGaScs5N6ev73uLoh/uAAALJUlEQVTfv3fDr1688PN/AVaP7RqpVaouSaVpMRa9NaUGBf5QrNQ4R8ZEwJBjeHjf0dFFHgg8gwdlJJiTZmlktEImx9oYRMUASgOQOvrYD0vhKXlPno9YerjSRpq/GmPm9vbuP7DfWKNZr1UVQGMiO+b4E1yriaiV1mmrFVcq7L1SBiBKk6Z4P08++eQVK1b80yOPfW3NtZGxSZYeccSRiNhMUuG8MrHpOqTug4QnCusUAVuv1+fOnbvv3wrXuDBNkYgOPOB9hx58SJqmHbW6tbazsxMBefdqBslhF71bRAUzS7fO7u5ua62cItEWHXgA0IJdIwDLjru6OwHBubSjXtfGMKg5c+YggFK5ZwZKfeTlDXt7eyXRUARVmqYy1rx586DwVk0/10nfdC3LtNbSeNKVLHoAQATvOYRRBLk2sHgA6Ovr6+7uDqZGWDTcAzk4j7XmgINw4oknwu7tHGT0oO6FynZf9EmWk9DV1VWgVU83MZB5y200RqImFhG7uzrKvq8pS+Sc6+7uFtkflH3hdJKVsK9B8/1lCGIMCQA80bJlS0Xp6e/v90XrESqwwkI0SP6rt7dX9lpsys7Ozs7OzizLTEkLLr9HWPksy6w2gOjFPLLm1I+e5NJMa91R7wsjQuFwEyO1t7c3aTWAmQi0xiRtzp49W2KQRivnwFjYI/c9z9ANr52fBynnYghgL4F1ykw7OzvFNg1XO2g8cRzPnTuXipJygU2UQadyX/be+56eXmZm9krB8SecoJRhAKhXAIC811reo/D/pK6zq0vcfHEcAwsUXpxlWU9PTxRFMvQfSG1nzwAeNQAoKRKSzqWIHz3llDRjZXV/Xy8yIAgGwbRI0og4e/bs4LHMfQM66uqcReRmzepC1I5Ict72OHN51Q4xIYNC453T1jAzIDrvjNJEdOKJH8kcKaOgqwsIdNdkTDFYzLVaba/vVv7GCC9ToIy1AHkMClFZowF06omIo8ggAEihOCjnSGsEBEcQR9Z5ZxSmaRrZCrBX2rSSNK5ESsWZS6pxBQA6a1ViAlS1ej1NWyaKFSJ5bzQiQByZzDsFOoqrDHzkEUf96sVfrl+/fu0NNyxYMJCmaSWKM++0tpVYAwB5dj6tRDGzfw8wEOF6VCqVzs7OdevWHXbYYfvo1ldesvKxFu1eTIpWq1Wt19I0tdoEf2Ucx6+//vrpp58ebmaWZd3d3c8///zq1asF20Mpg4jIxAheETMbRgBwxNZan3ittWdnIotMJIaIZ4TcZpLgZPACAYBz7q233pISXKnOnTdv3q233vriiy9KUa7MdLrLwOxDPkwRlQFxFDSbTWvjkHFfKCkwMjLS19fnnBN9WSlVr9dvuummBQsWcCmwkS8jyqGf2mNZlB3pDyGRpCkFiSHYgIhbtmw59dRTZb7SvwwAvvrVr4o4KdHkHDnvhZfbqdZaUTARtZwEebhMLQThZfRKpbJhw4brr78+CGYiGh0dvfrqq2UR9mFFoZrsKV0WG5ArsJM90oO4kgcWEeDcU7Fhw4ZzzjknXO/f/e53l1122ZRe2bt1ti/VjWtUYuCaKEfpl+UNzbdl1kmSSBZZrVZ76aWXPv/5z3vvtTYA0N3d/dBDD42ONJIkmxhvdXd3JelEITZUUV/tAIlJy8PFNUqSkhBiWjBpS4WXDHnP4bSEM5Nl2aWXXipRJTGpyWeCesJhJVls7kwp5T0bY5xLiYgZjTGZd1EUZUmKiKKSAurMO61spVJ59tlnP/nJT4okVsjGWiLq6+u7+eabX375ZTE3fQEUvff9BWIAj0aKTDWTZkKgjElp23KsTcRZGlntfCuKIu94r5nNoohs3LjxiiuuAMi7hQNAHMcPP/zweGNsdHwMQMmKM7PGsvghAOKiGDCyttlItNYS6zKRDQ5VpryngLW21WwCgDEq8ASxNsSRsG9lCD07BJ0lpA0iJEop543Rqpm2KnEFAHzBpHIoQ0alDBEpBY5yEFxrLBZWZ5q2KtW6J++9j20E7NM0jeI488TMoJRVmoElBUdOepY6G1W40AcZmJzXGpFVkiRxteIlaVIi4EgGDAC4LNu3w3GvJAp4UCJardbQ0BBMn+QgKabi9+QiQi6GvPjTEdH7TOKxzjlpBB+4KgAMDAyEqKacwpGRkbGxMQmti7GsgAnYKQIkTYCoPSMiGgIiYgTUSnKcyl5v79Iwl9wpj9p7P3v27Hq9jkoRgVbAzNu2bRPeGhTq6cMMFFapiDnnzuUsy0TIUdE6Qo5BlmXz5s2TGi6528z85ptvhqquoDtrrcs41jkzhTy0LhgncRynWf6qQe8WniNqvuBx9ff355imxogHZtu2bXvUr+wmNvKv8gCvbTQacRzL+RT3rqdceoliWy6Gt9b29fUFbq6UGhsbk6B9sH33vpqMhKKHhopuAgAsUviUUoh54Docm7L5KN9Uq9U5c+ZwAXg8Pj6+a9cuKDz75fUMnxFRxLAwcaVMliXWaizsLW2iVqtVqdYBQOA4yWdEBMRdXV2zeroAtPOkNSL6ncM7J8YTZoxstdls2IiLFVYFVlIKSAojEbppmtZqNeec81zUtKK0kCrvSIhh9PT0iGleXr3x8fGhoSFZiiLnUDbScF5lohQrAGBqAZLCChGBYq0RKNc2kqQZR5F49piZGE1kvePUuziO9+ufl9tAeTa/IqLt27cHPZKKZLm97q9CJuay2DBEqNgBEipSWiurvMvSRrUatVotpaPpCmJEfM6dO1eVmqsrVEM7djSTBiNobVPngCiKInIMkAOiIAssACErYFZomNkzSYlM5p3WWmGeDOK9tyaXHGJAywkJSsbs2bNF3Qx7sae1gZ6dcxRpCwguaxprAQwRYJ5ayQqVRMt1XsimHPlQWSraKCIygkLF4BGQmBQqJlFp8+w6pZRgN5LAGpLL/5cZUAOoRjOpVmNp9sfkcgnP7AlEcsomQpH7H9vKHzYh90bBLoNSJ4np2agwhfwXhX+FiFnhSZhMfvWeQ7lTOW8ESgp+2AYx7AAEiA48EgBp0ABAoLzLIm2ZCJSAA+c6OxbZDuQzpTUXnp/JtZIJetY6d5pR0TiIi8yf6deNyqBMYlYXqrouIod5wqL3+akICFeqBDsf2KI8N0/DLTHY4u8i85IIlXJZZmwMpfR/LkVNYI9DzEXZR243T2tFTbpKyg+UNfRSZo+6rOYH9h12E2BSewhLivtMWOTQiAkAgJFzscGlLCzpZlF++ZBvqkrJ4uGdQ7kcEamSFrybk6pgghxcRloDMyJL5QoAFGG1XF0TJYOIFKD3XluVJc7G4hlLjFVMWuA3UIVdk4MnY1N4Zr6vojkhTgJV717QDsWtmeIog0IHDYsQEhQLD/5UEELhJ86BMYoBMpdEJgYA5hye0junJbysrSOvlRbNPU1dHOVJEGIbQZFmidN3jplcc2Rm9AgAOOmkQmRpMqG086TIW6u9S7UxgrK553PEqyzHWHY/P/+C1AteKeUKYFNPXmNp37kEBEOyd3nzYwFIl6Mnd1aUBoW7tZwoH2apE/gDYmP35SgdhX8d4r36tf81R/w3RBJ9x8J1OyP32xTe2qY/Gv3JrHweyciLo//tz3emV2zfj4LwtNI/dvv+3xGv+xduTd6m/1+0p0bQpj8a/akt/p/afNs0hdpio01talOb2jQD+vdgMbWpTW1qU5v+aNQWG21qU5va1KYZUFtstKlNbWpTm2ZAbbHRpja1qU1tmgG1xUab2tSmNrVpBtQWG21qU5va1KYZUFtstKlNbWpTm2ZAbbHRpja1qU1tmgG1xUab2tSmNrVpBvR/AUNewH65k0zlAAAAAElFTkSuQmCC)![image.png](https://postfiles.pstatic.net/MjAyMTA0MDZfNzIg/MDAxNjE3NzIxMDU5NTgw.asUP1M4nO-fR-HSx42C5Z1oo4PEd23kVEcKxH5oYuzEg.XFXVs1dKnpdW0A-WDbKOOfn8O8rKE0JIY9hzmmz8rKIg.PNG.handuelly/image.png?type=w773)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRI3V0tl3yFT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "6291fcd6b963428b87be058e2ab96e34",
            "3a25b6bd30e147cf9416ab4771d6434f",
            "7a8039447b744eaa825a1ec779a773f6",
            "0172d726e1954b11b32856048e892eed",
            "f413c03364f342608ab44da96182e1b2",
            "3a6384e3a2b74f83b4e6c702f84ac4e7",
            "a1db969a4f7b440abe13beaff200fef7",
            "1ebb16dcea2d4143a2f5b100055f3165",
            "7e754c626e56488fb9e6964261ab2d08",
            "68fd56caee394c1084f5f1bf862f661d",
            "e8d0208c3253474ea72aead7fe7975e8",
            "c037718cf1984b19a7e5068d39374f31",
            "88c61a03f1124f6e9954302553191d59",
            "476270df6c6f40428e42056ffcce25d2",
            "e2faa102c69d442ca181535d670ef49c",
            "9fe0f39f66fe4f21b6681031d3c93df8",
            "0a008d67b8534e398323e72b647f9c7a",
            "3954827f8f164c61ae779d7d5b2f0e44",
            "8d236d53430f440095a65e6dbd4cecc1",
            "d7a4c24dd2d646e5b410fc4e9caa0751",
            "fbb615ac51d24fbea82013d80fb37707",
            "6cd76af7fffb485189db1fd701ff24d1",
            "d920a9c97cf149fd825f8685aa01ada6",
            "a94a001e0aa44a9eb00432bb05a818fa",
            "085b8cea9060437a9c8eeabdf15e3b58",
            "ac3e4a6bcb84435997c27f1d05b56f35",
            "90a1b2657dd544af950e962773a47a70",
            "109adf8f80d049609d281a106df9d8a9",
            "40caa59333674b4f884305ea3aa0bb09",
            "2bdca07c66d14ae88cbd19946873454c",
            "293cfdb6faa34201a67a86f9349a76b6",
            "90a9550b9da046fca6387e1e3098844d",
            "e04453f232024a96967590b655fddc9a",
            "2c3ced200d894ade8b0e88f6d6343c7a",
            "32d78cc9c9264a0f82e026b4c6849ca1",
            "62aaa96d281042579ac362ae0e20c82b",
            "4d9cddc745584f74b4b123017c6e3278",
            "64fa48ccabfe40c898b4547302a51067",
            "edbfd7f673db4705bc2453f3ca557d7b",
            "661548674be44fb9ae18e981a2c047b0",
            "2170e836df47411aa8c6d8a24597e009",
            "9b613911814a4607a9d3d9f3ea93226c",
            "e3f8ebb196154a1286f7da7198c1a5cc",
            "7f84adc1c7584234955c4e5abd6c8eac"
          ]
        },
        "outputId": "abc36a90-4753-42d2-d92d-6c3155170d1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6291fcd6b963428b87be058e2ab96e34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c037718cf1984b19a7e5068d39374f31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMultipleChoice: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d920a9c97cf149fd825f8685aa01ada6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c3ced200d894ade8b0e88f6d6343c7a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMultipleChoice, AdamW\n",
        "\n",
        "#Load pre-trained model and tokenizer\n",
        "model = BertForMultipleChoice.from_pretrained('bert-large-cased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vVxtld83yFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4484788-25f3-4fb4-9426-7e1a3d33dc27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlTFcVSe3yFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6474d76-2856-46db-c021-9cbb1c3a2184"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "context = sat_data[\"question\"][0]\n",
        "options = sat_data[\"option\"][0]\n",
        "correct_option = sat_data[\"answer\"][0].strip()\n",
        "\n",
        "# Prepare the inputs\n",
        "choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=128, padding='max_length', truncation=True) for option in options]\n",
        "choices_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I will evaluate test set and check the accuracy."
      ],
      "metadata": {
        "id": "_-jt1Hfb4Mr0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGfM0Nqo3yFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ba1864-4b51-4ed6-8e47-727a8bcc0e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 82 / 31\n",
            "Question 143 / 31\n",
            "Question 32 / 31\n",
            "Question 30 / 31\n",
            "Question 119 / 31\n",
            "Question 61 / 31\n",
            "Question 94 / 31\n",
            "Question 148 / 31\n",
            "Question 154 / 31\n",
            "Question 69 / 31\n",
            "Question 43 / 31\n",
            "Question 139 / 31\n",
            "Question 79 / 31\n",
            "Question 76 / 31\n",
            "Question 16 / 31\n",
            "Question 20 / 31\n",
            "Question 31 / 31\n",
            "Question 91 / 31\n",
            "Question 118 / 31\n",
            "Question 138 / 31\n",
            "Question 19 / 31\n",
            "Question 13 / 31\n",
            "Question 10 / 31\n",
            "Question 25 / 31\n",
            "Question 70 / 31\n",
            "Question 132 / 31\n",
            "Question 96 / 31\n",
            "Question 46 / 31\n",
            "Question 87 / 31\n",
            "Question 85 / 31\n",
            "Question 127 / 31\n"
          ]
        }
      ],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Evaluation loop\n",
        "num_correct = 0\n",
        "for idx, row in test_data.iterrows():\n",
        "    context = row[\"question\"]\n",
        "    options = row[\"option\"].split(',')  # Assumes options are comma-separated in the CSV\n",
        "    options = [option.strip() for option in options]\n",
        "    correct_option = row[\"answer\"].strip()\n",
        "\n",
        "    # Prepare the inputs\n",
        "    choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=256, padding='max_length', truncation=True) for option in options]\n",
        "\n",
        "    # Get the input tensors and reshape them\n",
        "    input_ids = torch.cat([choice['input_ids'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    attention_mask = torch.cat([choice['attention_mask'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    # Compute the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "\n",
        "    # Get the predicted option\n",
        "    predicted_option = torch.argmax(outputs.logits).item()\n",
        "\n",
        "    # Check if the prediction is correct\n",
        "    if predicted_option == options.index(correct_option):\n",
        "        num_correct += 1\n",
        "    print(f\"Question {idx + 1} / {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehN8fg3y3yFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a00850-0ac5-4a7f-bbf5-d60a5d65e191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0967741935483871\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy: {num_correct / len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hb4PT983yFV"
      },
      "source": [
        "Training for the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XZ3PHvz3yFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbce05b0-6179-4f02-d582-ca5263901053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Question 97 / 124 for epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Question 123 / 124 for epoch 0\n",
            "Training Question 83 / 124 for epoch 0\n",
            "Training Question 110 / 124 for epoch 0\n",
            "Training Question 66 / 124 for epoch 0\n",
            "Training Question 52 / 124 for epoch 0\n",
            "Training Question 27 / 124 for epoch 0\n",
            "Training Question 134 / 124 for epoch 0\n",
            "Training Question 77 / 124 for epoch 0\n",
            "Training Question 57 / 124 for epoch 0\n",
            "Training Question 37 / 124 for epoch 0\n",
            "Training Question 125 / 124 for epoch 0\n",
            "Training Question 23 / 124 for epoch 0\n",
            "Training Question 56 / 124 for epoch 0\n",
            "Training Question 86 / 124 for epoch 0\n",
            "Training Question 12 / 124 for epoch 0\n",
            "Training Question 142 / 124 for epoch 0\n",
            "Training Question 67 / 124 for epoch 0\n",
            "Training Question 120 / 124 for epoch 0\n",
            "Training Question 28 / 124 for epoch 0\n",
            "Training Question 80 / 124 for epoch 0\n",
            "Training Question 145 / 124 for epoch 0\n",
            "Training Question 42 / 124 for epoch 0\n",
            "Training Question 5 / 124 for epoch 0\n",
            "Training Question 33 / 124 for epoch 0\n",
            "Training Question 135 / 124 for epoch 0\n",
            "Training Question 144 / 124 for epoch 0\n",
            "Training Question 68 / 124 for epoch 0\n",
            "Training Question 17 / 124 for epoch 0\n",
            "Training Question 124 / 124 for epoch 0\n",
            "Training Question 11 / 124 for epoch 0\n",
            "Training Question 114 / 124 for epoch 0\n",
            "Training Question 147 / 124 for epoch 0\n",
            "Training Question 102 / 124 for epoch 0\n",
            "Training Question 1 / 124 for epoch 0\n",
            "Training Question 111 / 124 for epoch 0\n",
            "Training Question 65 / 124 for epoch 0\n",
            "Training Question 45 / 124 for epoch 0\n",
            "Training Question 98 / 124 for epoch 0\n",
            "Training Question 29 / 124 for epoch 0\n",
            "Training Question 41 / 124 for epoch 0\n",
            "Training Question 105 / 124 for epoch 0\n",
            "Training Question 26 / 124 for epoch 0\n",
            "Training Question 24 / 124 for epoch 0\n",
            "Training Question 109 / 124 for epoch 0\n",
            "Training Question 40 / 124 for epoch 0\n",
            "Training Question 152 / 124 for epoch 0\n",
            "Training Question 99 / 124 for epoch 0\n",
            "Training Question 151 / 124 for epoch 0\n",
            "Training Question 137 / 124 for epoch 0\n",
            "Training Question 48 / 124 for epoch 0\n",
            "Training Question 112 / 124 for epoch 0\n",
            "Training Question 62 / 124 for epoch 0\n",
            "Training Question 74 / 124 for epoch 0\n",
            "Training Question 34 / 124 for epoch 0\n",
            "Training Question 149 / 124 for epoch 0\n",
            "Training Question 126 / 124 for epoch 0\n",
            "Training Question 63 / 124 for epoch 0\n",
            "Training Question 106 / 124 for epoch 0\n",
            "Training Question 95 / 124 for epoch 0\n",
            "Training Question 54 / 124 for epoch 0\n",
            "Training Question 6 / 124 for epoch 0\n",
            "Training Question 128 / 124 for epoch 0\n",
            "Training Question 115 / 124 for epoch 0\n",
            "Training Question 50 / 124 for epoch 0\n",
            "Training Question 36 / 124 for epoch 0\n",
            "Training Question 81 / 124 for epoch 0\n",
            "Training Question 78 / 124 for epoch 0\n",
            "Training Question 35 / 124 for epoch 0\n",
            "Training Question 47 / 124 for epoch 0\n",
            "Training Question 8 / 124 for epoch 0\n",
            "Training Question 44 / 124 for epoch 0\n",
            "Training Question 71 / 124 for epoch 0\n",
            "Training Question 113 / 124 for epoch 0\n",
            "Training Question 92 / 124 for epoch 0\n",
            "Training Question 84 / 124 for epoch 0\n",
            "Training Question 140 / 124 for epoch 0\n",
            "Training Question 141 / 124 for epoch 0\n",
            "Training Question 90 / 124 for epoch 0\n",
            "Training Question 9 / 124 for epoch 0\n",
            "Training Question 14 / 124 for epoch 0\n",
            "Training Question 60 / 124 for epoch 0\n",
            "Training Question 133 / 124 for epoch 0\n",
            "Training Question 4 / 124 for epoch 0\n",
            "Training Question 18 / 124 for epoch 0\n",
            "Training Question 39 / 124 for epoch 0\n",
            "Training Question 73 / 124 for epoch 0\n",
            "Training Question 136 / 124 for epoch 0\n",
            "Training Question 7 / 124 for epoch 0\n",
            "Training Question 129 / 124 for epoch 0\n",
            "Training Question 101 / 124 for epoch 0\n",
            "Training Question 3 / 124 for epoch 0\n",
            "Training Question 121 / 124 for epoch 0\n",
            "Training Question 64 / 124 for epoch 0\n",
            "Training Question 116 / 124 for epoch 0\n",
            "Training Question 55 / 124 for epoch 0\n",
            "Training Question 108 / 124 for epoch 0\n",
            "Training Question 51 / 124 for epoch 0\n",
            "Training Question 153 / 124 for epoch 0\n",
            "Training Question 59 / 124 for epoch 0\n",
            "Training Question 49 / 124 for epoch 0\n",
            "Training Question 89 / 124 for epoch 0\n",
            "Training Question 22 / 124 for epoch 0\n",
            "Training Question 58 / 124 for epoch 0\n",
            "Training Question 150 / 124 for epoch 0\n",
            "Training Question 130 / 124 for epoch 0\n",
            "Training Question 38 / 124 for epoch 0\n",
            "Training Question 146 / 124 for epoch 0\n",
            "Training Question 2 / 124 for epoch 0\n",
            "Training Question 53 / 124 for epoch 0\n",
            "Training Question 131 / 124 for epoch 0\n",
            "Training Question 104 / 124 for epoch 0\n",
            "Training Question 100 / 124 for epoch 0\n",
            "Training Question 117 / 124 for epoch 0\n",
            "Training Question 88 / 124 for epoch 0\n",
            "Training Question 75 / 124 for epoch 0\n",
            "Training Question 122 / 124 for epoch 0\n",
            "Training Question 155 / 124 for epoch 0\n",
            "Training Question 21 / 124 for epoch 0\n",
            "Training Question 72 / 124 for epoch 0\n",
            "Training Question 107 / 124 for epoch 0\n",
            "Training Question 15 / 124 for epoch 0\n",
            "Training Question 93 / 124 for epoch 0\n",
            "Training Question 103 / 124 for epoch 0\n",
            "Training Question 97 / 124 for epoch 1\n",
            "Training Question 123 / 124 for epoch 1\n",
            "Training Question 83 / 124 for epoch 1\n",
            "Training Question 110 / 124 for epoch 1\n",
            "Training Question 66 / 124 for epoch 1\n",
            "Training Question 52 / 124 for epoch 1\n",
            "Training Question 27 / 124 for epoch 1\n",
            "Training Question 134 / 124 for epoch 1\n",
            "Training Question 77 / 124 for epoch 1\n",
            "Training Question 57 / 124 for epoch 1\n",
            "Training Question 37 / 124 for epoch 1\n",
            "Training Question 125 / 124 for epoch 1\n",
            "Training Question 23 / 124 for epoch 1\n",
            "Training Question 56 / 124 for epoch 1\n",
            "Training Question 86 / 124 for epoch 1\n",
            "Training Question 12 / 124 for epoch 1\n",
            "Training Question 142 / 124 for epoch 1\n",
            "Training Question 67 / 124 for epoch 1\n",
            "Training Question 120 / 124 for epoch 1\n",
            "Training Question 28 / 124 for epoch 1\n",
            "Training Question 80 / 124 for epoch 1\n",
            "Training Question 145 / 124 for epoch 1\n",
            "Training Question 42 / 124 for epoch 1\n",
            "Training Question 5 / 124 for epoch 1\n",
            "Training Question 33 / 124 for epoch 1\n",
            "Training Question 135 / 124 for epoch 1\n",
            "Training Question 144 / 124 for epoch 1\n",
            "Training Question 68 / 124 for epoch 1\n",
            "Training Question 17 / 124 for epoch 1\n",
            "Training Question 124 / 124 for epoch 1\n",
            "Training Question 11 / 124 for epoch 1\n",
            "Training Question 114 / 124 for epoch 1\n",
            "Training Question 147 / 124 for epoch 1\n",
            "Training Question 102 / 124 for epoch 1\n",
            "Training Question 1 / 124 for epoch 1\n",
            "Training Question 111 / 124 for epoch 1\n",
            "Training Question 65 / 124 for epoch 1\n",
            "Training Question 45 / 124 for epoch 1\n",
            "Training Question 98 / 124 for epoch 1\n",
            "Training Question 29 / 124 for epoch 1\n",
            "Training Question 41 / 124 for epoch 1\n",
            "Training Question 105 / 124 for epoch 1\n",
            "Training Question 26 / 124 for epoch 1\n",
            "Training Question 24 / 124 for epoch 1\n",
            "Training Question 109 / 124 for epoch 1\n",
            "Training Question 40 / 124 for epoch 1\n",
            "Training Question 152 / 124 for epoch 1\n",
            "Training Question 99 / 124 for epoch 1\n",
            "Training Question 151 / 124 for epoch 1\n",
            "Training Question 137 / 124 for epoch 1\n",
            "Training Question 48 / 124 for epoch 1\n",
            "Training Question 112 / 124 for epoch 1\n",
            "Training Question 62 / 124 for epoch 1\n",
            "Training Question 74 / 124 for epoch 1\n",
            "Training Question 34 / 124 for epoch 1\n",
            "Training Question 149 / 124 for epoch 1\n",
            "Training Question 126 / 124 for epoch 1\n",
            "Training Question 63 / 124 for epoch 1\n",
            "Training Question 106 / 124 for epoch 1\n",
            "Training Question 95 / 124 for epoch 1\n",
            "Training Question 54 / 124 for epoch 1\n",
            "Training Question 6 / 124 for epoch 1\n",
            "Training Question 128 / 124 for epoch 1\n",
            "Training Question 115 / 124 for epoch 1\n",
            "Training Question 50 / 124 for epoch 1\n",
            "Training Question 36 / 124 for epoch 1\n",
            "Training Question 81 / 124 for epoch 1\n",
            "Training Question 78 / 124 for epoch 1\n",
            "Training Question 35 / 124 for epoch 1\n",
            "Training Question 47 / 124 for epoch 1\n",
            "Training Question 8 / 124 for epoch 1\n",
            "Training Question 44 / 124 for epoch 1\n",
            "Training Question 71 / 124 for epoch 1\n",
            "Training Question 113 / 124 for epoch 1\n",
            "Training Question 92 / 124 for epoch 1\n",
            "Training Question 84 / 124 for epoch 1\n",
            "Training Question 140 / 124 for epoch 1\n",
            "Training Question 141 / 124 for epoch 1\n",
            "Training Question 90 / 124 for epoch 1\n",
            "Training Question 9 / 124 for epoch 1\n",
            "Training Question 14 / 124 for epoch 1\n",
            "Training Question 60 / 124 for epoch 1\n",
            "Training Question 133 / 124 for epoch 1\n",
            "Training Question 4 / 124 for epoch 1\n",
            "Training Question 18 / 124 for epoch 1\n",
            "Training Question 39 / 124 for epoch 1\n",
            "Training Question 73 / 124 for epoch 1\n",
            "Training Question 136 / 124 for epoch 1\n",
            "Training Question 7 / 124 for epoch 1\n",
            "Training Question 129 / 124 for epoch 1\n",
            "Training Question 101 / 124 for epoch 1\n",
            "Training Question 3 / 124 for epoch 1\n",
            "Training Question 121 / 124 for epoch 1\n",
            "Training Question 64 / 124 for epoch 1\n",
            "Training Question 116 / 124 for epoch 1\n",
            "Training Question 55 / 124 for epoch 1\n",
            "Training Question 108 / 124 for epoch 1\n",
            "Training Question 51 / 124 for epoch 1\n",
            "Training Question 153 / 124 for epoch 1\n",
            "Training Question 59 / 124 for epoch 1\n",
            "Training Question 49 / 124 for epoch 1\n",
            "Training Question 89 / 124 for epoch 1\n",
            "Training Question 22 / 124 for epoch 1\n",
            "Training Question 58 / 124 for epoch 1\n",
            "Training Question 150 / 124 for epoch 1\n",
            "Training Question 130 / 124 for epoch 1\n",
            "Training Question 38 / 124 for epoch 1\n",
            "Training Question 146 / 124 for epoch 1\n",
            "Training Question 2 / 124 for epoch 1\n",
            "Training Question 53 / 124 for epoch 1\n",
            "Training Question 131 / 124 for epoch 1\n",
            "Training Question 104 / 124 for epoch 1\n",
            "Training Question 100 / 124 for epoch 1\n",
            "Training Question 117 / 124 for epoch 1\n",
            "Training Question 88 / 124 for epoch 1\n",
            "Training Question 75 / 124 for epoch 1\n",
            "Training Question 122 / 124 for epoch 1\n",
            "Training Question 155 / 124 for epoch 1\n",
            "Training Question 21 / 124 for epoch 1\n",
            "Training Question 72 / 124 for epoch 1\n",
            "Training Question 107 / 124 for epoch 1\n",
            "Training Question 15 / 124 for epoch 1\n",
            "Training Question 93 / 124 for epoch 1\n",
            "Training Question 103 / 124 for epoch 1\n",
            "Training Question 97 / 124 for epoch 2\n",
            "Training Question 123 / 124 for epoch 2\n",
            "Training Question 83 / 124 for epoch 2\n",
            "Training Question 110 / 124 for epoch 2\n",
            "Training Question 66 / 124 for epoch 2\n",
            "Training Question 52 / 124 for epoch 2\n",
            "Training Question 27 / 124 for epoch 2\n",
            "Training Question 134 / 124 for epoch 2\n",
            "Training Question 77 / 124 for epoch 2\n",
            "Training Question 57 / 124 for epoch 2\n",
            "Training Question 37 / 124 for epoch 2\n",
            "Training Question 125 / 124 for epoch 2\n",
            "Training Question 23 / 124 for epoch 2\n",
            "Training Question 56 / 124 for epoch 2\n",
            "Training Question 86 / 124 for epoch 2\n",
            "Training Question 12 / 124 for epoch 2\n",
            "Training Question 142 / 124 for epoch 2\n",
            "Training Question 67 / 124 for epoch 2\n",
            "Training Question 120 / 124 for epoch 2\n",
            "Training Question 28 / 124 for epoch 2\n",
            "Training Question 80 / 124 for epoch 2\n",
            "Training Question 145 / 124 for epoch 2\n",
            "Training Question 42 / 124 for epoch 2\n",
            "Training Question 5 / 124 for epoch 2\n",
            "Training Question 33 / 124 for epoch 2\n",
            "Training Question 135 / 124 for epoch 2\n",
            "Training Question 144 / 124 for epoch 2\n",
            "Training Question 68 / 124 for epoch 2\n",
            "Training Question 17 / 124 for epoch 2\n",
            "Training Question 124 / 124 for epoch 2\n",
            "Training Question 11 / 124 for epoch 2\n",
            "Training Question 114 / 124 for epoch 2\n",
            "Training Question 147 / 124 for epoch 2\n",
            "Training Question 102 / 124 for epoch 2\n",
            "Training Question 1 / 124 for epoch 2\n",
            "Training Question 111 / 124 for epoch 2\n",
            "Training Question 65 / 124 for epoch 2\n",
            "Training Question 45 / 124 for epoch 2\n",
            "Training Question 98 / 124 for epoch 2\n",
            "Training Question 29 / 124 for epoch 2\n",
            "Training Question 41 / 124 for epoch 2\n",
            "Training Question 105 / 124 for epoch 2\n",
            "Training Question 26 / 124 for epoch 2\n",
            "Training Question 24 / 124 for epoch 2\n",
            "Training Question 109 / 124 for epoch 2\n",
            "Training Question 40 / 124 for epoch 2\n",
            "Training Question 152 / 124 for epoch 2\n",
            "Training Question 99 / 124 for epoch 2\n",
            "Training Question 151 / 124 for epoch 2\n",
            "Training Question 137 / 124 for epoch 2\n",
            "Training Question 48 / 124 for epoch 2\n",
            "Training Question 112 / 124 for epoch 2\n",
            "Training Question 62 / 124 for epoch 2\n",
            "Training Question 74 / 124 for epoch 2\n",
            "Training Question 34 / 124 for epoch 2\n",
            "Training Question 149 / 124 for epoch 2\n",
            "Training Question 126 / 124 for epoch 2\n",
            "Training Question 63 / 124 for epoch 2\n",
            "Training Question 106 / 124 for epoch 2\n",
            "Training Question 95 / 124 for epoch 2\n",
            "Training Question 54 / 124 for epoch 2\n",
            "Training Question 6 / 124 for epoch 2\n",
            "Training Question 128 / 124 for epoch 2\n",
            "Training Question 115 / 124 for epoch 2\n",
            "Training Question 50 / 124 for epoch 2\n",
            "Training Question 36 / 124 for epoch 2\n",
            "Training Question 81 / 124 for epoch 2\n",
            "Training Question 78 / 124 for epoch 2\n",
            "Training Question 35 / 124 for epoch 2\n",
            "Training Question 47 / 124 for epoch 2\n",
            "Training Question 8 / 124 for epoch 2\n",
            "Training Question 44 / 124 for epoch 2\n",
            "Training Question 71 / 124 for epoch 2\n",
            "Training Question 113 / 124 for epoch 2\n",
            "Training Question 92 / 124 for epoch 2\n",
            "Training Question 84 / 124 for epoch 2\n",
            "Training Question 140 / 124 for epoch 2\n",
            "Training Question 141 / 124 for epoch 2\n",
            "Training Question 90 / 124 for epoch 2\n",
            "Training Question 9 / 124 for epoch 2\n",
            "Training Question 14 / 124 for epoch 2\n",
            "Training Question 60 / 124 for epoch 2\n",
            "Training Question 133 / 124 for epoch 2\n",
            "Training Question 4 / 124 for epoch 2\n",
            "Training Question 18 / 124 for epoch 2\n",
            "Training Question 39 / 124 for epoch 2\n",
            "Training Question 73 / 124 for epoch 2\n",
            "Training Question 136 / 124 for epoch 2\n",
            "Training Question 7 / 124 for epoch 2\n",
            "Training Question 129 / 124 for epoch 2\n",
            "Training Question 101 / 124 for epoch 2\n",
            "Training Question 3 / 124 for epoch 2\n",
            "Training Question 121 / 124 for epoch 2\n",
            "Training Question 64 / 124 for epoch 2\n",
            "Training Question 116 / 124 for epoch 2\n",
            "Training Question 55 / 124 for epoch 2\n",
            "Training Question 108 / 124 for epoch 2\n",
            "Training Question 51 / 124 for epoch 2\n",
            "Training Question 153 / 124 for epoch 2\n",
            "Training Question 59 / 124 for epoch 2\n",
            "Training Question 49 / 124 for epoch 2\n",
            "Training Question 89 / 124 for epoch 2\n",
            "Training Question 22 / 124 for epoch 2\n",
            "Training Question 58 / 124 for epoch 2\n",
            "Training Question 150 / 124 for epoch 2\n",
            "Training Question 130 / 124 for epoch 2\n",
            "Training Question 38 / 124 for epoch 2\n",
            "Training Question 146 / 124 for epoch 2\n",
            "Training Question 2 / 124 for epoch 2\n",
            "Training Question 53 / 124 for epoch 2\n",
            "Training Question 131 / 124 for epoch 2\n",
            "Training Question 104 / 124 for epoch 2\n",
            "Training Question 100 / 124 for epoch 2\n",
            "Training Question 117 / 124 for epoch 2\n",
            "Training Question 88 / 124 for epoch 2\n",
            "Training Question 75 / 124 for epoch 2\n",
            "Training Question 122 / 124 for epoch 2\n",
            "Training Question 155 / 124 for epoch 2\n",
            "Training Question 21 / 124 for epoch 2\n",
            "Training Question 72 / 124 for epoch 2\n",
            "Training Question 107 / 124 for epoch 2\n",
            "Training Question 15 / 124 for epoch 2\n",
            "Training Question 93 / 124 for epoch 2\n",
            "Training Question 103 / 124 for epoch 2\n"
          ]
        }
      ],
      "source": [
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Set the model to training mode\n",
        "model.train()\n",
        "\n",
        "num_epochs = 3\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "  for idx, row in train_data.iterrows():\n",
        "      print(f\"Training Question {idx + 1} / {len(train_data)} for epoch {epoch}\")\n",
        "      context = row[\"question\"]\n",
        "      options = row[\"option\"].split(',')  # Assumes options are comma-separated in the CSV\n",
        "      options = [option.strip() for option in options]\n",
        "      #print(row['answer'])\n",
        "      correct_option = row[\"answer\"].strip()\n",
        "\n",
        "      # Prepare the inputs\n",
        "      choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=256, padding='max_length', truncation=True) for option in options]\n",
        "\n",
        "      # Get the input tensors and reshape them\n",
        "      input_ids = torch.cat([choice['input_ids'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "      attention_mask = torch.cat([choice['attention_mask'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "      input_ids = input_ids.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "\n",
        "      # Compute the model outputs\n",
        "      correct_option_idx = options.index(correct_option)\n",
        "      correct_option_idx = torch.tensor([correct_option_idx]).to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=correct_option_idx)\n",
        "      # Compute the loss\n",
        "      loss = outputs.loss\n",
        "\n",
        "      # Backward pass and optimization\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfTmdkj73yFV"
      },
      "source": [
        "Now check the accuracy for the test set after training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l970oLq_3yFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0738b6a2-3701-4740-8131-5c85027cbf1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 82 / 31\n",
            "Question 143 / 31\n",
            "Question 32 / 31\n",
            "Question 30 / 31\n",
            "Question 119 / 31\n",
            "Question 61 / 31\n",
            "Question 94 / 31\n",
            "Question 148 / 31\n",
            "Question 154 / 31\n",
            "Question 69 / 31\n",
            "Question 43 / 31\n",
            "Question 139 / 31\n",
            "Question 79 / 31\n",
            "Question 76 / 31\n",
            "Question 16 / 31\n",
            "Question 20 / 31\n",
            "Question 31 / 31\n",
            "Question 91 / 31\n",
            "Question 118 / 31\n",
            "Question 138 / 31\n",
            "Question 19 / 31\n",
            "Question 13 / 31\n",
            "Question 10 / 31\n",
            "Question 25 / 31\n",
            "Question 70 / 31\n",
            "Question 132 / 31\n",
            "Question 96 / 31\n",
            "Question 46 / 31\n",
            "Question 87 / 31\n",
            "Question 85 / 31\n",
            "Question 127 / 31\n"
          ]
        }
      ],
      "source": [
        "# Evaluation loop\n",
        "num_correct = 0\n",
        "for idx, row in test_data.iterrows():\n",
        "    context = row[\"question\"]\n",
        "    options = row[\"option\"].split(',')  # Assumes options are comma-separated in the CSV\n",
        "    options = [option.strip() for option in options]\n",
        "    correct_option = row[\"answer\"].strip()\n",
        "\n",
        "    # Prepare the inputs\n",
        "    choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=256, padding='max_length', truncation=True) for option in options]\n",
        "\n",
        "    # Get the input tensors and reshape them\n",
        "    input_ids = torch.cat([choice['input_ids'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    attention_mask = torch.cat([choice['attention_mask'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    # Compute the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Get the predicted option\n",
        "    predicted_option = torch.argmax(outputs.logits).item()\n",
        "\n",
        "    # Check if the prediction is correct\n",
        "    if predicted_option == options.index(correct_option):\n",
        "        num_correct += 1\n",
        "    print(f\"Question {idx + 1} / {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiCpreMZ3yFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74b9c69-7db1-41ff-eff8-87a53c86909d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2903225806451613\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy: {num_correct / len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be observed that the accuracy has improved compared to before training, but it is still significantly low."
      ],
      "metadata": {
        "id": "DNaSW_814U-C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbNsDhqfMTN4"
      },
      "source": [
        "# TOEIC Dataset\n",
        "\n",
        "There are many reasons for the observed results, but one of them could be that the problems are complex while the dataset size is very small. Therefore, this time we will train the model using the simpler fill-in-the-blank inference problems from the TOEIC dataset and then use this trained model to solve the 수능 (Korean national college entrance exam) problems.\n",
        "\n",
        "The Blank in the question is represented with \"___\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISiNEgJ8MS7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e868712a-9bdc-477f-cbb1-af2f912e2157"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('109',\n",
              "  {'1': 'will be published',\n",
              "   '2': 'will publish',\n",
              "   '3': 'are publishing',\n",
              "   '4': 'publishes',\n",
              "   'anwser': 'will be published',\n",
              "   'question': 'The new novel by Steven Kim ___ no later than the 18th of November according to a reliable source.'}),\n",
              " ('110',\n",
              "  {'1': 'exactly',\n",
              "   '2': 'jointly',\n",
              "   '3': 'hardly',\n",
              "   '4': 'consistently',\n",
              "   'anwser': 'consistently',\n",
              "   'question': 'As we have had workers who quit after working for a short period of time, we need someone who can work ___ for at least a year.'}),\n",
              " ('111',\n",
              "  {'1': 'attraction',\n",
              "   '2': 'attractive',\n",
              "   '3': 'attracted',\n",
              "   '4': 'attractively',\n",
              "   'anwser': 'attractive',\n",
              "   'question': 'While Jason found the proposal from the other company ___ , he ultimately turned it down to keep the relationship with his original partner company.'})]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "with open('./CS376/train.json', 'r') as f:\n",
        "    toeic_data = json.load(f)\n",
        "\n",
        "items_to_print = list(toeic_data.items())[:3]\n",
        "items_to_print\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9Afgu3OPCvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f33df81-1ccd-413b-86ba-dfedb75039c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': 'The new novel by Steven Kim ___ no later than the 18th of November according to a reliable source.',\n",
              "  'option': ['will be published',\n",
              "   'will publish',\n",
              "   'are publishing',\n",
              "   'publishes'],\n",
              "  'answer': 'will be published'},\n",
              " {'question': 'As we have had workers who quit after working for a short period of time, we need someone who can work ___ for at least a year.',\n",
              "  'option': ['exactly', 'jointly', 'hardly', 'consistently'],\n",
              "  'answer': 'consistently'},\n",
              " {'question': 'While Jason found the proposal from the other company ___ , he ultimately turned it down to keep the relationship with his original partner company.',\n",
              "  'option': ['attraction', 'attractive', 'attracted', 'attractively'],\n",
              "  'answer': 'attractive'},\n",
              " {'question': 'Maverick Manufacturers has maintained the highest safety ___ of any company in its industry.',\n",
              "  'option': ['standards', 'guides', 'documents', 'precautions'],\n",
              "  'answer': 'standards'},\n",
              " {'question': \"Peter had to work during my vacation because the matter was so ___ - that it couldn't wait for my return.\",\n",
              "  'option': ['urgent', 'urgency', 'urgently', 'urgencies'],\n",
              "  'answer': 'urgent'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data_list = [{'question': v['question'], 'option': [v[str(i)] for i in range(1, 5)], 'answer': v['anwser']} for v in toeic_data.values()]\n",
        "data_list[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53li-U5bTHV3"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, I will use bart-large-cased model."
      ],
      "metadata": {
        "id": "tY0UHFnK5yHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjFOs6olSe4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc41115-c868-435e-89a8-e7ea17abf7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMultipleChoice: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained model and tokenizer\n",
        "model = BertForMultipleChoice.from_pretrained('bert-large-cased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXh0IxaBfCc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed12d3d-e7ee-4de8-f719-da21867e532e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input_ids': tensor([[  101,  1109,  1207,  2281,  1118,  6536,  4246,  1209,  1129,  1502,\n",
              "           1185,  1224,  1190,  1103,  4186,  1104,  1379,  2452,  1106,   170,\n",
              "          10682,  2674,   119,   102,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]])},\n",
              " {'input_ids': tensor([[  101,  1109,  1207,  2281,  1118,  6536,  4246,  1209, 10086,  1185,\n",
              "           1224,  1190,  1103,  4186,  1104,  1379,  2452,  1106,   170, 10682,\n",
              "           2674,   119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]])},\n",
              " {'input_ids': tensor([[  101,  1109,  1207,  2281,  1118,  6536,  4246,  1132,  5550,  1185,\n",
              "           1224,  1190,  1103,  4186,  1104,  1379,  2452,  1106,   170, 10682,\n",
              "           2674,   119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]])},\n",
              " {'input_ids': tensor([[  101,  1109,  1207,  2281,  1118,  6536,  4246, 12701,  1185,  1224,\n",
              "           1190,  1103,  4186,  1104,  1379,  2452,  1106,   170, 10682,  2674,\n",
              "            119,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]])}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "context = data_list[0][\"question\"]\n",
        "options = data_list[0][\"option\"]\n",
        "correct_option = data_list[0][\"answer\"].strip()\n",
        "\n",
        "# Prepare the inputs\n",
        "choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=128, padding='max_length', truncation=True) for option in options]\n",
        "choices_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw4Np-ZiWBaV"
      },
      "source": [
        "First, we will input the test dataset into the model without fine-tuning and check the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVCGDooRdlaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792e5d1c-1134-480f-9980-837b1dec9ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data :  2813  test_data :  704\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)\n",
        "print('train_data : ', len(train_data), ' test_data : ', len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_nlaG_rhkXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23749805-050a-4615-b830-4a7e78c6114f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFuNcFj6WS5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5738737-6585-4b76-f74f-3722fdabbb2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1 / 704\n",
            "Question 2 / 704\n",
            "Question 3 / 704\n",
            "Question 4 / 704\n",
            "Question 5 / 704\n",
            "Question 6 / 704\n",
            "Question 7 / 704\n",
            "Question 8 / 704\n",
            "Question 9 / 704\n",
            "Question 10 / 704\n",
            "Question 11 / 704\n",
            "Question 12 / 704\n",
            "Question 13 / 704\n",
            "Question 14 / 704\n",
            "Question 15 / 704\n",
            "Question 16 / 704\n",
            "Question 17 / 704\n",
            "Question 18 / 704\n",
            "Question 19 / 704\n",
            "Question 20 / 704\n",
            "Question 21 / 704\n",
            "Question 22 / 704\n",
            "Question 23 / 704\n",
            "Question 24 / 704\n",
            "Question 25 / 704\n",
            "Question 26 / 704\n",
            "Question 27 / 704\n",
            "Question 28 / 704\n",
            "Question 29 / 704\n",
            "Question 30 / 704\n",
            "Question 31 / 704\n",
            "Question 32 / 704\n",
            "Question 33 / 704\n",
            "Question 34 / 704\n",
            "Question 35 / 704\n",
            "Question 36 / 704\n",
            "Question 37 / 704\n",
            "Question 38 / 704\n",
            "Question 39 / 704\n",
            "Question 40 / 704\n",
            "Question 41 / 704\n",
            "Question 42 / 704\n",
            "Question 43 / 704\n",
            "Question 44 / 704\n",
            "Question 45 / 704\n",
            "Question 46 / 704\n",
            "Question 47 / 704\n",
            "Question 48 / 704\n",
            "Question 49 / 704\n",
            "Question 50 / 704\n",
            "Question 51 / 704\n",
            "Question 52 / 704\n",
            "Question 53 / 704\n",
            "Question 54 / 704\n",
            "Question 55 / 704\n",
            "Question 56 / 704\n",
            "Question 57 / 704\n",
            "Question 58 / 704\n",
            "Question 59 / 704\n",
            "Question 60 / 704\n",
            "Question 61 / 704\n",
            "Question 62 / 704\n",
            "Question 63 / 704\n",
            "Question 64 / 704\n",
            "Question 65 / 704\n",
            "Question 66 / 704\n",
            "Question 67 / 704\n",
            "Question 68 / 704\n",
            "Question 69 / 704\n",
            "Question 70 / 704\n",
            "Question 71 / 704\n",
            "Question 72 / 704\n",
            "Question 73 / 704\n",
            "Question 74 / 704\n",
            "Question 75 / 704\n",
            "Question 76 / 704\n",
            "Question 77 / 704\n",
            "Question 78 / 704\n",
            "Question 79 / 704\n",
            "Question 80 / 704\n",
            "Question 81 / 704\n",
            "Question 82 / 704\n",
            "Question 83 / 704\n",
            "Question 84 / 704\n",
            "Question 85 / 704\n",
            "Question 86 / 704\n",
            "Question 87 / 704\n",
            "Question 88 / 704\n",
            "Question 89 / 704\n",
            "Question 90 / 704\n",
            "Question 91 / 704\n",
            "Question 92 / 704\n",
            "Question 93 / 704\n",
            "Question 94 / 704\n",
            "Question 95 / 704\n",
            "Question 96 / 704\n",
            "Question 97 / 704\n",
            "Question 98 / 704\n",
            "Question 99 / 704\n",
            "Question 100 / 704\n",
            "Question 101 / 704\n",
            "Question 102 / 704\n",
            "Question 103 / 704\n",
            "Question 104 / 704\n",
            "Question 105 / 704\n",
            "Question 106 / 704\n",
            "Question 107 / 704\n",
            "Question 108 / 704\n",
            "Question 109 / 704\n",
            "Question 110 / 704\n",
            "Question 111 / 704\n",
            "Question 112 / 704\n",
            "Question 113 / 704\n",
            "Question 114 / 704\n",
            "Question 115 / 704\n",
            "Question 116 / 704\n",
            "Question 117 / 704\n",
            "Question 118 / 704\n",
            "Question 119 / 704\n",
            "Question 120 / 704\n",
            "Question 121 / 704\n",
            "Question 122 / 704\n",
            "Question 123 / 704\n",
            "Question 124 / 704\n",
            "Question 125 / 704\n",
            "Question 126 / 704\n",
            "Question 127 / 704\n",
            "Question 128 / 704\n",
            "Question 129 / 704\n",
            "Question 130 / 704\n",
            "Question 131 / 704\n",
            "Question 132 / 704\n",
            "Question 133 / 704\n",
            "Question 134 / 704\n",
            "Question 135 / 704\n",
            "Question 136 / 704\n",
            "Question 137 / 704\n",
            "Question 138 / 704\n",
            "Question 139 / 704\n",
            "Question 140 / 704\n",
            "Question 141 / 704\n",
            "Question 142 / 704\n",
            "Question 143 / 704\n",
            "Question 144 / 704\n",
            "Question 145 / 704\n",
            "Question 146 / 704\n",
            "Question 147 / 704\n",
            "Question 148 / 704\n",
            "Question 149 / 704\n",
            "Question 150 / 704\n",
            "Question 151 / 704\n",
            "Question 152 / 704\n",
            "Question 153 / 704\n",
            "Question 154 / 704\n",
            "Question 155 / 704\n",
            "Question 156 / 704\n",
            "Question 157 / 704\n",
            "Question 158 / 704\n",
            "Question 159 / 704\n",
            "Question 160 / 704\n",
            "Question 161 / 704\n",
            "Question 162 / 704\n",
            "Question 163 / 704\n",
            "Question 164 / 704\n",
            "Question 165 / 704\n",
            "Question 166 / 704\n",
            "Question 167 / 704\n",
            "Question 168 / 704\n",
            "Question 169 / 704\n",
            "Question 170 / 704\n",
            "Question 171 / 704\n",
            "Question 172 / 704\n",
            "Question 173 / 704\n",
            "Question 174 / 704\n",
            "Question 175 / 704\n",
            "Question 176 / 704\n",
            "Question 177 / 704\n",
            "Question 178 / 704\n",
            "Question 179 / 704\n",
            "Question 180 / 704\n",
            "Question 181 / 704\n",
            "Question 182 / 704\n",
            "Question 183 / 704\n",
            "Question 184 / 704\n",
            "Question 185 / 704\n",
            "Question 186 / 704\n",
            "Question 187 / 704\n",
            "Question 188 / 704\n",
            "Question 189 / 704\n",
            "Question 190 / 704\n",
            "Question 191 / 704\n",
            "Question 192 / 704\n",
            "Question 193 / 704\n",
            "Question 194 / 704\n",
            "Question 195 / 704\n",
            "Question 196 / 704\n",
            "Question 197 / 704\n",
            "Question 198 / 704\n",
            "Question 199 / 704\n",
            "Question 200 / 704\n",
            "Question 201 / 704\n",
            "Question 202 / 704\n",
            "Question 203 / 704\n",
            "Question 204 / 704\n",
            "Question 205 / 704\n",
            "Question 206 / 704\n",
            "Question 207 / 704\n",
            "Question 208 / 704\n",
            "Question 209 / 704\n",
            "Question 210 / 704\n",
            "Question 211 / 704\n",
            "Question 212 / 704\n",
            "Question 213 / 704\n",
            "Question 214 / 704\n",
            "Question 215 / 704\n",
            "Question 216 / 704\n",
            "Question 217 / 704\n",
            "Question 218 / 704\n",
            "Question 219 / 704\n",
            "Question 220 / 704\n",
            "Question 221 / 704\n",
            "Question 222 / 704\n",
            "Question 223 / 704\n",
            "Question 224 / 704\n",
            "Question 225 / 704\n",
            "Question 226 / 704\n",
            "Question 227 / 704\n",
            "Question 228 / 704\n",
            "Question 229 / 704\n",
            "Question 230 / 704\n",
            "Question 231 / 704\n",
            "Question 232 / 704\n",
            "Question 233 / 704\n",
            "Question 234 / 704\n",
            "Question 235 / 704\n",
            "Question 236 / 704\n",
            "Question 237 / 704\n",
            "Question 238 / 704\n",
            "Question 239 / 704\n",
            "Question 240 / 704\n",
            "Question 241 / 704\n",
            "Question 242 / 704\n",
            "Question 243 / 704\n",
            "Question 244 / 704\n",
            "Question 245 / 704\n",
            "Question 246 / 704\n",
            "Question 247 / 704\n",
            "Question 248 / 704\n",
            "Question 249 / 704\n",
            "Question 250 / 704\n",
            "Question 251 / 704\n",
            "Question 252 / 704\n",
            "Question 253 / 704\n",
            "Question 254 / 704\n",
            "Question 255 / 704\n",
            "Question 256 / 704\n",
            "Question 257 / 704\n",
            "Question 258 / 704\n",
            "Question 259 / 704\n",
            "Question 260 / 704\n",
            "Question 261 / 704\n",
            "Question 262 / 704\n",
            "Question 263 / 704\n",
            "Question 264 / 704\n",
            "Question 265 / 704\n",
            "Question 266 / 704\n",
            "Question 267 / 704\n",
            "Question 268 / 704\n",
            "Question 269 / 704\n",
            "Question 270 / 704\n",
            "Question 271 / 704\n",
            "Question 272 / 704\n",
            "Question 273 / 704\n",
            "Question 274 / 704\n",
            "Question 275 / 704\n",
            "Question 276 / 704\n",
            "Question 277 / 704\n",
            "Question 278 / 704\n",
            "Question 279 / 704\n",
            "Question 280 / 704\n",
            "Question 281 / 704\n",
            "Question 282 / 704\n",
            "Question 283 / 704\n",
            "Question 284 / 704\n",
            "Question 285 / 704\n",
            "Question 286 / 704\n",
            "Question 287 / 704\n",
            "Question 288 / 704\n",
            "Question 289 / 704\n",
            "Question 290 / 704\n",
            "Question 291 / 704\n",
            "Question 292 / 704\n",
            "Question 293 / 704\n",
            "Question 294 / 704\n",
            "Question 295 / 704\n",
            "Question 296 / 704\n",
            "Question 297 / 704\n",
            "Question 298 / 704\n",
            "Question 299 / 704\n",
            "Question 300 / 704\n",
            "Question 301 / 704\n",
            "Question 302 / 704\n",
            "Question 303 / 704\n",
            "Question 304 / 704\n",
            "Question 305 / 704\n",
            "Question 306 / 704\n",
            "Question 307 / 704\n",
            "Question 308 / 704\n",
            "Question 309 / 704\n",
            "Question 310 / 704\n",
            "Question 311 / 704\n",
            "Question 312 / 704\n",
            "Question 313 / 704\n",
            "Question 314 / 704\n",
            "Question 315 / 704\n",
            "Question 316 / 704\n",
            "Question 317 / 704\n",
            "Question 318 / 704\n",
            "Question 319 / 704\n",
            "Question 320 / 704\n",
            "Question 321 / 704\n",
            "Question 322 / 704\n",
            "Question 323 / 704\n",
            "Question 324 / 704\n",
            "Question 325 / 704\n",
            "Question 326 / 704\n",
            "Question 327 / 704\n",
            "Question 328 / 704\n",
            "Question 329 / 704\n",
            "Question 330 / 704\n",
            "Question 331 / 704\n",
            "Question 332 / 704\n",
            "Question 333 / 704\n",
            "Question 334 / 704\n",
            "Question 335 / 704\n",
            "Question 336 / 704\n",
            "Question 337 / 704\n",
            "Question 338 / 704\n",
            "Question 339 / 704\n",
            "Question 340 / 704\n",
            "Question 341 / 704\n",
            "Question 342 / 704\n",
            "Question 343 / 704\n",
            "Question 344 / 704\n",
            "Question 345 / 704\n",
            "Question 346 / 704\n",
            "Question 347 / 704\n",
            "Question 348 / 704\n",
            "Question 349 / 704\n",
            "Question 350 / 704\n",
            "Question 351 / 704\n",
            "Question 352 / 704\n",
            "Question 353 / 704\n",
            "Question 354 / 704\n",
            "Question 355 / 704\n",
            "Question 356 / 704\n",
            "Question 357 / 704\n",
            "Question 358 / 704\n",
            "Question 359 / 704\n",
            "Question 360 / 704\n",
            "Question 361 / 704\n",
            "Question 362 / 704\n",
            "Question 363 / 704\n",
            "Question 364 / 704\n",
            "Question 365 / 704\n",
            "Question 366 / 704\n",
            "Question 367 / 704\n",
            "Question 368 / 704\n",
            "Question 369 / 704\n",
            "Question 370 / 704\n",
            "Question 371 / 704\n",
            "Question 372 / 704\n",
            "Question 373 / 704\n",
            "Question 374 / 704\n",
            "Question 375 / 704\n",
            "Question 376 / 704\n",
            "Question 377 / 704\n",
            "Question 378 / 704\n",
            "Question 379 / 704\n",
            "Question 380 / 704\n",
            "Question 381 / 704\n",
            "Question 382 / 704\n",
            "Question 383 / 704\n",
            "Question 384 / 704\n",
            "Question 385 / 704\n",
            "Question 386 / 704\n",
            "Question 387 / 704\n",
            "Question 388 / 704\n",
            "Question 389 / 704\n",
            "Question 390 / 704\n",
            "Question 391 / 704\n",
            "Question 392 / 704\n",
            "Question 393 / 704\n",
            "Question 394 / 704\n",
            "Question 395 / 704\n",
            "Question 396 / 704\n",
            "Question 397 / 704\n",
            "Question 398 / 704\n",
            "Question 399 / 704\n",
            "Question 400 / 704\n",
            "Question 401 / 704\n",
            "Question 402 / 704\n",
            "Question 403 / 704\n",
            "Question 404 / 704\n",
            "Question 405 / 704\n",
            "Question 406 / 704\n",
            "Question 407 / 704\n",
            "Question 408 / 704\n",
            "Question 409 / 704\n",
            "Question 410 / 704\n",
            "Question 411 / 704\n",
            "Question 412 / 704\n",
            "Question 413 / 704\n",
            "Question 414 / 704\n",
            "Question 415 / 704\n",
            "Question 416 / 704\n",
            "Question 417 / 704\n",
            "Question 418 / 704\n",
            "Question 419 / 704\n",
            "Question 420 / 704\n",
            "Question 421 / 704\n",
            "Question 422 / 704\n",
            "Question 423 / 704\n",
            "Question 424 / 704\n",
            "Question 425 / 704\n",
            "Question 426 / 704\n",
            "Question 427 / 704\n",
            "Question 428 / 704\n",
            "Question 429 / 704\n",
            "Question 430 / 704\n",
            "Question 431 / 704\n",
            "Question 432 / 704\n",
            "Question 433 / 704\n",
            "Question 434 / 704\n",
            "Question 435 / 704\n",
            "Question 436 / 704\n",
            "Question 437 / 704\n",
            "Question 438 / 704\n",
            "Question 439 / 704\n",
            "Question 440 / 704\n",
            "Question 441 / 704\n",
            "Question 442 / 704\n",
            "Question 443 / 704\n",
            "Question 444 / 704\n",
            "Question 445 / 704\n",
            "Question 446 / 704\n",
            "Question 447 / 704\n",
            "Question 448 / 704\n",
            "Question 449 / 704\n",
            "Question 450 / 704\n",
            "Question 451 / 704\n",
            "Question 452 / 704\n",
            "Question 453 / 704\n",
            "Question 454 / 704\n",
            "Question 455 / 704\n",
            "Question 456 / 704\n",
            "Question 457 / 704\n",
            "Question 458 / 704\n",
            "Question 459 / 704\n",
            "Question 460 / 704\n",
            "Question 461 / 704\n",
            "Question 462 / 704\n",
            "Question 463 / 704\n",
            "Question 464 / 704\n",
            "Question 465 / 704\n",
            "Question 466 / 704\n",
            "Question 467 / 704\n",
            "Question 468 / 704\n",
            "Question 469 / 704\n",
            "Question 470 / 704\n",
            "Question 471 / 704\n",
            "Question 472 / 704\n",
            "Question 473 / 704\n",
            "Question 474 / 704\n",
            "Question 475 / 704\n",
            "Question 476 / 704\n",
            "Question 477 / 704\n",
            "Question 478 / 704\n",
            "Question 479 / 704\n",
            "Question 480 / 704\n",
            "Question 481 / 704\n",
            "Question 482 / 704\n",
            "Question 483 / 704\n",
            "Question 484 / 704\n",
            "Question 485 / 704\n",
            "Question 486 / 704\n",
            "Question 487 / 704\n",
            "Question 488 / 704\n",
            "Question 489 / 704\n",
            "Question 490 / 704\n",
            "Question 491 / 704\n",
            "Question 492 / 704\n",
            "Question 493 / 704\n",
            "Question 494 / 704\n",
            "Question 495 / 704\n",
            "Question 496 / 704\n",
            "Question 497 / 704\n",
            "Question 498 / 704\n",
            "Question 499 / 704\n",
            "Question 500 / 704\n",
            "Question 501 / 704\n",
            "Question 502 / 704\n",
            "Question 503 / 704\n",
            "Question 504 / 704\n",
            "Question 505 / 704\n",
            "Question 506 / 704\n",
            "Question 507 / 704\n",
            "Question 508 / 704\n",
            "Question 509 / 704\n",
            "Question 510 / 704\n",
            "Question 511 / 704\n",
            "Question 512 / 704\n",
            "Question 513 / 704\n",
            "Question 514 / 704\n",
            "Question 515 / 704\n",
            "Question 516 / 704\n",
            "Question 517 / 704\n",
            "Question 518 / 704\n",
            "Question 519 / 704\n",
            "Question 520 / 704\n",
            "Question 521 / 704\n",
            "Question 522 / 704\n",
            "Question 523 / 704\n",
            "Question 524 / 704\n",
            "Question 525 / 704\n",
            "Question 526 / 704\n",
            "Question 527 / 704\n",
            "Question 528 / 704\n",
            "Question 529 / 704\n",
            "Question 530 / 704\n",
            "Question 531 / 704\n",
            "Question 532 / 704\n",
            "Question 533 / 704\n",
            "Question 534 / 704\n",
            "Question 535 / 704\n",
            "Question 536 / 704\n",
            "Question 537 / 704\n",
            "Question 538 / 704\n",
            "Question 539 / 704\n",
            "Question 540 / 704\n",
            "Question 541 / 704\n",
            "Question 542 / 704\n",
            "Question 543 / 704\n",
            "Question 544 / 704\n",
            "Question 545 / 704\n",
            "Question 546 / 704\n",
            "Question 547 / 704\n",
            "Question 548 / 704\n",
            "Question 549 / 704\n",
            "Question 550 / 704\n",
            "Question 551 / 704\n",
            "Question 552 / 704\n",
            "Question 553 / 704\n",
            "Question 554 / 704\n",
            "Question 555 / 704\n",
            "Question 556 / 704\n",
            "Question 557 / 704\n",
            "Question 558 / 704\n",
            "Question 559 / 704\n",
            "Question 560 / 704\n",
            "Question 561 / 704\n",
            "Question 562 / 704\n",
            "Question 563 / 704\n",
            "Question 564 / 704\n",
            "Question 565 / 704\n",
            "Question 566 / 704\n",
            "Question 567 / 704\n",
            "Question 568 / 704\n",
            "Question 569 / 704\n",
            "Question 570 / 704\n",
            "Question 571 / 704\n",
            "Question 572 / 704\n",
            "Question 573 / 704\n",
            "Question 574 / 704\n",
            "Question 575 / 704\n",
            "Question 576 / 704\n",
            "Question 577 / 704\n",
            "Question 578 / 704\n",
            "Question 579 / 704\n",
            "Question 580 / 704\n",
            "Question 581 / 704\n",
            "Question 582 / 704\n",
            "Question 583 / 704\n",
            "Question 584 / 704\n",
            "Question 585 / 704\n",
            "Question 586 / 704\n",
            "Question 587 / 704\n",
            "Question 588 / 704\n",
            "Question 589 / 704\n",
            "Question 590 / 704\n",
            "Question 591 / 704\n",
            "Question 592 / 704\n",
            "Question 593 / 704\n",
            "Question 594 / 704\n",
            "Question 595 / 704\n",
            "Question 596 / 704\n",
            "Question 597 / 704\n",
            "Question 598 / 704\n",
            "Question 599 / 704\n",
            "Question 600 / 704\n",
            "Question 601 / 704\n",
            "Question 602 / 704\n",
            "Question 603 / 704\n",
            "Question 604 / 704\n",
            "Question 605 / 704\n",
            "Question 606 / 704\n",
            "Question 607 / 704\n",
            "Question 608 / 704\n",
            "Question 609 / 704\n",
            "Question 610 / 704\n",
            "Question 611 / 704\n",
            "Question 612 / 704\n",
            "Question 613 / 704\n",
            "Question 614 / 704\n",
            "Question 615 / 704\n",
            "Question 616 / 704\n",
            "Question 617 / 704\n",
            "Question 618 / 704\n",
            "Question 619 / 704\n",
            "Question 620 / 704\n",
            "Question 621 / 704\n",
            "Question 622 / 704\n",
            "Question 623 / 704\n",
            "Question 624 / 704\n",
            "Question 625 / 704\n",
            "Question 626 / 704\n",
            "Question 627 / 704\n",
            "Question 628 / 704\n",
            "Question 629 / 704\n",
            "Question 630 / 704\n",
            "Question 631 / 704\n",
            "Question 632 / 704\n",
            "Question 633 / 704\n",
            "Question 634 / 704\n",
            "Question 635 / 704\n",
            "Question 636 / 704\n",
            "Question 637 / 704\n",
            "Question 638 / 704\n",
            "Question 639 / 704\n",
            "Question 640 / 704\n",
            "Question 641 / 704\n",
            "Question 642 / 704\n",
            "Question 643 / 704\n",
            "Question 644 / 704\n",
            "Question 645 / 704\n",
            "Question 646 / 704\n",
            "Question 647 / 704\n",
            "Question 648 / 704\n",
            "Question 649 / 704\n",
            "Question 650 / 704\n",
            "Question 651 / 704\n",
            "Question 652 / 704\n",
            "Question 653 / 704\n",
            "Question 654 / 704\n",
            "Question 655 / 704\n",
            "Question 656 / 704\n",
            "Question 657 / 704\n",
            "Question 658 / 704\n",
            "Question 659 / 704\n",
            "Question 660 / 704\n",
            "Question 661 / 704\n",
            "Question 662 / 704\n",
            "Question 663 / 704\n",
            "Question 664 / 704\n",
            "Question 665 / 704\n",
            "Question 666 / 704\n",
            "Question 667 / 704\n",
            "Question 668 / 704\n",
            "Question 669 / 704\n",
            "Question 670 / 704\n",
            "Question 671 / 704\n",
            "Question 672 / 704\n",
            "Question 673 / 704\n",
            "Question 674 / 704\n",
            "Question 675 / 704\n",
            "Question 676 / 704\n",
            "Question 677 / 704\n",
            "Question 678 / 704\n",
            "Question 679 / 704\n",
            "Question 680 / 704\n",
            "Question 681 / 704\n",
            "Question 682 / 704\n",
            "Question 683 / 704\n",
            "Question 684 / 704\n",
            "Question 685 / 704\n",
            "Question 686 / 704\n",
            "Question 687 / 704\n",
            "Question 688 / 704\n",
            "Question 689 / 704\n",
            "Question 690 / 704\n",
            "Question 691 / 704\n",
            "Question 692 / 704\n",
            "Question 693 / 704\n",
            "Question 694 / 704\n",
            "Question 695 / 704\n",
            "Question 696 / 704\n",
            "Question 697 / 704\n",
            "Question 698 / 704\n",
            "Question 699 / 704\n",
            "Question 700 / 704\n",
            "Question 701 / 704\n",
            "Question 702 / 704\n",
            "Question 703 / 704\n",
            "Question 704 / 704\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Evaluation loop\n",
        "num_correct = 0\n",
        "for idx, row in enumerate(test_data):\n",
        "    context = row[\"question\"]\n",
        "    options = row[\"option\"]\n",
        "    correct_option = row[\"answer\"].strip()\n",
        "\n",
        "    # Prepare the inputs\n",
        "    choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=128, padding='max_length', truncation=True) for option in options]\n",
        "\n",
        "    # Get the input tensors and reshape them\n",
        "    input_ids = torch.cat([choice['input_ids'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    attention_mask = torch.cat([choice['attention_mask'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    # Compute the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Get the predicted option\n",
        "    predicted_option = torch.argmax(outputs.logits).item()\n",
        "\n",
        "    # Check if the prediction is correct\n",
        "    if predicted_option == options.index(correct_option):\n",
        "        num_correct += 1\n",
        "    print(f\"Question {idx + 1} / {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDBisVxMWWIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec64c38-e80d-4e8c-f0c9-1f7f6e773398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.18607954545454544\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy: {num_correct / len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will train the model by train data set and re-evaluate for test set. <br>\n",
        "**I only do the training for 1 epoch because of the running-time. If epoch gets larger, then the accuracy will increase further**"
      ],
      "metadata": {
        "id": "XsRa548T56_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pf0votydPFL",
        "outputId": "882066c1-4943-4777-a7fd-7180da960463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Question 1 / 2813 for epoch 0\n",
            "Training Question 51 / 2813 for epoch 0\n",
            "Training Question 101 / 2813 for epoch 0\n",
            "Training Question 151 / 2813 for epoch 0\n",
            "Training Question 201 / 2813 for epoch 0\n",
            "Training Question 251 / 2813 for epoch 0\n",
            "Training Question 301 / 2813 for epoch 0\n",
            "Training Question 351 / 2813 for epoch 0\n",
            "Training Question 401 / 2813 for epoch 0\n",
            "Training Question 451 / 2813 for epoch 0\n",
            "Training Question 501 / 2813 for epoch 0\n",
            "Training Question 551 / 2813 for epoch 0\n",
            "Training Question 601 / 2813 for epoch 0\n",
            "Training Question 651 / 2813 for epoch 0\n",
            "Training Question 701 / 2813 for epoch 0\n",
            "Training Question 751 / 2813 for epoch 0\n",
            "Training Question 801 / 2813 for epoch 0\n",
            "Training Question 851 / 2813 for epoch 0\n",
            "Training Question 901 / 2813 for epoch 0\n",
            "Training Question 951 / 2813 for epoch 0\n",
            "Training Question 1001 / 2813 for epoch 0\n",
            "Training Question 1051 / 2813 for epoch 0\n",
            "Training Question 1101 / 2813 for epoch 0\n",
            "Training Question 1151 / 2813 for epoch 0\n",
            "Training Question 1201 / 2813 for epoch 0\n",
            "Training Question 1251 / 2813 for epoch 0\n",
            "Training Question 1301 / 2813 for epoch 0\n",
            "Training Question 1351 / 2813 for epoch 0\n",
            "Training Question 1401 / 2813 for epoch 0\n",
            "Training Question 1451 / 2813 for epoch 0\n",
            "Training Question 1501 / 2813 for epoch 0\n",
            "Training Question 1551 / 2813 for epoch 0\n",
            "Training Question 1601 / 2813 for epoch 0\n",
            "Training Question 1651 / 2813 for epoch 0\n",
            "Training Question 1701 / 2813 for epoch 0\n",
            "Training Question 1751 / 2813 for epoch 0\n",
            "Training Question 1801 / 2813 for epoch 0\n",
            "Training Question 1851 / 2813 for epoch 0\n",
            "Training Question 1901 / 2813 for epoch 0\n",
            "Training Question 1951 / 2813 for epoch 0\n",
            "Training Question 2001 / 2813 for epoch 0\n",
            "Training Question 2051 / 2813 for epoch 0\n",
            "Training Question 2101 / 2813 for epoch 0\n",
            "Training Question 2151 / 2813 for epoch 0\n",
            "Training Question 2201 / 2813 for epoch 0\n",
            "Training Question 2251 / 2813 for epoch 0\n",
            "Training Question 2301 / 2813 for epoch 0\n",
            "Training Question 2351 / 2813 for epoch 0\n",
            "Training Question 2401 / 2813 for epoch 0\n",
            "Training Question 2451 / 2813 for epoch 0\n",
            "Training Question 2501 / 2813 for epoch 0\n",
            "Training Question 2551 / 2813 for epoch 0\n",
            "Training Question 2601 / 2813 for epoch 0\n",
            "Training Question 2651 / 2813 for epoch 0\n",
            "Training Question 2701 / 2813 for epoch 0\n",
            "Training Question 2751 / 2813 for epoch 0\n",
            "Training Question 2801 / 2813 for epoch 0\n",
            "Training Question 1 / 2813 for epoch 1\n",
            "Training Question 51 / 2813 for epoch 1\n",
            "Training Question 101 / 2813 for epoch 1\n",
            "Training Question 151 / 2813 for epoch 1\n",
            "Training Question 201 / 2813 for epoch 1\n",
            "Training Question 251 / 2813 for epoch 1\n",
            "Training Question 301 / 2813 for epoch 1\n",
            "Training Question 351 / 2813 for epoch 1\n",
            "Training Question 401 / 2813 for epoch 1\n",
            "Training Question 451 / 2813 for epoch 1\n",
            "Training Question 501 / 2813 for epoch 1\n",
            "Training Question 551 / 2813 for epoch 1\n",
            "Training Question 601 / 2813 for epoch 1\n",
            "Training Question 651 / 2813 for epoch 1\n",
            "Training Question 701 / 2813 for epoch 1\n",
            "Training Question 751 / 2813 for epoch 1\n",
            "Training Question 801 / 2813 for epoch 1\n",
            "Training Question 851 / 2813 for epoch 1\n",
            "Training Question 901 / 2813 for epoch 1\n",
            "Training Question 951 / 2813 for epoch 1\n",
            "Training Question 1001 / 2813 for epoch 1\n",
            "Training Question 1051 / 2813 for epoch 1\n",
            "Training Question 1101 / 2813 for epoch 1\n",
            "Training Question 1151 / 2813 for epoch 1\n",
            "Training Question 1201 / 2813 for epoch 1\n",
            "Training Question 1251 / 2813 for epoch 1\n",
            "Training Question 1301 / 2813 for epoch 1\n",
            "Training Question 1351 / 2813 for epoch 1\n",
            "Training Question 1401 / 2813 for epoch 1\n",
            "Training Question 1451 / 2813 for epoch 1\n",
            "Training Question 1501 / 2813 for epoch 1\n",
            "Training Question 1551 / 2813 for epoch 1\n",
            "Training Question 1601 / 2813 for epoch 1\n",
            "Training Question 1651 / 2813 for epoch 1\n",
            "Training Question 1701 / 2813 for epoch 1\n",
            "Training Question 1751 / 2813 for epoch 1\n",
            "Training Question 1801 / 2813 for epoch 1\n",
            "Training Question 1851 / 2813 for epoch 1\n",
            "Training Question 1901 / 2813 for epoch 1\n",
            "Training Question 1951 / 2813 for epoch 1\n",
            "Training Question 2001 / 2813 for epoch 1\n",
            "Training Question 2051 / 2813 for epoch 1\n",
            "Training Question 2101 / 2813 for epoch 1\n",
            "Training Question 2151 / 2813 for epoch 1\n",
            "Training Question 2201 / 2813 for epoch 1\n",
            "Training Question 2251 / 2813 for epoch 1\n",
            "Training Question 2301 / 2813 for epoch 1\n",
            "Training Question 2351 / 2813 for epoch 1\n",
            "Training Question 2401 / 2813 for epoch 1\n",
            "Training Question 2451 / 2813 for epoch 1\n",
            "Training Question 2501 / 2813 for epoch 1\n",
            "Training Question 2551 / 2813 for epoch 1\n",
            "Training Question 2601 / 2813 for epoch 1\n",
            "Training Question 2651 / 2813 for epoch 1\n",
            "Training Question 2701 / 2813 for epoch 1\n",
            "Training Question 2751 / 2813 for epoch 1\n",
            "Training Question 2801 / 2813 for epoch 1\n",
            "Training Question 1 / 2813 for epoch 2\n",
            "Training Question 51 / 2813 for epoch 2\n",
            "Training Question 101 / 2813 for epoch 2\n",
            "Training Question 151 / 2813 for epoch 2\n",
            "Training Question 201 / 2813 for epoch 2\n",
            "Training Question 251 / 2813 for epoch 2\n",
            "Training Question 301 / 2813 for epoch 2\n",
            "Training Question 351 / 2813 for epoch 2\n",
            "Training Question 401 / 2813 for epoch 2\n",
            "Training Question 451 / 2813 for epoch 2\n",
            "Training Question 501 / 2813 for epoch 2\n",
            "Training Question 551 / 2813 for epoch 2\n",
            "Training Question 601 / 2813 for epoch 2\n",
            "Training Question 651 / 2813 for epoch 2\n",
            "Training Question 701 / 2813 for epoch 2\n",
            "Training Question 751 / 2813 for epoch 2\n",
            "Training Question 801 / 2813 for epoch 2\n",
            "Training Question 851 / 2813 for epoch 2\n",
            "Training Question 901 / 2813 for epoch 2\n",
            "Training Question 951 / 2813 for epoch 2\n",
            "Training Question 1001 / 2813 for epoch 2\n",
            "Training Question 1051 / 2813 for epoch 2\n",
            "Training Question 1101 / 2813 for epoch 2\n",
            "Training Question 1151 / 2813 for epoch 2\n",
            "Training Question 1201 / 2813 for epoch 2\n",
            "Training Question 1251 / 2813 for epoch 2\n",
            "Training Question 1301 / 2813 for epoch 2\n",
            "Training Question 1351 / 2813 for epoch 2\n",
            "Training Question 1401 / 2813 for epoch 2\n",
            "Training Question 1451 / 2813 for epoch 2\n",
            "Training Question 1501 / 2813 for epoch 2\n",
            "Training Question 1551 / 2813 for epoch 2\n",
            "Training Question 1601 / 2813 for epoch 2\n",
            "Training Question 1651 / 2813 for epoch 2\n",
            "Training Question 1701 / 2813 for epoch 2\n",
            "Training Question 1751 / 2813 for epoch 2\n",
            "Training Question 1801 / 2813 for epoch 2\n",
            "Training Question 1851 / 2813 for epoch 2\n",
            "Training Question 1901 / 2813 for epoch 2\n",
            "Training Question 1951 / 2813 for epoch 2\n",
            "Training Question 2001 / 2813 for epoch 2\n",
            "Training Question 2051 / 2813 for epoch 2\n",
            "Training Question 2101 / 2813 for epoch 2\n",
            "Training Question 2151 / 2813 for epoch 2\n",
            "Training Question 2201 / 2813 for epoch 2\n",
            "Training Question 2251 / 2813 for epoch 2\n",
            "Training Question 2301 / 2813 for epoch 2\n",
            "Training Question 2351 / 2813 for epoch 2\n",
            "Training Question 2401 / 2813 for epoch 2\n",
            "Training Question 2451 / 2813 for epoch 2\n",
            "Training Question 2501 / 2813 for epoch 2\n",
            "Training Question 2551 / 2813 for epoch 2\n",
            "Training Question 2601 / 2813 for epoch 2\n",
            "Training Question 2651 / 2813 for epoch 2\n",
            "Training Question 2701 / 2813 for epoch 2\n",
            "Training Question 2751 / 2813 for epoch 2\n",
            "Training Question 2801 / 2813 for epoch 2\n"
          ]
        }
      ],
      "source": [
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Set the model to training mode\n",
        "model.train()\n",
        "\n",
        "num_epochs = 3\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "  for idx, row in enumerate(train_data):\n",
        "      context = row[\"question\"]\n",
        "      options = row[\"option\"]\n",
        "      correct_option = row[\"answer\"].strip()\n",
        "\n",
        "      # Prepare the inputs\n",
        "      choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=256, padding='max_length', truncation=True) for option in options]\n",
        "\n",
        "      # Get the input tensors and reshape them\n",
        "      input_ids = torch.cat([choice['input_ids'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "      attention_mask = torch.cat([choice['attention_mask'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "      input_ids = input_ids.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "\n",
        "      # Compute the model outputs\n",
        "      correct_option_idx = options.index(correct_option)\n",
        "      correct_option_idx = torch.tensor([correct_option_idx]).to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=correct_option_idx)\n",
        "\n",
        "      # Compute the loss\n",
        "      loss = outputs.loss\n",
        "\n",
        "      # Backward pass and optimization\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      if idx % 50 == 0:\n",
        "        print(f\"Training Question {idx + 1} / {len(train_data)} for epoch {epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2qKgyufedeg"
      },
      "source": [
        "After training, we will test and see the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbp6WAIfekiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24d18ce-4f1f-48ed-d89c-9c7710a22b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1 / 704\n",
            "Question 2 / 704\n",
            "Question 3 / 704\n",
            "Question 4 / 704\n",
            "Question 5 / 704\n",
            "Question 6 / 704\n",
            "Question 7 / 704\n",
            "Question 8 / 704\n",
            "Question 9 / 704\n",
            "Question 10 / 704\n",
            "Question 11 / 704\n",
            "Question 12 / 704\n",
            "Question 13 / 704\n",
            "Question 14 / 704\n",
            "Question 15 / 704\n",
            "Question 16 / 704\n",
            "Question 17 / 704\n",
            "Question 18 / 704\n",
            "Question 19 / 704\n",
            "Question 20 / 704\n",
            "Question 21 / 704\n",
            "Question 22 / 704\n",
            "Question 23 / 704\n",
            "Question 24 / 704\n",
            "Question 25 / 704\n",
            "Question 26 / 704\n",
            "Question 27 / 704\n",
            "Question 28 / 704\n",
            "Question 29 / 704\n",
            "Question 30 / 704\n",
            "Question 31 / 704\n",
            "Question 32 / 704\n",
            "Question 33 / 704\n",
            "Question 34 / 704\n",
            "Question 35 / 704\n",
            "Question 36 / 704\n",
            "Question 37 / 704\n",
            "Question 38 / 704\n",
            "Question 39 / 704\n",
            "Question 40 / 704\n",
            "Question 41 / 704\n",
            "Question 42 / 704\n",
            "Question 43 / 704\n",
            "Question 44 / 704\n",
            "Question 45 / 704\n",
            "Question 46 / 704\n",
            "Question 47 / 704\n",
            "Question 48 / 704\n",
            "Question 49 / 704\n",
            "Question 50 / 704\n",
            "Question 51 / 704\n",
            "Question 52 / 704\n",
            "Question 53 / 704\n",
            "Question 54 / 704\n",
            "Question 55 / 704\n",
            "Question 56 / 704\n",
            "Question 57 / 704\n",
            "Question 58 / 704\n",
            "Question 59 / 704\n",
            "Question 60 / 704\n",
            "Question 61 / 704\n",
            "Question 62 / 704\n",
            "Question 63 / 704\n",
            "Question 64 / 704\n",
            "Question 65 / 704\n",
            "Question 66 / 704\n",
            "Question 67 / 704\n",
            "Question 68 / 704\n",
            "Question 69 / 704\n",
            "Question 70 / 704\n",
            "Question 71 / 704\n",
            "Question 72 / 704\n",
            "Question 73 / 704\n",
            "Question 74 / 704\n",
            "Question 75 / 704\n",
            "Question 76 / 704\n",
            "Question 77 / 704\n",
            "Question 78 / 704\n",
            "Question 79 / 704\n",
            "Question 80 / 704\n",
            "Question 81 / 704\n",
            "Question 82 / 704\n",
            "Question 83 / 704\n",
            "Question 84 / 704\n",
            "Question 85 / 704\n",
            "Question 86 / 704\n",
            "Question 87 / 704\n",
            "Question 88 / 704\n",
            "Question 89 / 704\n",
            "Question 90 / 704\n",
            "Question 91 / 704\n",
            "Question 92 / 704\n",
            "Question 93 / 704\n",
            "Question 94 / 704\n",
            "Question 95 / 704\n",
            "Question 96 / 704\n",
            "Question 97 / 704\n",
            "Question 98 / 704\n",
            "Question 99 / 704\n",
            "Question 100 / 704\n",
            "Question 101 / 704\n",
            "Question 102 / 704\n",
            "Question 103 / 704\n",
            "Question 104 / 704\n",
            "Question 105 / 704\n",
            "Question 106 / 704\n",
            "Question 107 / 704\n",
            "Question 108 / 704\n",
            "Question 109 / 704\n",
            "Question 110 / 704\n",
            "Question 111 / 704\n",
            "Question 112 / 704\n",
            "Question 113 / 704\n",
            "Question 114 / 704\n",
            "Question 115 / 704\n",
            "Question 116 / 704\n",
            "Question 117 / 704\n",
            "Question 118 / 704\n",
            "Question 119 / 704\n",
            "Question 120 / 704\n",
            "Question 121 / 704\n",
            "Question 122 / 704\n",
            "Question 123 / 704\n",
            "Question 124 / 704\n",
            "Question 125 / 704\n",
            "Question 126 / 704\n",
            "Question 127 / 704\n",
            "Question 128 / 704\n",
            "Question 129 / 704\n",
            "Question 130 / 704\n",
            "Question 131 / 704\n",
            "Question 132 / 704\n",
            "Question 133 / 704\n",
            "Question 134 / 704\n",
            "Question 135 / 704\n",
            "Question 136 / 704\n",
            "Question 137 / 704\n",
            "Question 138 / 704\n",
            "Question 139 / 704\n",
            "Question 140 / 704\n",
            "Question 141 / 704\n",
            "Question 142 / 704\n",
            "Question 143 / 704\n",
            "Question 144 / 704\n",
            "Question 145 / 704\n",
            "Question 146 / 704\n",
            "Question 147 / 704\n",
            "Question 148 / 704\n",
            "Question 149 / 704\n",
            "Question 150 / 704\n",
            "Question 151 / 704\n",
            "Question 152 / 704\n",
            "Question 153 / 704\n",
            "Question 154 / 704\n",
            "Question 155 / 704\n",
            "Question 156 / 704\n",
            "Question 157 / 704\n",
            "Question 158 / 704\n",
            "Question 159 / 704\n",
            "Question 160 / 704\n",
            "Question 161 / 704\n",
            "Question 162 / 704\n",
            "Question 163 / 704\n",
            "Question 164 / 704\n",
            "Question 165 / 704\n",
            "Question 166 / 704\n",
            "Question 167 / 704\n",
            "Question 168 / 704\n",
            "Question 169 / 704\n",
            "Question 170 / 704\n",
            "Question 171 / 704\n",
            "Question 172 / 704\n",
            "Question 173 / 704\n",
            "Question 174 / 704\n",
            "Question 175 / 704\n",
            "Question 176 / 704\n",
            "Question 177 / 704\n",
            "Question 178 / 704\n",
            "Question 179 / 704\n",
            "Question 180 / 704\n",
            "Question 181 / 704\n",
            "Question 182 / 704\n",
            "Question 183 / 704\n",
            "Question 184 / 704\n",
            "Question 185 / 704\n",
            "Question 186 / 704\n",
            "Question 187 / 704\n",
            "Question 188 / 704\n",
            "Question 189 / 704\n",
            "Question 190 / 704\n",
            "Question 191 / 704\n",
            "Question 192 / 704\n",
            "Question 193 / 704\n",
            "Question 194 / 704\n",
            "Question 195 / 704\n",
            "Question 196 / 704\n",
            "Question 197 / 704\n",
            "Question 198 / 704\n",
            "Question 199 / 704\n",
            "Question 200 / 704\n",
            "Question 201 / 704\n",
            "Question 202 / 704\n",
            "Question 203 / 704\n",
            "Question 204 / 704\n",
            "Question 205 / 704\n",
            "Question 206 / 704\n",
            "Question 207 / 704\n",
            "Question 208 / 704\n",
            "Question 209 / 704\n",
            "Question 210 / 704\n",
            "Question 211 / 704\n",
            "Question 212 / 704\n",
            "Question 213 / 704\n",
            "Question 214 / 704\n",
            "Question 215 / 704\n",
            "Question 216 / 704\n",
            "Question 217 / 704\n",
            "Question 218 / 704\n",
            "Question 219 / 704\n",
            "Question 220 / 704\n",
            "Question 221 / 704\n",
            "Question 222 / 704\n",
            "Question 223 / 704\n",
            "Question 224 / 704\n",
            "Question 225 / 704\n",
            "Question 226 / 704\n",
            "Question 227 / 704\n",
            "Question 228 / 704\n",
            "Question 229 / 704\n",
            "Question 230 / 704\n",
            "Question 231 / 704\n",
            "Question 232 / 704\n",
            "Question 233 / 704\n",
            "Question 234 / 704\n",
            "Question 235 / 704\n",
            "Question 236 / 704\n",
            "Question 237 / 704\n",
            "Question 238 / 704\n",
            "Question 239 / 704\n",
            "Question 240 / 704\n",
            "Question 241 / 704\n",
            "Question 242 / 704\n",
            "Question 243 / 704\n",
            "Question 244 / 704\n",
            "Question 245 / 704\n",
            "Question 246 / 704\n",
            "Question 247 / 704\n",
            "Question 248 / 704\n",
            "Question 249 / 704\n",
            "Question 250 / 704\n",
            "Question 251 / 704\n",
            "Question 252 / 704\n",
            "Question 253 / 704\n",
            "Question 254 / 704\n",
            "Question 255 / 704\n",
            "Question 256 / 704\n",
            "Question 257 / 704\n",
            "Question 258 / 704\n",
            "Question 259 / 704\n",
            "Question 260 / 704\n",
            "Question 261 / 704\n",
            "Question 262 / 704\n",
            "Question 263 / 704\n",
            "Question 264 / 704\n",
            "Question 265 / 704\n",
            "Question 266 / 704\n",
            "Question 267 / 704\n",
            "Question 268 / 704\n",
            "Question 269 / 704\n",
            "Question 270 / 704\n",
            "Question 271 / 704\n",
            "Question 272 / 704\n",
            "Question 273 / 704\n",
            "Question 274 / 704\n",
            "Question 275 / 704\n",
            "Question 276 / 704\n",
            "Question 277 / 704\n",
            "Question 278 / 704\n",
            "Question 279 / 704\n",
            "Question 280 / 704\n",
            "Question 281 / 704\n",
            "Question 282 / 704\n",
            "Question 283 / 704\n",
            "Question 284 / 704\n",
            "Question 285 / 704\n",
            "Question 286 / 704\n",
            "Question 287 / 704\n",
            "Question 288 / 704\n",
            "Question 289 / 704\n",
            "Question 290 / 704\n",
            "Question 291 / 704\n",
            "Question 292 / 704\n",
            "Question 293 / 704\n",
            "Question 294 / 704\n",
            "Question 295 / 704\n",
            "Question 296 / 704\n",
            "Question 297 / 704\n",
            "Question 298 / 704\n",
            "Question 299 / 704\n",
            "Question 300 / 704\n",
            "Question 301 / 704\n",
            "Question 302 / 704\n",
            "Question 303 / 704\n",
            "Question 304 / 704\n",
            "Question 305 / 704\n",
            "Question 306 / 704\n",
            "Question 307 / 704\n",
            "Question 308 / 704\n",
            "Question 309 / 704\n",
            "Question 310 / 704\n",
            "Question 311 / 704\n",
            "Question 312 / 704\n",
            "Question 313 / 704\n",
            "Question 314 / 704\n",
            "Question 315 / 704\n",
            "Question 316 / 704\n",
            "Question 317 / 704\n",
            "Question 318 / 704\n",
            "Question 319 / 704\n",
            "Question 320 / 704\n",
            "Question 321 / 704\n",
            "Question 322 / 704\n",
            "Question 323 / 704\n",
            "Question 324 / 704\n",
            "Question 325 / 704\n",
            "Question 326 / 704\n",
            "Question 327 / 704\n",
            "Question 328 / 704\n",
            "Question 329 / 704\n",
            "Question 330 / 704\n",
            "Question 331 / 704\n",
            "Question 332 / 704\n",
            "Question 333 / 704\n",
            "Question 334 / 704\n",
            "Question 335 / 704\n",
            "Question 336 / 704\n",
            "Question 337 / 704\n",
            "Question 338 / 704\n",
            "Question 339 / 704\n",
            "Question 340 / 704\n",
            "Question 341 / 704\n",
            "Question 342 / 704\n",
            "Question 343 / 704\n",
            "Question 344 / 704\n",
            "Question 345 / 704\n",
            "Question 346 / 704\n",
            "Question 347 / 704\n",
            "Question 348 / 704\n",
            "Question 349 / 704\n",
            "Question 350 / 704\n",
            "Question 351 / 704\n",
            "Question 352 / 704\n",
            "Question 353 / 704\n",
            "Question 354 / 704\n",
            "Question 355 / 704\n",
            "Question 356 / 704\n",
            "Question 357 / 704\n",
            "Question 358 / 704\n",
            "Question 359 / 704\n",
            "Question 360 / 704\n",
            "Question 361 / 704\n",
            "Question 362 / 704\n",
            "Question 363 / 704\n",
            "Question 364 / 704\n",
            "Question 365 / 704\n",
            "Question 366 / 704\n",
            "Question 367 / 704\n",
            "Question 368 / 704\n",
            "Question 369 / 704\n",
            "Question 370 / 704\n",
            "Question 371 / 704\n",
            "Question 372 / 704\n",
            "Question 373 / 704\n",
            "Question 374 / 704\n",
            "Question 375 / 704\n",
            "Question 376 / 704\n",
            "Question 377 / 704\n",
            "Question 378 / 704\n",
            "Question 379 / 704\n",
            "Question 380 / 704\n",
            "Question 381 / 704\n",
            "Question 382 / 704\n",
            "Question 383 / 704\n",
            "Question 384 / 704\n",
            "Question 385 / 704\n",
            "Question 386 / 704\n",
            "Question 387 / 704\n",
            "Question 388 / 704\n",
            "Question 389 / 704\n",
            "Question 390 / 704\n",
            "Question 391 / 704\n",
            "Question 392 / 704\n",
            "Question 393 / 704\n",
            "Question 394 / 704\n",
            "Question 395 / 704\n",
            "Question 396 / 704\n",
            "Question 397 / 704\n",
            "Question 398 / 704\n",
            "Question 399 / 704\n",
            "Question 400 / 704\n",
            "Question 401 / 704\n",
            "Question 402 / 704\n",
            "Question 403 / 704\n",
            "Question 404 / 704\n",
            "Question 405 / 704\n",
            "Question 406 / 704\n",
            "Question 407 / 704\n",
            "Question 408 / 704\n",
            "Question 409 / 704\n",
            "Question 410 / 704\n",
            "Question 411 / 704\n",
            "Question 412 / 704\n",
            "Question 413 / 704\n",
            "Question 414 / 704\n",
            "Question 415 / 704\n",
            "Question 416 / 704\n",
            "Question 417 / 704\n",
            "Question 418 / 704\n",
            "Question 419 / 704\n",
            "Question 420 / 704\n",
            "Question 421 / 704\n",
            "Question 422 / 704\n",
            "Question 423 / 704\n",
            "Question 424 / 704\n",
            "Question 425 / 704\n",
            "Question 426 / 704\n",
            "Question 427 / 704\n",
            "Question 428 / 704\n",
            "Question 429 / 704\n",
            "Question 430 / 704\n",
            "Question 431 / 704\n",
            "Question 432 / 704\n",
            "Question 433 / 704\n",
            "Question 434 / 704\n",
            "Question 435 / 704\n",
            "Question 436 / 704\n",
            "Question 437 / 704\n",
            "Question 438 / 704\n",
            "Question 439 / 704\n",
            "Question 440 / 704\n",
            "Question 441 / 704\n",
            "Question 442 / 704\n",
            "Question 443 / 704\n",
            "Question 444 / 704\n",
            "Question 445 / 704\n",
            "Question 446 / 704\n",
            "Question 447 / 704\n",
            "Question 448 / 704\n",
            "Question 449 / 704\n",
            "Question 450 / 704\n",
            "Question 451 / 704\n",
            "Question 452 / 704\n",
            "Question 453 / 704\n",
            "Question 454 / 704\n",
            "Question 455 / 704\n",
            "Question 456 / 704\n",
            "Question 457 / 704\n",
            "Question 458 / 704\n",
            "Question 459 / 704\n",
            "Question 460 / 704\n",
            "Question 461 / 704\n",
            "Question 462 / 704\n",
            "Question 463 / 704\n",
            "Question 464 / 704\n",
            "Question 465 / 704\n",
            "Question 466 / 704\n",
            "Question 467 / 704\n",
            "Question 468 / 704\n",
            "Question 469 / 704\n",
            "Question 470 / 704\n",
            "Question 471 / 704\n",
            "Question 472 / 704\n",
            "Question 473 / 704\n",
            "Question 474 / 704\n",
            "Question 475 / 704\n",
            "Question 476 / 704\n",
            "Question 477 / 704\n",
            "Question 478 / 704\n",
            "Question 479 / 704\n",
            "Question 480 / 704\n",
            "Question 481 / 704\n",
            "Question 482 / 704\n",
            "Question 483 / 704\n",
            "Question 484 / 704\n",
            "Question 485 / 704\n",
            "Question 486 / 704\n",
            "Question 487 / 704\n",
            "Question 488 / 704\n",
            "Question 489 / 704\n",
            "Question 490 / 704\n",
            "Question 491 / 704\n",
            "Question 492 / 704\n",
            "Question 493 / 704\n",
            "Question 494 / 704\n",
            "Question 495 / 704\n",
            "Question 496 / 704\n",
            "Question 497 / 704\n",
            "Question 498 / 704\n",
            "Question 499 / 704\n",
            "Question 500 / 704\n",
            "Question 501 / 704\n",
            "Question 502 / 704\n",
            "Question 503 / 704\n",
            "Question 504 / 704\n",
            "Question 505 / 704\n",
            "Question 506 / 704\n",
            "Question 507 / 704\n",
            "Question 508 / 704\n",
            "Question 509 / 704\n",
            "Question 510 / 704\n",
            "Question 511 / 704\n",
            "Question 512 / 704\n",
            "Question 513 / 704\n",
            "Question 514 / 704\n",
            "Question 515 / 704\n",
            "Question 516 / 704\n",
            "Question 517 / 704\n",
            "Question 518 / 704\n",
            "Question 519 / 704\n",
            "Question 520 / 704\n",
            "Question 521 / 704\n",
            "Question 522 / 704\n",
            "Question 523 / 704\n",
            "Question 524 / 704\n",
            "Question 525 / 704\n",
            "Question 526 / 704\n",
            "Question 527 / 704\n",
            "Question 528 / 704\n",
            "Question 529 / 704\n",
            "Question 530 / 704\n",
            "Question 531 / 704\n",
            "Question 532 / 704\n",
            "Question 533 / 704\n",
            "Question 534 / 704\n",
            "Question 535 / 704\n",
            "Question 536 / 704\n",
            "Question 537 / 704\n",
            "Question 538 / 704\n",
            "Question 539 / 704\n",
            "Question 540 / 704\n",
            "Question 541 / 704\n",
            "Question 542 / 704\n",
            "Question 543 / 704\n",
            "Question 544 / 704\n",
            "Question 545 / 704\n",
            "Question 546 / 704\n",
            "Question 547 / 704\n",
            "Question 548 / 704\n",
            "Question 549 / 704\n",
            "Question 550 / 704\n",
            "Question 551 / 704\n",
            "Question 552 / 704\n",
            "Question 553 / 704\n",
            "Question 554 / 704\n",
            "Question 555 / 704\n",
            "Question 556 / 704\n",
            "Question 557 / 704\n",
            "Question 558 / 704\n",
            "Question 559 / 704\n",
            "Question 560 / 704\n",
            "Question 561 / 704\n",
            "Question 562 / 704\n",
            "Question 563 / 704\n",
            "Question 564 / 704\n",
            "Question 565 / 704\n",
            "Question 566 / 704\n",
            "Question 567 / 704\n",
            "Question 568 / 704\n",
            "Question 569 / 704\n",
            "Question 570 / 704\n",
            "Question 571 / 704\n",
            "Question 572 / 704\n",
            "Question 573 / 704\n",
            "Question 574 / 704\n",
            "Question 575 / 704\n",
            "Question 576 / 704\n",
            "Question 577 / 704\n",
            "Question 578 / 704\n",
            "Question 579 / 704\n",
            "Question 580 / 704\n",
            "Question 581 / 704\n",
            "Question 582 / 704\n",
            "Question 583 / 704\n",
            "Question 584 / 704\n",
            "Question 585 / 704\n",
            "Question 586 / 704\n",
            "Question 587 / 704\n",
            "Question 588 / 704\n",
            "Question 589 / 704\n",
            "Question 590 / 704\n",
            "Question 591 / 704\n",
            "Question 592 / 704\n",
            "Question 593 / 704\n",
            "Question 594 / 704\n",
            "Question 595 / 704\n",
            "Question 596 / 704\n",
            "Question 597 / 704\n",
            "Question 598 / 704\n",
            "Question 599 / 704\n",
            "Question 600 / 704\n",
            "Question 601 / 704\n",
            "Question 602 / 704\n",
            "Question 603 / 704\n",
            "Question 604 / 704\n",
            "Question 605 / 704\n",
            "Question 606 / 704\n",
            "Question 607 / 704\n",
            "Question 608 / 704\n",
            "Question 609 / 704\n",
            "Question 610 / 704\n",
            "Question 611 / 704\n",
            "Question 612 / 704\n",
            "Question 613 / 704\n",
            "Question 614 / 704\n",
            "Question 615 / 704\n",
            "Question 616 / 704\n",
            "Question 617 / 704\n",
            "Question 618 / 704\n",
            "Question 619 / 704\n",
            "Question 620 / 704\n",
            "Question 621 / 704\n",
            "Question 622 / 704\n",
            "Question 623 / 704\n",
            "Question 624 / 704\n",
            "Question 625 / 704\n",
            "Question 626 / 704\n",
            "Question 627 / 704\n",
            "Question 628 / 704\n",
            "Question 629 / 704\n",
            "Question 630 / 704\n",
            "Question 631 / 704\n",
            "Question 632 / 704\n",
            "Question 633 / 704\n",
            "Question 634 / 704\n",
            "Question 635 / 704\n",
            "Question 636 / 704\n",
            "Question 637 / 704\n",
            "Question 638 / 704\n",
            "Question 639 / 704\n",
            "Question 640 / 704\n",
            "Question 641 / 704\n",
            "Question 642 / 704\n",
            "Question 643 / 704\n",
            "Question 644 / 704\n",
            "Question 645 / 704\n",
            "Question 646 / 704\n",
            "Question 647 / 704\n",
            "Question 648 / 704\n",
            "Question 649 / 704\n",
            "Question 650 / 704\n",
            "Question 651 / 704\n",
            "Question 652 / 704\n",
            "Question 653 / 704\n",
            "Question 654 / 704\n",
            "Question 655 / 704\n",
            "Question 656 / 704\n",
            "Question 657 / 704\n",
            "Question 658 / 704\n",
            "Question 659 / 704\n",
            "Question 660 / 704\n",
            "Question 661 / 704\n",
            "Question 662 / 704\n",
            "Question 663 / 704\n",
            "Question 664 / 704\n",
            "Question 665 / 704\n",
            "Question 666 / 704\n",
            "Question 667 / 704\n",
            "Question 668 / 704\n",
            "Question 669 / 704\n",
            "Question 670 / 704\n",
            "Question 671 / 704\n",
            "Question 672 / 704\n",
            "Question 673 / 704\n",
            "Question 674 / 704\n",
            "Question 675 / 704\n",
            "Question 676 / 704\n",
            "Question 677 / 704\n",
            "Question 678 / 704\n",
            "Question 679 / 704\n",
            "Question 680 / 704\n",
            "Question 681 / 704\n",
            "Question 682 / 704\n",
            "Question 683 / 704\n",
            "Question 684 / 704\n",
            "Question 685 / 704\n",
            "Question 686 / 704\n",
            "Question 687 / 704\n",
            "Question 688 / 704\n",
            "Question 689 / 704\n",
            "Question 690 / 704\n",
            "Question 691 / 704\n",
            "Question 692 / 704\n",
            "Question 693 / 704\n",
            "Question 694 / 704\n",
            "Question 695 / 704\n",
            "Question 696 / 704\n",
            "Question 697 / 704\n",
            "Question 698 / 704\n",
            "Question 699 / 704\n",
            "Question 700 / 704\n",
            "Question 701 / 704\n",
            "Question 702 / 704\n",
            "Question 703 / 704\n",
            "Question 704 / 704\n"
          ]
        }
      ],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Evaluation loop\n",
        "num_correct = 0\n",
        "for idx, row in enumerate(test_data):\n",
        "    context = row[\"question\"]\n",
        "    options = row[\"option\"]\n",
        "    correct_option = row[\"answer\"].strip()\n",
        "\n",
        "    # Prepare the inputs\n",
        "    choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=128, padding='max_length', truncation=True) for option in options]\n",
        "\n",
        "    # Get the input tensors and reshape them\n",
        "    input_ids = torch.cat([choice['input_ids'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    attention_mask = torch.cat([choice['attention_mask'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "    # Compute the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Get the predicted option\n",
        "    predicted_option = torch.argmax(outputs.logits).item()\n",
        "\n",
        "    # Check if the prediction is correct\n",
        "    if predicted_option == options.index(correct_option):\n",
        "        num_correct += 1\n",
        "    print(f\"Question {idx + 1} / {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy: {num_correct / len(test_data)}')\n",
        "print(num_correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S_A5Px2RT7G",
        "outputId": "567fa6b2-2d22-4b28-fa38-0e714d8d83e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9048295454545454\n",
            "637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ixLDnaU2E_T"
      },
      "source": [
        "It can be observed that simple problems like TOEIC questions tend to exhibit high accuracy rates although I did only 1 epoch!. Now, we will proceed to train the model on much more complex problems from the Korean national college entrance exam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhVwbRv6ILfN"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuQCu109JUsA"
      },
      "source": [
        "First, we will attempt to solve the test set problems without any training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lpj-IL8cIcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d60fae-110e-49ff-8dfe-b1ddc3f722b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data :  124  test_data :  31\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(sat_data, test_size=0.2, random_state=42)\n",
        "print('train_data : ', len(train_data), ' test_data : ', len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL_-JDN2ZhTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5dd090-f3d8-4fc8-99a1-191c6669bd40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " {'input_ids': tensor([[  101, 18388, 23530,  5408,  1272,  1472,  2114,  1104,  1234,  8942,\n",
              "           3689,  1472,  1734,  1105,  1472, 17238,  1116,  1166,  1103,  1736,\n",
              "           1104,  1159,   119,  1252,  1103,  2304,  2606,  1725,  1343, 23448,\n",
              "           3660,  3483,  1274,   200,   100, 14713,  1254,  1165,  3147,  4757,\n",
              "           1234,  2819,  1149,  1105,  1231,   118,  3232,  1296,  1168,  1120,\n",
              "           4055,  7070,   119,  1370,  5374,   117,  1120,  1103,  2030,  5904,\n",
              "           1206,  1860,  1105,  2870,   117,  1175,  1132,  3129,  4024,  1485,\n",
              "           1528,  4024,   117,  1133,  1103, 12453,  1253,  2936,   170,  1469,\n",
              "           2783,  1104,  1719,  1528,  1137,  1104,  3129,   117,  1897,  1190,\n",
              "            170,  5495,  1104,  1528,  1105,  3129,   119,  2009,  1110,  1115,\n",
              "           1177,   136, 10109,  1103,  1514, 22611,  1104,  3522,   170,  3216,\n",
              "           1846,  6808,   170,  3501,  3053,  1104,  1769,  1846,   131,  1112,\n",
              "           1770,  1112,  1128,  1838,  1106,  2936,  1106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "context = sat_data[\"question\"][0]\n",
        "options = sat_data[\"option\"][0]\n",
        "correct_option = sat_data[\"answer\"][0].strip()\n",
        "\n",
        "# Prepare the inputs\n",
        "choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=128, padding='max_length', truncation=True) for option in options]\n",
        "choices_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCK7U5PCIorY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50666450-ae72-4949-c44b-ef1e18de01eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 82 / 31\n",
            "Question 143 / 31\n",
            "Question 32 / 31\n",
            "Question 30 / 31\n",
            "Question 119 / 31\n",
            "Question 61 / 31\n",
            "Question 94 / 31\n",
            "Question 148 / 31\n",
            "Question 154 / 31\n",
            "Question 69 / 31\n",
            "Question 43 / 31\n",
            "Question 139 / 31\n",
            "Question 79 / 31\n",
            "Question 76 / 31\n",
            "Question 16 / 31\n",
            "Question 20 / 31\n",
            "Question 31 / 31\n",
            "Question 91 / 31\n",
            "Question 118 / 31\n",
            "Question 138 / 31\n",
            "Question 19 / 31\n",
            "Question 13 / 31\n",
            "Question 10 / 31\n",
            "Question 25 / 31\n",
            "Question 70 / 31\n",
            "Question 132 / 31\n",
            "Question 96 / 31\n",
            "Question 46 / 31\n",
            "Question 87 / 31\n",
            "Question 85 / 31\n",
            "Question 127 / 31\n"
          ]
        }
      ],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Evaluation loop\n",
        "num_correct = 0\n",
        "for idx, row in test_data.iterrows():\n",
        "    context = row[\"question\"]\n",
        "    options = row[\"option\"].split(',')  # Assumes options are comma-separated in the CSV\n",
        "    options = [option.strip() for option in options]\n",
        "    correct_option = row[\"answer\"].strip()\n",
        "\n",
        "    # Prepare the inputs\n",
        "    choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=256, padding='max_length', truncation=True) for option in options]\n",
        "\n",
        "    # Get the input tensors and reshape them\n",
        "    input_ids = torch.cat([choice['input_ids'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    attention_mask = torch.cat([choice['attention_mask'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    # Compute the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Get the predicted option\n",
        "    predicted_option = torch.argmax(outputs.logits).item()\n",
        "\n",
        "    # Check if the prediction is correct\n",
        "    if predicted_option == options.index(correct_option):\n",
        "        num_correct += 1\n",
        "    print(f\"Question {idx + 1} / {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wO5QUetJli2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d7c6aa-d472-426a-9526-42bf47c8810f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3548387096774194\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy: {num_correct / len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpXzNzxrJqxg"
      },
      "source": [
        "We can observe that accuracy increases before training for the TOEIC dataset.\n",
        "Now I will train the bert for the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEhW13iwJqPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49ee787-cf76-4d3b-c6c1-560058af9710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Question 97 / 124 for epoch 0\n",
            "Training Question 123 / 124 for epoch 0\n",
            "Training Question 83 / 124 for epoch 0\n",
            "Training Question 110 / 124 for epoch 0\n",
            "Training Question 66 / 124 for epoch 0\n",
            "Training Question 52 / 124 for epoch 0\n",
            "Training Question 27 / 124 for epoch 0\n",
            "Training Question 134 / 124 for epoch 0\n",
            "Training Question 77 / 124 for epoch 0\n",
            "Training Question 57 / 124 for epoch 0\n",
            "Training Question 37 / 124 for epoch 0\n",
            "Training Question 125 / 124 for epoch 0\n",
            "Training Question 23 / 124 for epoch 0\n",
            "Training Question 56 / 124 for epoch 0\n",
            "Training Question 86 / 124 for epoch 0\n",
            "Training Question 12 / 124 for epoch 0\n",
            "Training Question 142 / 124 for epoch 0\n",
            "Training Question 67 / 124 for epoch 0\n",
            "Training Question 120 / 124 for epoch 0\n",
            "Training Question 28 / 124 for epoch 0\n",
            "Training Question 80 / 124 for epoch 0\n",
            "Training Question 145 / 124 for epoch 0\n",
            "Training Question 42 / 124 for epoch 0\n",
            "Training Question 5 / 124 for epoch 0\n",
            "Training Question 33 / 124 for epoch 0\n",
            "Training Question 135 / 124 for epoch 0\n",
            "Training Question 144 / 124 for epoch 0\n",
            "Training Question 68 / 124 for epoch 0\n",
            "Training Question 17 / 124 for epoch 0\n",
            "Training Question 124 / 124 for epoch 0\n",
            "Training Question 11 / 124 for epoch 0\n",
            "Training Question 114 / 124 for epoch 0\n",
            "Training Question 147 / 124 for epoch 0\n",
            "Training Question 102 / 124 for epoch 0\n",
            "Training Question 1 / 124 for epoch 0\n",
            "Training Question 111 / 124 for epoch 0\n",
            "Training Question 65 / 124 for epoch 0\n",
            "Training Question 45 / 124 for epoch 0\n",
            "Training Question 98 / 124 for epoch 0\n",
            "Training Question 29 / 124 for epoch 0\n",
            "Training Question 41 / 124 for epoch 0\n",
            "Training Question 105 / 124 for epoch 0\n",
            "Training Question 26 / 124 for epoch 0\n",
            "Training Question 24 / 124 for epoch 0\n",
            "Training Question 109 / 124 for epoch 0\n",
            "Training Question 40 / 124 for epoch 0\n",
            "Training Question 152 / 124 for epoch 0\n",
            "Training Question 99 / 124 for epoch 0\n",
            "Training Question 151 / 124 for epoch 0\n",
            "Training Question 137 / 124 for epoch 0\n",
            "Training Question 48 / 124 for epoch 0\n",
            "Training Question 112 / 124 for epoch 0\n",
            "Training Question 62 / 124 for epoch 0\n",
            "Training Question 74 / 124 for epoch 0\n",
            "Training Question 34 / 124 for epoch 0\n",
            "Training Question 149 / 124 for epoch 0\n",
            "Training Question 126 / 124 for epoch 0\n",
            "Training Question 63 / 124 for epoch 0\n",
            "Training Question 106 / 124 for epoch 0\n",
            "Training Question 95 / 124 for epoch 0\n",
            "Training Question 54 / 124 for epoch 0\n",
            "Training Question 6 / 124 for epoch 0\n",
            "Training Question 128 / 124 for epoch 0\n",
            "Training Question 115 / 124 for epoch 0\n",
            "Training Question 50 / 124 for epoch 0\n",
            "Training Question 36 / 124 for epoch 0\n",
            "Training Question 81 / 124 for epoch 0\n",
            "Training Question 78 / 124 for epoch 0\n",
            "Training Question 35 / 124 for epoch 0\n",
            "Training Question 47 / 124 for epoch 0\n",
            "Training Question 8 / 124 for epoch 0\n",
            "Training Question 44 / 124 for epoch 0\n",
            "Training Question 71 / 124 for epoch 0\n",
            "Training Question 113 / 124 for epoch 0\n",
            "Training Question 92 / 124 for epoch 0\n",
            "Training Question 84 / 124 for epoch 0\n",
            "Training Question 140 / 124 for epoch 0\n",
            "Training Question 141 / 124 for epoch 0\n",
            "Training Question 90 / 124 for epoch 0\n",
            "Training Question 9 / 124 for epoch 0\n",
            "Training Question 14 / 124 for epoch 0\n",
            "Training Question 60 / 124 for epoch 0\n",
            "Training Question 133 / 124 for epoch 0\n",
            "Training Question 4 / 124 for epoch 0\n",
            "Training Question 18 / 124 for epoch 0\n",
            "Training Question 39 / 124 for epoch 0\n",
            "Training Question 73 / 124 for epoch 0\n",
            "Training Question 136 / 124 for epoch 0\n",
            "Training Question 7 / 124 for epoch 0\n",
            "Training Question 129 / 124 for epoch 0\n",
            "Training Question 101 / 124 for epoch 0\n",
            "Training Question 3 / 124 for epoch 0\n",
            "Training Question 121 / 124 for epoch 0\n",
            "Training Question 64 / 124 for epoch 0\n",
            "Training Question 116 / 124 for epoch 0\n",
            "Training Question 55 / 124 for epoch 0\n",
            "Training Question 108 / 124 for epoch 0\n",
            "Training Question 51 / 124 for epoch 0\n",
            "Training Question 153 / 124 for epoch 0\n",
            "Training Question 59 / 124 for epoch 0\n",
            "Training Question 49 / 124 for epoch 0\n",
            "Training Question 89 / 124 for epoch 0\n",
            "Training Question 22 / 124 for epoch 0\n",
            "Training Question 58 / 124 for epoch 0\n",
            "Training Question 150 / 124 for epoch 0\n",
            "Training Question 130 / 124 for epoch 0\n",
            "Training Question 38 / 124 for epoch 0\n",
            "Training Question 146 / 124 for epoch 0\n",
            "Training Question 2 / 124 for epoch 0\n",
            "Training Question 53 / 124 for epoch 0\n",
            "Training Question 131 / 124 for epoch 0\n",
            "Training Question 104 / 124 for epoch 0\n",
            "Training Question 100 / 124 for epoch 0\n",
            "Training Question 117 / 124 for epoch 0\n",
            "Training Question 88 / 124 for epoch 0\n",
            "Training Question 75 / 124 for epoch 0\n",
            "Training Question 122 / 124 for epoch 0\n",
            "Training Question 155 / 124 for epoch 0\n",
            "Training Question 21 / 124 for epoch 0\n",
            "Training Question 72 / 124 for epoch 0\n",
            "Training Question 107 / 124 for epoch 0\n",
            "Training Question 15 / 124 for epoch 0\n",
            "Training Question 93 / 124 for epoch 0\n",
            "Training Question 103 / 124 for epoch 0\n",
            "Training Question 97 / 124 for epoch 1\n",
            "Training Question 123 / 124 for epoch 1\n",
            "Training Question 83 / 124 for epoch 1\n",
            "Training Question 110 / 124 for epoch 1\n",
            "Training Question 66 / 124 for epoch 1\n",
            "Training Question 52 / 124 for epoch 1\n",
            "Training Question 27 / 124 for epoch 1\n",
            "Training Question 134 / 124 for epoch 1\n",
            "Training Question 77 / 124 for epoch 1\n",
            "Training Question 57 / 124 for epoch 1\n",
            "Training Question 37 / 124 for epoch 1\n",
            "Training Question 125 / 124 for epoch 1\n",
            "Training Question 23 / 124 for epoch 1\n",
            "Training Question 56 / 124 for epoch 1\n",
            "Training Question 86 / 124 for epoch 1\n",
            "Training Question 12 / 124 for epoch 1\n",
            "Training Question 142 / 124 for epoch 1\n",
            "Training Question 67 / 124 for epoch 1\n",
            "Training Question 120 / 124 for epoch 1\n",
            "Training Question 28 / 124 for epoch 1\n",
            "Training Question 80 / 124 for epoch 1\n",
            "Training Question 145 / 124 for epoch 1\n",
            "Training Question 42 / 124 for epoch 1\n",
            "Training Question 5 / 124 for epoch 1\n",
            "Training Question 33 / 124 for epoch 1\n",
            "Training Question 135 / 124 for epoch 1\n",
            "Training Question 144 / 124 for epoch 1\n",
            "Training Question 68 / 124 for epoch 1\n",
            "Training Question 17 / 124 for epoch 1\n",
            "Training Question 124 / 124 for epoch 1\n",
            "Training Question 11 / 124 for epoch 1\n",
            "Training Question 114 / 124 for epoch 1\n",
            "Training Question 147 / 124 for epoch 1\n",
            "Training Question 102 / 124 for epoch 1\n",
            "Training Question 1 / 124 for epoch 1\n",
            "Training Question 111 / 124 for epoch 1\n",
            "Training Question 65 / 124 for epoch 1\n",
            "Training Question 45 / 124 for epoch 1\n",
            "Training Question 98 / 124 for epoch 1\n",
            "Training Question 29 / 124 for epoch 1\n",
            "Training Question 41 / 124 for epoch 1\n",
            "Training Question 105 / 124 for epoch 1\n",
            "Training Question 26 / 124 for epoch 1\n",
            "Training Question 24 / 124 for epoch 1\n",
            "Training Question 109 / 124 for epoch 1\n",
            "Training Question 40 / 124 for epoch 1\n",
            "Training Question 152 / 124 for epoch 1\n",
            "Training Question 99 / 124 for epoch 1\n",
            "Training Question 151 / 124 for epoch 1\n",
            "Training Question 137 / 124 for epoch 1\n",
            "Training Question 48 / 124 for epoch 1\n",
            "Training Question 112 / 124 for epoch 1\n",
            "Training Question 62 / 124 for epoch 1\n",
            "Training Question 74 / 124 for epoch 1\n",
            "Training Question 34 / 124 for epoch 1\n",
            "Training Question 149 / 124 for epoch 1\n",
            "Training Question 126 / 124 for epoch 1\n",
            "Training Question 63 / 124 for epoch 1\n",
            "Training Question 106 / 124 for epoch 1\n",
            "Training Question 95 / 124 for epoch 1\n",
            "Training Question 54 / 124 for epoch 1\n",
            "Training Question 6 / 124 for epoch 1\n",
            "Training Question 128 / 124 for epoch 1\n",
            "Training Question 115 / 124 for epoch 1\n",
            "Training Question 50 / 124 for epoch 1\n",
            "Training Question 36 / 124 for epoch 1\n",
            "Training Question 81 / 124 for epoch 1\n",
            "Training Question 78 / 124 for epoch 1\n",
            "Training Question 35 / 124 for epoch 1\n",
            "Training Question 47 / 124 for epoch 1\n",
            "Training Question 8 / 124 for epoch 1\n",
            "Training Question 44 / 124 for epoch 1\n",
            "Training Question 71 / 124 for epoch 1\n",
            "Training Question 113 / 124 for epoch 1\n",
            "Training Question 92 / 124 for epoch 1\n",
            "Training Question 84 / 124 for epoch 1\n",
            "Training Question 140 / 124 for epoch 1\n",
            "Training Question 141 / 124 for epoch 1\n",
            "Training Question 90 / 124 for epoch 1\n",
            "Training Question 9 / 124 for epoch 1\n",
            "Training Question 14 / 124 for epoch 1\n",
            "Training Question 60 / 124 for epoch 1\n",
            "Training Question 133 / 124 for epoch 1\n",
            "Training Question 4 / 124 for epoch 1\n",
            "Training Question 18 / 124 for epoch 1\n",
            "Training Question 39 / 124 for epoch 1\n",
            "Training Question 73 / 124 for epoch 1\n",
            "Training Question 136 / 124 for epoch 1\n",
            "Training Question 7 / 124 for epoch 1\n",
            "Training Question 129 / 124 for epoch 1\n",
            "Training Question 101 / 124 for epoch 1\n",
            "Training Question 3 / 124 for epoch 1\n",
            "Training Question 121 / 124 for epoch 1\n",
            "Training Question 64 / 124 for epoch 1\n",
            "Training Question 116 / 124 for epoch 1\n",
            "Training Question 55 / 124 for epoch 1\n",
            "Training Question 108 / 124 for epoch 1\n",
            "Training Question 51 / 124 for epoch 1\n",
            "Training Question 153 / 124 for epoch 1\n",
            "Training Question 59 / 124 for epoch 1\n",
            "Training Question 49 / 124 for epoch 1\n",
            "Training Question 89 / 124 for epoch 1\n",
            "Training Question 22 / 124 for epoch 1\n",
            "Training Question 58 / 124 for epoch 1\n",
            "Training Question 150 / 124 for epoch 1\n",
            "Training Question 130 / 124 for epoch 1\n",
            "Training Question 38 / 124 for epoch 1\n",
            "Training Question 146 / 124 for epoch 1\n",
            "Training Question 2 / 124 for epoch 1\n",
            "Training Question 53 / 124 for epoch 1\n",
            "Training Question 131 / 124 for epoch 1\n",
            "Training Question 104 / 124 for epoch 1\n",
            "Training Question 100 / 124 for epoch 1\n",
            "Training Question 117 / 124 for epoch 1\n",
            "Training Question 88 / 124 for epoch 1\n",
            "Training Question 75 / 124 for epoch 1\n",
            "Training Question 122 / 124 for epoch 1\n",
            "Training Question 155 / 124 for epoch 1\n",
            "Training Question 21 / 124 for epoch 1\n",
            "Training Question 72 / 124 for epoch 1\n",
            "Training Question 107 / 124 for epoch 1\n",
            "Training Question 15 / 124 for epoch 1\n",
            "Training Question 93 / 124 for epoch 1\n",
            "Training Question 103 / 124 for epoch 1\n",
            "Training Question 97 / 124 for epoch 2\n",
            "Training Question 123 / 124 for epoch 2\n",
            "Training Question 83 / 124 for epoch 2\n",
            "Training Question 110 / 124 for epoch 2\n",
            "Training Question 66 / 124 for epoch 2\n",
            "Training Question 52 / 124 for epoch 2\n",
            "Training Question 27 / 124 for epoch 2\n",
            "Training Question 134 / 124 for epoch 2\n",
            "Training Question 77 / 124 for epoch 2\n",
            "Training Question 57 / 124 for epoch 2\n",
            "Training Question 37 / 124 for epoch 2\n",
            "Training Question 125 / 124 for epoch 2\n",
            "Training Question 23 / 124 for epoch 2\n",
            "Training Question 56 / 124 for epoch 2\n",
            "Training Question 86 / 124 for epoch 2\n",
            "Training Question 12 / 124 for epoch 2\n",
            "Training Question 142 / 124 for epoch 2\n",
            "Training Question 67 / 124 for epoch 2\n",
            "Training Question 120 / 124 for epoch 2\n",
            "Training Question 28 / 124 for epoch 2\n",
            "Training Question 80 / 124 for epoch 2\n",
            "Training Question 145 / 124 for epoch 2\n",
            "Training Question 42 / 124 for epoch 2\n",
            "Training Question 5 / 124 for epoch 2\n",
            "Training Question 33 / 124 for epoch 2\n",
            "Training Question 135 / 124 for epoch 2\n",
            "Training Question 144 / 124 for epoch 2\n",
            "Training Question 68 / 124 for epoch 2\n",
            "Training Question 17 / 124 for epoch 2\n",
            "Training Question 124 / 124 for epoch 2\n",
            "Training Question 11 / 124 for epoch 2\n",
            "Training Question 114 / 124 for epoch 2\n",
            "Training Question 147 / 124 for epoch 2\n",
            "Training Question 102 / 124 for epoch 2\n",
            "Training Question 1 / 124 for epoch 2\n",
            "Training Question 111 / 124 for epoch 2\n",
            "Training Question 65 / 124 for epoch 2\n",
            "Training Question 45 / 124 for epoch 2\n",
            "Training Question 98 / 124 for epoch 2\n",
            "Training Question 29 / 124 for epoch 2\n",
            "Training Question 41 / 124 for epoch 2\n",
            "Training Question 105 / 124 for epoch 2\n",
            "Training Question 26 / 124 for epoch 2\n",
            "Training Question 24 / 124 for epoch 2\n",
            "Training Question 109 / 124 for epoch 2\n",
            "Training Question 40 / 124 for epoch 2\n",
            "Training Question 152 / 124 for epoch 2\n",
            "Training Question 99 / 124 for epoch 2\n",
            "Training Question 151 / 124 for epoch 2\n",
            "Training Question 137 / 124 for epoch 2\n",
            "Training Question 48 / 124 for epoch 2\n",
            "Training Question 112 / 124 for epoch 2\n",
            "Training Question 62 / 124 for epoch 2\n",
            "Training Question 74 / 124 for epoch 2\n",
            "Training Question 34 / 124 for epoch 2\n",
            "Training Question 149 / 124 for epoch 2\n",
            "Training Question 126 / 124 for epoch 2\n",
            "Training Question 63 / 124 for epoch 2\n",
            "Training Question 106 / 124 for epoch 2\n",
            "Training Question 95 / 124 for epoch 2\n",
            "Training Question 54 / 124 for epoch 2\n",
            "Training Question 6 / 124 for epoch 2\n",
            "Training Question 128 / 124 for epoch 2\n",
            "Training Question 115 / 124 for epoch 2\n",
            "Training Question 50 / 124 for epoch 2\n",
            "Training Question 36 / 124 for epoch 2\n",
            "Training Question 81 / 124 for epoch 2\n",
            "Training Question 78 / 124 for epoch 2\n",
            "Training Question 35 / 124 for epoch 2\n",
            "Training Question 47 / 124 for epoch 2\n",
            "Training Question 8 / 124 for epoch 2\n",
            "Training Question 44 / 124 for epoch 2\n",
            "Training Question 71 / 124 for epoch 2\n",
            "Training Question 113 / 124 for epoch 2\n",
            "Training Question 92 / 124 for epoch 2\n",
            "Training Question 84 / 124 for epoch 2\n",
            "Training Question 140 / 124 for epoch 2\n",
            "Training Question 141 / 124 for epoch 2\n",
            "Training Question 90 / 124 for epoch 2\n",
            "Training Question 9 / 124 for epoch 2\n",
            "Training Question 14 / 124 for epoch 2\n",
            "Training Question 60 / 124 for epoch 2\n",
            "Training Question 133 / 124 for epoch 2\n",
            "Training Question 4 / 124 for epoch 2\n",
            "Training Question 18 / 124 for epoch 2\n",
            "Training Question 39 / 124 for epoch 2\n",
            "Training Question 73 / 124 for epoch 2\n",
            "Training Question 136 / 124 for epoch 2\n",
            "Training Question 7 / 124 for epoch 2\n",
            "Training Question 129 / 124 for epoch 2\n",
            "Training Question 101 / 124 for epoch 2\n",
            "Training Question 3 / 124 for epoch 2\n",
            "Training Question 121 / 124 for epoch 2\n",
            "Training Question 64 / 124 for epoch 2\n",
            "Training Question 116 / 124 for epoch 2\n",
            "Training Question 55 / 124 for epoch 2\n",
            "Training Question 108 / 124 for epoch 2\n",
            "Training Question 51 / 124 for epoch 2\n",
            "Training Question 153 / 124 for epoch 2\n",
            "Training Question 59 / 124 for epoch 2\n",
            "Training Question 49 / 124 for epoch 2\n",
            "Training Question 89 / 124 for epoch 2\n",
            "Training Question 22 / 124 for epoch 2\n",
            "Training Question 58 / 124 for epoch 2\n",
            "Training Question 150 / 124 for epoch 2\n",
            "Training Question 130 / 124 for epoch 2\n",
            "Training Question 38 / 124 for epoch 2\n",
            "Training Question 146 / 124 for epoch 2\n",
            "Training Question 2 / 124 for epoch 2\n",
            "Training Question 53 / 124 for epoch 2\n",
            "Training Question 131 / 124 for epoch 2\n",
            "Training Question 104 / 124 for epoch 2\n",
            "Training Question 100 / 124 for epoch 2\n",
            "Training Question 117 / 124 for epoch 2\n",
            "Training Question 88 / 124 for epoch 2\n",
            "Training Question 75 / 124 for epoch 2\n",
            "Training Question 122 / 124 for epoch 2\n",
            "Training Question 155 / 124 for epoch 2\n",
            "Training Question 21 / 124 for epoch 2\n",
            "Training Question 72 / 124 for epoch 2\n",
            "Training Question 107 / 124 for epoch 2\n",
            "Training Question 15 / 124 for epoch 2\n",
            "Training Question 93 / 124 for epoch 2\n",
            "Training Question 103 / 124 for epoch 2\n",
            "Training Question 97 / 124 for epoch 3\n",
            "Training Question 123 / 124 for epoch 3\n",
            "Training Question 83 / 124 for epoch 3\n",
            "Training Question 110 / 124 for epoch 3\n",
            "Training Question 66 / 124 for epoch 3\n",
            "Training Question 52 / 124 for epoch 3\n",
            "Training Question 27 / 124 for epoch 3\n",
            "Training Question 134 / 124 for epoch 3\n",
            "Training Question 77 / 124 for epoch 3\n",
            "Training Question 57 / 124 for epoch 3\n",
            "Training Question 37 / 124 for epoch 3\n",
            "Training Question 125 / 124 for epoch 3\n",
            "Training Question 23 / 124 for epoch 3\n",
            "Training Question 56 / 124 for epoch 3\n",
            "Training Question 86 / 124 for epoch 3\n",
            "Training Question 12 / 124 for epoch 3\n",
            "Training Question 142 / 124 for epoch 3\n",
            "Training Question 67 / 124 for epoch 3\n",
            "Training Question 120 / 124 for epoch 3\n",
            "Training Question 28 / 124 for epoch 3\n",
            "Training Question 80 / 124 for epoch 3\n",
            "Training Question 145 / 124 for epoch 3\n",
            "Training Question 42 / 124 for epoch 3\n",
            "Training Question 5 / 124 for epoch 3\n",
            "Training Question 33 / 124 for epoch 3\n",
            "Training Question 135 / 124 for epoch 3\n",
            "Training Question 144 / 124 for epoch 3\n",
            "Training Question 68 / 124 for epoch 3\n",
            "Training Question 17 / 124 for epoch 3\n",
            "Training Question 124 / 124 for epoch 3\n",
            "Training Question 11 / 124 for epoch 3\n",
            "Training Question 114 / 124 for epoch 3\n",
            "Training Question 147 / 124 for epoch 3\n",
            "Training Question 102 / 124 for epoch 3\n",
            "Training Question 1 / 124 for epoch 3\n",
            "Training Question 111 / 124 for epoch 3\n",
            "Training Question 65 / 124 for epoch 3\n",
            "Training Question 45 / 124 for epoch 3\n",
            "Training Question 98 / 124 for epoch 3\n",
            "Training Question 29 / 124 for epoch 3\n",
            "Training Question 41 / 124 for epoch 3\n",
            "Training Question 105 / 124 for epoch 3\n",
            "Training Question 26 / 124 for epoch 3\n",
            "Training Question 24 / 124 for epoch 3\n",
            "Training Question 109 / 124 for epoch 3\n",
            "Training Question 40 / 124 for epoch 3\n",
            "Training Question 152 / 124 for epoch 3\n",
            "Training Question 99 / 124 for epoch 3\n",
            "Training Question 151 / 124 for epoch 3\n",
            "Training Question 137 / 124 for epoch 3\n",
            "Training Question 48 / 124 for epoch 3\n",
            "Training Question 112 / 124 for epoch 3\n",
            "Training Question 62 / 124 for epoch 3\n",
            "Training Question 74 / 124 for epoch 3\n",
            "Training Question 34 / 124 for epoch 3\n",
            "Training Question 149 / 124 for epoch 3\n",
            "Training Question 126 / 124 for epoch 3\n",
            "Training Question 63 / 124 for epoch 3\n",
            "Training Question 106 / 124 for epoch 3\n",
            "Training Question 95 / 124 for epoch 3\n",
            "Training Question 54 / 124 for epoch 3\n",
            "Training Question 6 / 124 for epoch 3\n",
            "Training Question 128 / 124 for epoch 3\n",
            "Training Question 115 / 124 for epoch 3\n",
            "Training Question 50 / 124 for epoch 3\n",
            "Training Question 36 / 124 for epoch 3\n",
            "Training Question 81 / 124 for epoch 3\n",
            "Training Question 78 / 124 for epoch 3\n",
            "Training Question 35 / 124 for epoch 3\n",
            "Training Question 47 / 124 for epoch 3\n",
            "Training Question 8 / 124 for epoch 3\n",
            "Training Question 44 / 124 for epoch 3\n",
            "Training Question 71 / 124 for epoch 3\n",
            "Training Question 113 / 124 for epoch 3\n",
            "Training Question 92 / 124 for epoch 3\n",
            "Training Question 84 / 124 for epoch 3\n",
            "Training Question 140 / 124 for epoch 3\n",
            "Training Question 141 / 124 for epoch 3\n",
            "Training Question 90 / 124 for epoch 3\n",
            "Training Question 9 / 124 for epoch 3\n",
            "Training Question 14 / 124 for epoch 3\n",
            "Training Question 60 / 124 for epoch 3\n",
            "Training Question 133 / 124 for epoch 3\n",
            "Training Question 4 / 124 for epoch 3\n",
            "Training Question 18 / 124 for epoch 3\n",
            "Training Question 39 / 124 for epoch 3\n",
            "Training Question 73 / 124 for epoch 3\n",
            "Training Question 136 / 124 for epoch 3\n",
            "Training Question 7 / 124 for epoch 3\n",
            "Training Question 129 / 124 for epoch 3\n",
            "Training Question 101 / 124 for epoch 3\n",
            "Training Question 3 / 124 for epoch 3\n",
            "Training Question 121 / 124 for epoch 3\n",
            "Training Question 64 / 124 for epoch 3\n",
            "Training Question 116 / 124 for epoch 3\n",
            "Training Question 55 / 124 for epoch 3\n",
            "Training Question 108 / 124 for epoch 3\n",
            "Training Question 51 / 124 for epoch 3\n",
            "Training Question 153 / 124 for epoch 3\n",
            "Training Question 59 / 124 for epoch 3\n",
            "Training Question 49 / 124 for epoch 3\n",
            "Training Question 89 / 124 for epoch 3\n",
            "Training Question 22 / 124 for epoch 3\n",
            "Training Question 58 / 124 for epoch 3\n",
            "Training Question 150 / 124 for epoch 3\n",
            "Training Question 130 / 124 for epoch 3\n",
            "Training Question 38 / 124 for epoch 3\n",
            "Training Question 146 / 124 for epoch 3\n",
            "Training Question 2 / 124 for epoch 3\n",
            "Training Question 53 / 124 for epoch 3\n",
            "Training Question 131 / 124 for epoch 3\n",
            "Training Question 104 / 124 for epoch 3\n",
            "Training Question 100 / 124 for epoch 3\n",
            "Training Question 117 / 124 for epoch 3\n",
            "Training Question 88 / 124 for epoch 3\n",
            "Training Question 75 / 124 for epoch 3\n",
            "Training Question 122 / 124 for epoch 3\n",
            "Training Question 155 / 124 for epoch 3\n",
            "Training Question 21 / 124 for epoch 3\n",
            "Training Question 72 / 124 for epoch 3\n",
            "Training Question 107 / 124 for epoch 3\n",
            "Training Question 15 / 124 for epoch 3\n",
            "Training Question 93 / 124 for epoch 3\n",
            "Training Question 103 / 124 for epoch 3\n",
            "Training Question 97 / 124 for epoch 4\n",
            "Training Question 123 / 124 for epoch 4\n",
            "Training Question 83 / 124 for epoch 4\n",
            "Training Question 110 / 124 for epoch 4\n",
            "Training Question 66 / 124 for epoch 4\n",
            "Training Question 52 / 124 for epoch 4\n",
            "Training Question 27 / 124 for epoch 4\n",
            "Training Question 134 / 124 for epoch 4\n",
            "Training Question 77 / 124 for epoch 4\n",
            "Training Question 57 / 124 for epoch 4\n",
            "Training Question 37 / 124 for epoch 4\n",
            "Training Question 125 / 124 for epoch 4\n",
            "Training Question 23 / 124 for epoch 4\n",
            "Training Question 56 / 124 for epoch 4\n",
            "Training Question 86 / 124 for epoch 4\n",
            "Training Question 12 / 124 for epoch 4\n",
            "Training Question 142 / 124 for epoch 4\n",
            "Training Question 67 / 124 for epoch 4\n",
            "Training Question 120 / 124 for epoch 4\n",
            "Training Question 28 / 124 for epoch 4\n",
            "Training Question 80 / 124 for epoch 4\n",
            "Training Question 145 / 124 for epoch 4\n",
            "Training Question 42 / 124 for epoch 4\n",
            "Training Question 5 / 124 for epoch 4\n",
            "Training Question 33 / 124 for epoch 4\n",
            "Training Question 135 / 124 for epoch 4\n",
            "Training Question 144 / 124 for epoch 4\n",
            "Training Question 68 / 124 for epoch 4\n",
            "Training Question 17 / 124 for epoch 4\n",
            "Training Question 124 / 124 for epoch 4\n",
            "Training Question 11 / 124 for epoch 4\n",
            "Training Question 114 / 124 for epoch 4\n",
            "Training Question 147 / 124 for epoch 4\n",
            "Training Question 102 / 124 for epoch 4\n",
            "Training Question 1 / 124 for epoch 4\n",
            "Training Question 111 / 124 for epoch 4\n",
            "Training Question 65 / 124 for epoch 4\n",
            "Training Question 45 / 124 for epoch 4\n",
            "Training Question 98 / 124 for epoch 4\n",
            "Training Question 29 / 124 for epoch 4\n",
            "Training Question 41 / 124 for epoch 4\n",
            "Training Question 105 / 124 for epoch 4\n",
            "Training Question 26 / 124 for epoch 4\n",
            "Training Question 24 / 124 for epoch 4\n",
            "Training Question 109 / 124 for epoch 4\n",
            "Training Question 40 / 124 for epoch 4\n",
            "Training Question 152 / 124 for epoch 4\n",
            "Training Question 99 / 124 for epoch 4\n",
            "Training Question 151 / 124 for epoch 4\n",
            "Training Question 137 / 124 for epoch 4\n",
            "Training Question 48 / 124 for epoch 4\n",
            "Training Question 112 / 124 for epoch 4\n",
            "Training Question 62 / 124 for epoch 4\n",
            "Training Question 74 / 124 for epoch 4\n",
            "Training Question 34 / 124 for epoch 4\n",
            "Training Question 149 / 124 for epoch 4\n",
            "Training Question 126 / 124 for epoch 4\n",
            "Training Question 63 / 124 for epoch 4\n",
            "Training Question 106 / 124 for epoch 4\n",
            "Training Question 95 / 124 for epoch 4\n",
            "Training Question 54 / 124 for epoch 4\n",
            "Training Question 6 / 124 for epoch 4\n",
            "Training Question 128 / 124 for epoch 4\n",
            "Training Question 115 / 124 for epoch 4\n",
            "Training Question 50 / 124 for epoch 4\n",
            "Training Question 36 / 124 for epoch 4\n",
            "Training Question 81 / 124 for epoch 4\n",
            "Training Question 78 / 124 for epoch 4\n",
            "Training Question 35 / 124 for epoch 4\n",
            "Training Question 47 / 124 for epoch 4\n",
            "Training Question 8 / 124 for epoch 4\n",
            "Training Question 44 / 124 for epoch 4\n",
            "Training Question 71 / 124 for epoch 4\n",
            "Training Question 113 / 124 for epoch 4\n",
            "Training Question 92 / 124 for epoch 4\n",
            "Training Question 84 / 124 for epoch 4\n",
            "Training Question 140 / 124 for epoch 4\n",
            "Training Question 141 / 124 for epoch 4\n",
            "Training Question 90 / 124 for epoch 4\n",
            "Training Question 9 / 124 for epoch 4\n",
            "Training Question 14 / 124 for epoch 4\n",
            "Training Question 60 / 124 for epoch 4\n",
            "Training Question 133 / 124 for epoch 4\n",
            "Training Question 4 / 124 for epoch 4\n",
            "Training Question 18 / 124 for epoch 4\n",
            "Training Question 39 / 124 for epoch 4\n",
            "Training Question 73 / 124 for epoch 4\n",
            "Training Question 136 / 124 for epoch 4\n",
            "Training Question 7 / 124 for epoch 4\n",
            "Training Question 129 / 124 for epoch 4\n",
            "Training Question 101 / 124 for epoch 4\n",
            "Training Question 3 / 124 for epoch 4\n",
            "Training Question 121 / 124 for epoch 4\n",
            "Training Question 64 / 124 for epoch 4\n",
            "Training Question 116 / 124 for epoch 4\n",
            "Training Question 55 / 124 for epoch 4\n",
            "Training Question 108 / 124 for epoch 4\n",
            "Training Question 51 / 124 for epoch 4\n",
            "Training Question 153 / 124 for epoch 4\n",
            "Training Question 59 / 124 for epoch 4\n",
            "Training Question 49 / 124 for epoch 4\n",
            "Training Question 89 / 124 for epoch 4\n",
            "Training Question 22 / 124 for epoch 4\n",
            "Training Question 58 / 124 for epoch 4\n",
            "Training Question 150 / 124 for epoch 4\n",
            "Training Question 130 / 124 for epoch 4\n",
            "Training Question 38 / 124 for epoch 4\n",
            "Training Question 146 / 124 for epoch 4\n",
            "Training Question 2 / 124 for epoch 4\n",
            "Training Question 53 / 124 for epoch 4\n",
            "Training Question 131 / 124 for epoch 4\n",
            "Training Question 104 / 124 for epoch 4\n",
            "Training Question 100 / 124 for epoch 4\n",
            "Training Question 117 / 124 for epoch 4\n",
            "Training Question 88 / 124 for epoch 4\n",
            "Training Question 75 / 124 for epoch 4\n",
            "Training Question 122 / 124 for epoch 4\n",
            "Training Question 155 / 124 for epoch 4\n",
            "Training Question 21 / 124 for epoch 4\n",
            "Training Question 72 / 124 for epoch 4\n",
            "Training Question 107 / 124 for epoch 4\n",
            "Training Question 15 / 124 for epoch 4\n",
            "Training Question 93 / 124 for epoch 4\n",
            "Training Question 103 / 124 for epoch 4\n"
          ]
        }
      ],
      "source": [
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Set the model to training mode\n",
        "model.train()\n",
        "\n",
        "num_epochs = 5\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "  for idx, row in train_data.iterrows():\n",
        "      print(f\"Training Question {idx + 1} / {len(train_data)} for epoch {epoch}\")\n",
        "      context = row[\"question\"]\n",
        "      options = row[\"option\"].split(',')  # Assumes options are comma-separated in the CSV\n",
        "      options = [option.strip() for option in options]\n",
        "      #print(row['answer'])\n",
        "      correct_option = row[\"answer\"].strip()\n",
        "\n",
        "      # Prepare the inputs\n",
        "      choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=256, padding='max_length', truncation=True) for option in options]\n",
        "\n",
        "      # Get the input tensors and reshape them\n",
        "      input_ids = torch.cat([choice['input_ids'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "      attention_mask = torch.cat([choice['attention_mask'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "      input_ids = input_ids.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "\n",
        "      # Compute the model outputs\n",
        "      correct_option_idx = options.index(correct_option)\n",
        "      correct_option_idx = torch.tensor([correct_option_idx]).to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=correct_option_idx)\n",
        "\n",
        "      # Compute the loss\n",
        "      loss = outputs.loss\n",
        "\n",
        "      # Backward pass and optimization\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ1J5zH9Jy_C"
      },
      "source": [
        "Now check the accuracy for the test set after training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TewH2aYpJyUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ceb2515-ad2d-41b0-d1e8-c5d02c518bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The male stickleback fish builds a nest for its eggs. He makes the nest out of water plants and sticks. He makes it in the shape of a barrel and uses a thread-like material from his body to glue the nest together. When the nest is ready, the female fish comes. Once a female stickleback¡¯s job of laying egg is done, she doesn¡¯t return to the nest or see her young again. The male stickleback, however, has more work to do. Besides nest building, his job is to watch over the eggs. For two weeks, the male guards his nest fiercely. He fans oxygen-filled water through the tunnel of the barrel with his fins and repairs any damage to his nest. Protecting this nest is a full-time job, so he doesn¡¯t leave the nest. If other sea animals try to eat the baby sticklebacks, he fights them. He keeps the baby fish safe until they can care for themselves. The stickleback male is ___.\n",
            "0    a good father\n",
            "1    a private doctor\n",
            "2    a lazy worker\n",
            "3    an unskilled builder\n",
            "4    a stupid soldier\n",
            "Predicted Answer =>  a good father\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "Reading seems to be an important activity that helps teenagers secure a good ___. Some researchers from Oxford University studied 17,000 people all born in the same week in May, 1970. They are now grown up and in their early 40s and the sociological study has tracked their progress through time. At the age of 16, in 1986, they were asked which activities they did in their spare time for pleasure. These answers were then checked against what they were engaged in at the age of 33, in 2003. The researchers found that there was a 39 percent probability that girls would be in professional or managerial posts at 33 if they had read books at 16, but only a 25 percent chance if they had not. For boys the figures rose from 48 percent to 58 percent if they read books.\n",
            "0    job\n",
            "1    habit\n",
            "2    attitude\n",
            "3    education\n",
            "4    relationship\n",
            "Predicted Answer =>  job\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "Once a hand or gripper has been directed to an object by reaching, it can be grasped. Grasping requires that fingers hold an object securely. A secure grip is one in which the object won¡¯t slip or move, especially when displaced by an external force. Your grasp on a hammer, for example, would not be secure if knocking against something caused you to drop it. One precondition of a firm grasp is that the forces applied by the fingers balance each other so as not to disturb the object¡¯s position. The characteristics of an object such as its geometric configuration and mass distribution may demand that some fingers apply greater force than others to maintain ___. The grasp and support forces must also match overall object mass and fragility. An egg requires a more delicate touch than a rock. \n",
            "0    distance\n",
            "1    efficiency\n",
            "2    mobility\n",
            "3    direction\n",
            "4    stability\n",
            "Predicted Answer =>  stability\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "For any product, the last step of the recycling process is selling the new product. Unfortunately, it can be hard to find markets for some types of recyclables. Plastic companies generally prefer new plastic, ___, because it is of more consistent quality than recycled plastic. The new plastic is guaranteed to be free of incompatible polymers ¡ª the chemical from which plastics are made ¡ª that sometimes are mixed in when the plastic is not sorted well before recycling. Manufacturers say it is also easier to control the color of plastics that have no recycled content. Similarly, paper manufacturers complain that recycled paper often gets dirty during collection and sorting. The added expense of cleaning the paper makes it too expensive to use for some purposes.\n",
            "0    for instance\n",
            "1    therefore\n",
            "2    however\n",
            "3    instead\n",
            "4    in contrast\n",
            "Predicted Answer =>  for instance\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "Bullying is any behavior that hurts or is violent toward another person. It may be verbal or physical. While it is often considered to be simply \"normal kid stuff,\" it can severely damage the emotional health of the victim. Children often don't tell anyone because of fear of what may happen. It is essential that parents talk to their children on a regular basis about not only their schoolwork and friends but also their safety. Parents should ask their children direct questions about what's going on at school and how they feel about it. If parents have ongoing ___ with their children, when big issues come up, their sons and daughters will feel safe talking to them about their problems. Create a safe, loving environment in which kids can talk.\n",
            "0    communication\n",
            "1    disconnection\n",
            "2    conflicts\n",
            "3    exercise\n",
            "4    tension\n",
            "Predicted Answer =>  communication\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "It is easy to find examples of correlations which are far more systematic than could occur by chance and yet which it would be absurd to treat as evidence of a direct causal link. For instance, there is a high degree of correlation between shoe size and vocabulary size: people with larger shoe sizes tend to have much larger vocabularies than people with smaller shoe sizes. But having larger feet does not cause anyone to gain a larger vocabulary; nor does having a large vocabulary cause your feet to grow. The obvious explanation of the correlation is that children tend to have much smaller feet than adults, and, because children acquire their vocabularies gradually as they grow older, it is hardly surprising that, on average, people with smaller feet have smaller vocabularies. In other words, foot size and vocabulary size can be explained in terms of ___ from infancy to adulthood: a cause which both observed phenomena have in common. \n",
            "0    by-products of language acquisition\n",
            "1    causal links between uncommon events\n",
            "2    contrasts between physical and mental growth\n",
            "3    cultural beliefs derived from social interactions\n",
            "4    features of the process of human development\n",
            "Predicted Answer =>  features of the process of human development\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "A contributing factor to the growth of a fire service organization is ___. Unfortunately, some states do not recognize the need to increase fire department resources until a great loss is experienced as a result of inadequate fire protection. Significant fire losses of property, such as residential areas, million-dollar mansions, historical structures, and valuable wildlands, draw a lot of attention to fire protection needs. The losses associated with inadequate fire protection for major employers and contributors to the local economy generate incentives to support fire protection services. In the worst-case scenario, the citizens' deaths or the line-of-duty deaths of fire fighters resulting from inadequate fire protection will be needed to prompt community leaders to take innovative approaches for fund increases of fire department resources.\n",
            "0    community loss\n",
            "1    climate change\n",
            "2    tax revenue increase\n",
            "3    population growth\n",
            "4    technological advance\n",
            "Predicted Answer =>  community loss\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "Dozens of studies have demonstrated the ___ nature of self-supervision. For instance, people who were asked to make tricky choices and trade-offs¡ªsuch as setting up a wedding registry or ordering a new computer¡ªwere worse at focusing and solving problems than others who had not made the tough choices. In one study, some people were asked to restrain their emotions while watching a sad movie about sick animals. Afterward, they exhibited less physical endurance than others who had let the tears flow freely. The research shows that we burn up self-control in a wide variety of situations: managing the impression we are making on others; coping with fears; controlling our spending; trying to focus on simple instructions such as \"Don't think of a white bear\"; and many, many others.\n",
            "0    nurturing\n",
            "1    hesitating\n",
            "2    rewarding\n",
            "3    misleading\n",
            "4    exhausting\n",
            "Predicted Answer =>  exhausting\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "A sleeping mother has the ability to identify the particular cry of her own baby. This is one of the bonding factors that has been forgotten because of the way in which we live today. Typically, there is now only one newborn baby in any family house or apartment, so there is no way to test this ability. In an ancient tribe, however, living in small huts in a tiny village settlement, a mother would have been able to hear any of the babies crying in the night. If she woke up every time one of them screamed for food, she might get no sleep at all. During the course of evolution she became programmed to awake only at the sound of her own particular baby. This ___ is still there to this day, even though it is seldom used.\n",
            "0    affection\n",
            "1    creativity\n",
            "2    sociability\n",
            "3    intolerance\n",
            "4    sensitivity\n",
            "Predicted Answer =>  sensitivity\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "A term like social drinker was itself what we might call ¡°socially constructed.¡± When a social drinker was caught driving drunk, it was seen as a single instance of bad judgment in an otherwise exemplary life, but this was rarely the case. Experts liked to point out that persons caught driving drunk for the first time had probably done so dozens of times before without incident. The language chosen to characterize these particular individuals, however, reflected the ___ way that society viewed them. The same could be said for the word accident, which was the common term used to describe automobile crashes well into the 1980s. An accident implied an unfortunate act of God, not something that could ¡ª or should ¡ª be prevented. \n",
            "0    forgiving\n",
            "1    objective\n",
            "2    degrading\n",
            "3    unwelcome\n",
            "4    praiseworthy\n",
            "Predicted Answer =>  forgiving\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "In an astonishing example of how nurturing can influence nature, there is considerable evidence confirming that how parents emotionally respond to their children can encourage or suppress genetic tendencies. Biology is not destiny, so gene expression is not necessarily inevitable. To produce their effects, genes must be turned on. For example, shyness is a trait that seems to be partially hereditary. If parents are overprotective of their shy young daughter, the toddler is likely to remain shy. However, if they encourage her to interact with other toddlers, she may overcome it. ___, genetic tendencies toward intelligence, sociability, and aggression can be stimulated, controlled, or suppressed by parental response and other environmental influences.\n",
            "0    Thus\n",
            "1    However\n",
            "2    Similarly\n",
            "3    However\n",
            "4    But\n",
            "Predicted Answer =>  Thus\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "Changing our food habits is one of the hardest things we can do, because the impulses governing our preferences are often hidden, even from ourselves. And yet adjusting what you eat is entirely possible. We do it all the time. Were this not the case, the food companies that launch new products each year would be wasting their money. After the fall of the Berlin Wall, housewives from East and West Germany tried each other's food products for the first time in decades. It didn't take long for those from the East to realize that they preferred Western yogurt to their own. Equally, those from the West discovered a liking for the honey and vanilla wafer biscuits of the East. From both sides of the wall, these German housewives showed a remarkable ___ in their food preferences.\n",
            "0    simplicity\n",
            "1    flexibility\n",
            "2    difference\n",
            "3    resistance\n",
            "4    consistency\n",
            "Predicted Answer =>  flexibility\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "Today, 3D printing technology is used only in\n",
            "companies and universities, but the prices are now\n",
            "getting lower and the quality better. We can\n",
            "imagine every home having a 3D printer in the\n",
            "future. Note that 3D printing technology doesn¡¯t\n",
            "require an original object to copy: any drawing will\n",
            "do, as long as it describes the piece precisely.\n",
            "Soon anyone can use a home sketching tool to\n",
            "produce the proper design, and then the home\n",
            "printer will be able to create the actual physical\n",
            "object. If you can ___ it, you can make it.\n",
            "For example, if you don¡¯t have enough dinner\n",
            "plates for your guests, you can ¡°print out¡± some real\n",
            "plates from your sketch\n",
            "0    mix\n",
            "1    open\n",
            "2    draw\n",
            "3    move\n",
            "4    taste\n",
            "Predicted Answer =>  draw\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "Finkenauer and Rim? investigated the memory of the unexpected death of Belgium¡¯s King Baudouin in 1993 in a large sample of Belgian citizens. The data revealed that the news of the king¡¯s death had been widely socially shared. By talking about the event, people gradually constructed a social narrative and a collective memory of the emotional event. At the same time, they consolidated their own memory of the personal circumstances in which the event took place, an effect known as ¡°flashbulb memory.¡± The more an event is socially shared, the more it will be fixed in people¡¯s minds. Social sharing may in this way help to counteract some natural tendency people may have. Naturally, people should be driven to ¡°forget¡± undesirable events. Thus, someone who just heard a piece of bad news often tends initially to deny what happened. The ___ social sharing of the bad news contributes to realism.\n",
            "0    biased\n",
            "1    illegal\n",
            "2    repetitive\n",
            "3    temporary\n",
            "4    rational\n",
            "Predicted Answer =>  repetitive\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "Costs vary not only with the volume of output, and to varying degrees from one industry to another, they also vary according to the extent to which existing capacity is being used. When an airplane with 200 seats is about to take off with 180 passengers on board, the cost of letting 20 standby passengers get on the flight is negligible. That is one reason for radically different prices being charged to people flying on the same plane. Some passengers bought guaranteed reservations and others essentially bought a chance of getting on board as standbys. Different levels of probability have different costs in airline tickets, as elsewhere. The passengers themselves also differ in how important it is for them to be at a particular place at a particular time. Those on urgent business may want a guaranteed reservation, even at a higher price, while others may be in a position where ___ money is more important than being on one particular flight rather than another. \n",
            "0    saving\n",
            "1    raising\n",
            "2    investing\n",
            "3    decreasing\n",
            "4    increasing\n",
            "Predicted Answer =>  saving\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "Healthy living in individuals lays the foundation for healthy living throughout society and the world. For instance, healthy relationships depend upon healthy individuals sharing personally and working mutually to develop win¡©win agreements on how to grow and maintain the relationship. ___, healthy parenting depends upon healthy parents. Children learn the foundations of how the world works and how to develop their personal reality relative to the consciousness and behaviors of their parents. They model and subconsciously embrace much of their parents¡¯ behavior, so it becomes their own. Thus, the beliefs and behaviors of parents provide psychological and social information to the children that function almost like food does for the body; in this case, the information helps build their personal realities and shape their behaviors. Consequently, psychological, social, as well as the physical diets provided by parents must all be healthy or the children learn to repeat the unhealthy patterns of their parents.\n",
            "0    Similarly\n",
            "1    For example\n",
            "2    However\n",
            "3    In contrast\n",
            "4    But\n",
            "Predicted Answer =>  Similarly\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "For any product, the last step of the recycling process is selling the new product. Unfortunately, it can be hard to find markets for some types of recyclables. Plastic companies generally prefer new plastic, for instance, because it is of more consistent quality than recycled plastic. The new plastic is guaranteed to be free of incompatible polymers ¡ª the chemical from which plastics are made ¡ª that sometimes are mixed in when the plastic is not sorted well before recycling. Manufacturers say it is also easier to control the color of plastics that have no recycled content. ___, paper manufacturers complain that recycled paper often gets dirty during collection and sorting. The added expense of cleaning the paper makes it too expensive to use for some purposes.\n",
            "0    Instead\n",
            "1    Similarly\n",
            "2    In contrast\n",
            "3    Moreover\n",
            "4    In short\n",
            "Predicted Answer =>  Similarly\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "¡°Tell it to the Marines!¡± is a well-known expression in the United States. The expression originated in England when the marines were considered inferior to regular soldiers and sailors since they worked on both land and sea and so were regarded by many as foolish. Early in the nineteenth century, England organized a special army known as the British Royal Marines. These men often had to cross the seas to fight in other parts of the world. They were fine soldiers, but knew very little about life at sea. Sailors enjoyed telling these men unbelievable stories. If sailors tried to fool their own shipmates with tall tales, the reply was, ¡°Tell it to the Marines!¡± These sailors knew that only the marines on board would believe such tales. Today¡¯s marines are not so easily tricked, but we still use this expression to show our ___.\n",
            "0    emotion\n",
            "1    honesty\n",
            "2    courage\n",
            "3    ambition\n",
            "4    disbelief\n",
            "Predicted Answer =>  courage\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "According to field researchers, chimpanzees eat some plants for ___. Chimps occasionally eat Aspilia, which is not part of chimps' usual diet because its leaves are rough, sharp and extremely nasty to eat. They usually eat it first thing in the morning and in a very different way than normal food. They do not chew the leaves, but roll them around in their mouth before swallowing. It looks just as if they are taking old¡©fashioned medicine. Some African people use Aspilia to relieve stomach complaints or remove intestinal worms. It also has antibiotic properties. It is thought that chimps use Aspilia for the same purposes.\n",
            "0    mood change\n",
            "1    nutritional balance\n",
            "2    medicinal purposes\n",
            "3    additional moisture\n",
            "4    social interaction\n",
            "Predicted Answer =>  medicinal purposes\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "The English political scientist John Stuart Mill realized that it is not only within the goods market that a lack of competition is able to push prices up. Monopoly effects can also emerge in the ___ market. He pointed to the case of goldsmiths, who earned much higher wages than workers of a similar skill because they were perceived to be trustworthy¡ªa characteristic that is rare and not easily provable. This created a significant barrier to entry so that those working with gold could demand a monopoly price for their services. Mill realized that the goldsmiths' situation was not an isolated case. He noted that large sections of the working classes were barred from entering skilled professions because they entailed many years of education and training. The cost of supporting someone through this process was out of reach for most families, so those who could afford it were able to enjoy wages far above what might be expected.\n",
            "0    labor\n",
            "1    street\n",
            "2    gold\n",
            "3    property\n",
            "4    capital\n",
            "Predicted Answer =>  labor\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "The true champion recognizes that excellence often flows most smoothly from ___, a fact that can get lost in these high-tech days. I used to train with a world-class runner who was constantly hooking himself up to pulse meters and pace keepers. He spent hours collecting data that he thought would help him improve. In fact, a good 25 percent of his athletic time was devoted to externals other than working out. Sports became so complex for him that he forgot how to enjoy himself. Contrast his approach with that of the late Abebe Bikila, the Ethiopian who won the 1960 Olympic Marathon running barefoot. High-tech clothing and digital watches were not part of his world. Abebe Bikila simply ran. Many times in running, and in other areas of life, less is more. \n",
            "0    talent\n",
            "1    patience\n",
            "2    simplicity\n",
            "3    generosity\n",
            "4    confidence\n",
            "Predicted Answer =>  simplicity\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "It takes time for water to soften a sponge. When you are telling an employee, lawn service worker, your teenager, or anyone else, what it is that you want them to do, you may just have to repeat the order and instructions several times before the receiver really gets what it is you want done. That¡¯s not bad. That¡¯s normal communication lag. Be ___.When you are asking someone a question, in an effort to learn a fact that you feel is important for you to know, but they just don¡¯t seem to be willing to give you an answer, take it as a signal that you need to rephrase your question a little and repeat it again, and again, and again, until finally you are heard and answered.\n",
            "0    patient\n",
            "1    honest\n",
            "2    critical\n",
            "3    thankful\n",
            "4    curious\n",
            "Predicted Answer =>  patient\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "The idea that artists have a unique message to communicate is only a few hundred years old. For most of European history, artists were considered primarily craftsmen. When a noble contracted with a painter for a work, the contract specified details like the quantities of gold and blue paint to appear in the work, the deadline, and penalties for delays. A contract in 1485 between the painter Domenico Ghirlandaio and a client specified that Ghirlandaio would ¡°colour the panel at his own expense with good colours and with powdered gold on such ornaments as demand it ... and the blue must be ultramarine of the value about four florins per ounce¡±. In some contracts, artists were paid by the time worked rather than a fixed price for the completed work. These contract details show us that art was considered to be a  ___ ¡ª a very different concept of the artist than we hold today.\n",
            "0    trade\n",
            "1    hobby\n",
            "2    symbol\n",
            "3    miracle\n",
            "4    blessing\n",
            "Predicted Answer =>  trade\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "If we can¡¯t have everything we want today, what do we do? We are forced to make choices. We must choose some goods and services and not others. Sometimes this kind of choosing can be visibly painful. Have you ever watched children in a toy store with a gift certificate in hand? It can take them all day before they make a choice. And instead of bubbling with excitement over the toy they bought, they usually appear frustrated over not being able to walk away with everything! Life is like that. ___ governs us. Because we cannot have everything all at once, we are forever forced to make choices. We can use our resources to satisfy only some of our wants, leaving many others unsatisfied. \n",
            "0    Scarcity\n",
            "1    Morality\n",
            "2    Knowledge\n",
            "3    Reputation\n",
            "4    Compassion\n",
            "Predicted Answer =>  Scarcity\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "When you begin to tell a story again that you have retold many times, what you retrieve from memory is the index to the story itself. That index can be embellished in a variety of ways. Over time, even the embellishments become standardized. An old man¡¯s story that he has told hundreds of times shows little variation, and any variation that does exist becomes part of the story itself, regardless of its origin. People add details to their stories that may or may not have occurred. They are recalling indexes and reconstructing details. If at some point they add a nice detail, not really certain of its validity, telling the story with that same detail a few more times will ensure its permanent place in the story index. In other words, the stories we tell time and again are ___ to the memory we have of the events that the story relates. \n",
            "0    identical\n",
            "1    beneficial\n",
            "2    alien\n",
            "3    prior\n",
            "4    neutral\n",
            "Predicted Answer =>  identical\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "The biggest trap many family gardeners fall into is creating a garden that is too large. Even though you may have the best of intentions, over time a garden that is too large will become a maintenance nightmare. My family, like many others, eagerly planted large gardens only to cut back slowly on the time devoted to gardening. Sometime in September, we ended up with a garden full of overripened fruit and out¡©of¡©control, overgrown plants. This situation is not enjoyable for adult gardeners, let alone for children. Most children (and many adults) won't enjoy spending their warm sunny days tending an overgrown garden plot. When thinking about the size of your family garden, be ___. Plan the size according to the time your family can devote to the garden.\n",
            "0    diligent\n",
            "1    ambitious\n",
            "2    realistic\n",
            "3    challenging\n",
            "4    cooperative\n",
            "Predicted Answer =>  realistic\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "Getting to know yourself better takes ___. It is far easier to hide behind a mask than to see yourself as you really are. If you wish to know yourself and change for the better, you need to accept your weaknesses, mistakes, and more. That requires facing the fear of knowing yourself as you are. Most people who are afraid to know themselves, need others present constantly to entertain and distract them. That¡¯s because they are fearful of being still and actually seeing themselves. However, relying on others will only make matters worse. So you need to try to stay totally alone and see who you are, controlling the fear inside you. It will take a lot of nerve, but it is worth it.\n",
            "0    courage\n",
            "1    strategy\n",
            "2    modesty\n",
            "3    knowledge\n",
            "4    responsibility\n",
            "Predicted Answer =>  courage\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "For almost every location in the world, there is an ¡°optimal¡± temperature at which deaths are the lowest. On either side of this temperature ? both when it gets colder and warmer ? death rates increase. ___, what the optimal temperature is is a different issue. If you live in Helsinki, your optimal temperature is about 59¡ÆF, whereas in Athens you do best at 75¡ÆF. The important point to notice is that the best temperature is typically very similar to the average summer temperature.Thus, the actual temperature will only rarely go above the optimal temperature, but very often it will be below. In Helsinki, the optimal temperature is typically exceeded only 18 days per year, whereas it is below that temperature a full 312 days. Research shows that although 55 extra people die each year from it being too hot in Helsinki, some 1,655 people die from it being too cold. \n",
            "0    However\n",
            "1    In addition\n",
            "2    For instance\n",
            "3    For example\n",
            "4    Otherwise\n",
            "Predicted Answer =>  However\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "Wetlands are sometimes referred to as nature¡¯s kidneys. It is indeed impressive to see how well wetlands with flow-through characteristics change water chemistry. They generally increase water clarity and remove chemicals such as nitratenitrogen. They also retain or partially remove many of the constituents from water passing through the wetland system, including suspended solids, bacteria, certain heavy metals, and phosphorus. There are thousands of published papers in the past 35 years that have illustrated how natural and constructed wetlands ___.\n",
            "0    reduce soil erosion\n",
            "1    improve water quality\n",
            "2    protect us against floods\n",
            "3    are good places for fishing\n",
            "4    provide perfect nesting grounds\n",
            "Predicted Answer =>  improve water quality\n",
            "Correct!!!\n",
            "Question 5 / 31\n",
            "The monarch butterfly¡¯s caterpillars have some physical characteristics that make them noticeable to their predators. The caterpillars have yellow, black, and white stripes around their bodies and are unable to move quickly. They are highly visible while they munch their way across leaves. They offer a tasty snack to some insects and to many bigger animals, especially birds. But the monarch caterpillar¡¯s ___ protects it. Any bird that ate a monarch caterpillar would be so ill that it would never touch another. The monarch caterpillars feed on milkweed plants. The milkweed poison that accumulates in the caterpillar¡¯s body remains there even after it changes into the adult butterfly. Consequently the monarch butterfly is also poisonous and remains so throughout its life although adult monarchs feed only on nectar from flowers.\n",
            "0    diet\n",
            "1    smell\n",
            "2    sound\n",
            "3    shape\n",
            "4    coloration\n",
            "Predicted Answer =>  diet\n",
            "Wrong..\n",
            "Question 5 / 31\n",
            "No one else can experience the way your heart feels about things. No one can see through the lens you use to see life quite the same as you do. Accept this ___. Honor and praise it, too. Do not be quick to compromise it. In your desire to fit in or make others happy, you may be tempted to pretend to be someone you are not. You may even pretend to believe things you don't really believe, or act in ways that are out of character with who you really are. When you do this, you lose out on the real you. The world loses out on you, too. Strive to be a healthy, happy and enlightened person¡ªand then, taking your place alongside your fellow travelers, offer your self to the waiting world.\n",
            "0    similarity\n",
            "1    endurance\n",
            "2    generosity\n",
            "3    individuality\n",
            "4    compliment\n",
            "Predicted Answer =>  individuality\n",
            "Wrong..\n",
            "Question 5 / 31\n"
          ]
        }
      ],
      "source": [
        "# Evaluation loop\n",
        "num_correct = 0\n",
        "for idx, row in test_data.iterrows():\n",
        "    context = row[\"question\"]\n",
        "    options = row[\"option\"].split(',')  # Assumes options are comma-separated in the CSV\n",
        "    options = [option.strip() for option in options]\n",
        "    correct_option = row[\"answer\"].strip()\n",
        "\n",
        "    # Prepare the inputs\n",
        "    choices_inputs = [tokenizer.encode_plus(context.replace('___', option), return_tensors='pt', max_length=256, padding='max_length', truncation=True) for option in options]\n",
        "\n",
        "    # Get the input tensors and reshape them\n",
        "    input_ids = torch.cat([choice['input_ids'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    attention_mask = torch.cat([choice['attention_mask'] for choice in choices_inputs], dim=0).view(1, len(options), -1)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    # Compute the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Get the predicted option\n",
        "    predicted_option = torch.argmax(outputs.logits).item()\n",
        "\n",
        "    print(context)\n",
        "    for idx, r in enumerate(options):\n",
        "      print(idx, '  ', r)\n",
        "    print('Predicted Answer => ', correct_option)\n",
        "\n",
        "    # Check if the prediction is correct\n",
        "    if predicted_option == options.index(correct_option):\n",
        "        num_correct += 1\n",
        "        print('Correct!!!')\n",
        "    else:\n",
        "        print('Wrong..')\n",
        "    print(f\"Question {idx + 1} / {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfuGVnUWJ56u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "215f3d42-1b44-48ae-94ae-965b5d734e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5806451612903226\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy: {num_correct / len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be observed that the accuracy significantly improves when both the TOEIC and 수능 datasets are used for training.\n",
        "Fill-in-the-blank inference questions in the English section often have a high rate of incorrect answers. Even though these are short-word fill-in-the-blank questions, achieving such a level of accuracy with a dataset of around 150 samples is quite remarkable. I believe that with a larger dataset, it would be possible to achieve even higher accuracy. Also the epoch is small due to the execution time is so long. So the increase of epoch can also achieve higher accuracy."
      ],
      "metadata": {
        "id": "_Op6cqXPFfN2"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6291fcd6b963428b87be058e2ab96e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a25b6bd30e147cf9416ab4771d6434f",
              "IPY_MODEL_7a8039447b744eaa825a1ec779a773f6",
              "IPY_MODEL_0172d726e1954b11b32856048e892eed"
            ],
            "layout": "IPY_MODEL_f413c03364f342608ab44da96182e1b2"
          }
        },
        "3a25b6bd30e147cf9416ab4771d6434f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a6384e3a2b74f83b4e6c702f84ac4e7",
            "placeholder": "​",
            "style": "IPY_MODEL_a1db969a4f7b440abe13beaff200fef7",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7a8039447b744eaa825a1ec779a773f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ebb16dcea2d4143a2f5b100055f3165",
            "max": 762,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e754c626e56488fb9e6964261ab2d08",
            "value": 762
          }
        },
        "0172d726e1954b11b32856048e892eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68fd56caee394c1084f5f1bf862f661d",
            "placeholder": "​",
            "style": "IPY_MODEL_e8d0208c3253474ea72aead7fe7975e8",
            "value": " 762/762 [00:00&lt;00:00, 49.0kB/s]"
          }
        },
        "f413c03364f342608ab44da96182e1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6384e3a2b74f83b4e6c702f84ac4e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1db969a4f7b440abe13beaff200fef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ebb16dcea2d4143a2f5b100055f3165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e754c626e56488fb9e6964261ab2d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68fd56caee394c1084f5f1bf862f661d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d0208c3253474ea72aead7fe7975e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c037718cf1984b19a7e5068d39374f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88c61a03f1124f6e9954302553191d59",
              "IPY_MODEL_476270df6c6f40428e42056ffcce25d2",
              "IPY_MODEL_e2faa102c69d442ca181535d670ef49c"
            ],
            "layout": "IPY_MODEL_9fe0f39f66fe4f21b6681031d3c93df8"
          }
        },
        "88c61a03f1124f6e9954302553191d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a008d67b8534e398323e72b647f9c7a",
            "placeholder": "​",
            "style": "IPY_MODEL_3954827f8f164c61ae779d7d5b2f0e44",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "476270df6c6f40428e42056ffcce25d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d236d53430f440095a65e6dbd4cecc1",
            "max": 1338695354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7a4c24dd2d646e5b410fc4e9caa0751",
            "value": 1338695354
          }
        },
        "e2faa102c69d442ca181535d670ef49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb615ac51d24fbea82013d80fb37707",
            "placeholder": "​",
            "style": "IPY_MODEL_6cd76af7fffb485189db1fd701ff24d1",
            "value": " 1.34G/1.34G [00:04&lt;00:00, 184MB/s]"
          }
        },
        "9fe0f39f66fe4f21b6681031d3c93df8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a008d67b8534e398323e72b647f9c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3954827f8f164c61ae779d7d5b2f0e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d236d53430f440095a65e6dbd4cecc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7a4c24dd2d646e5b410fc4e9caa0751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbb615ac51d24fbea82013d80fb37707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd76af7fffb485189db1fd701ff24d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d920a9c97cf149fd825f8685aa01ada6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a94a001e0aa44a9eb00432bb05a818fa",
              "IPY_MODEL_085b8cea9060437a9c8eeabdf15e3b58",
              "IPY_MODEL_ac3e4a6bcb84435997c27f1d05b56f35"
            ],
            "layout": "IPY_MODEL_90a1b2657dd544af950e962773a47a70"
          }
        },
        "a94a001e0aa44a9eb00432bb05a818fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109adf8f80d049609d281a106df9d8a9",
            "placeholder": "​",
            "style": "IPY_MODEL_40caa59333674b4f884305ea3aa0bb09",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "085b8cea9060437a9c8eeabdf15e3b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bdca07c66d14ae88cbd19946873454c",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_293cfdb6faa34201a67a86f9349a76b6",
            "value": 213450
          }
        },
        "ac3e4a6bcb84435997c27f1d05b56f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90a9550b9da046fca6387e1e3098844d",
            "placeholder": "​",
            "style": "IPY_MODEL_e04453f232024a96967590b655fddc9a",
            "value": " 213k/213k [00:00&lt;00:00, 1.31MB/s]"
          }
        },
        "90a1b2657dd544af950e962773a47a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109adf8f80d049609d281a106df9d8a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40caa59333674b4f884305ea3aa0bb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bdca07c66d14ae88cbd19946873454c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293cfdb6faa34201a67a86f9349a76b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90a9550b9da046fca6387e1e3098844d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e04453f232024a96967590b655fddc9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c3ced200d894ade8b0e88f6d6343c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32d78cc9c9264a0f82e026b4c6849ca1",
              "IPY_MODEL_62aaa96d281042579ac362ae0e20c82b",
              "IPY_MODEL_4d9cddc745584f74b4b123017c6e3278"
            ],
            "layout": "IPY_MODEL_64fa48ccabfe40c898b4547302a51067"
          }
        },
        "32d78cc9c9264a0f82e026b4c6849ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edbfd7f673db4705bc2453f3ca557d7b",
            "placeholder": "​",
            "style": "IPY_MODEL_661548674be44fb9ae18e981a2c047b0",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "62aaa96d281042579ac362ae0e20c82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2170e836df47411aa8c6d8a24597e009",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b613911814a4607a9d3d9f3ea93226c",
            "value": 29
          }
        },
        "4d9cddc745584f74b4b123017c6e3278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f8ebb196154a1286f7da7198c1a5cc",
            "placeholder": "​",
            "style": "IPY_MODEL_7f84adc1c7584234955c4e5abd6c8eac",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.23kB/s]"
          }
        },
        "64fa48ccabfe40c898b4547302a51067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edbfd7f673db4705bc2453f3ca557d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "661548674be44fb9ae18e981a2c047b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2170e836df47411aa8c6d8a24597e009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b613911814a4607a9d3d9f3ea93226c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3f8ebb196154a1286f7da7198c1a5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f84adc1c7584234955c4e5abd6c8eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}